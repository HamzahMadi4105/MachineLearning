{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59781bc2-44e4-48bc-ae8b-e052fde6caf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a908c3d6-71c4-461b-8757-b2501b91eb81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available. Using GPU.\n"
     ]
    }
   ],
   "source": [
    "# Check if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available. Using GPU.\")\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    print(\"CUDA is not available. Using CPU.\")\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1238e675-3c7f-4026-a933-db57b5e9c078",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66e3e4df-f35d-4023-9cc9-1a91c7e76f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5249a08e-8a1f-4fef-b9a6-3ed864338a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets\n",
    "data_path = '../data-unversioned/p1ch7/'\n",
    "cifar10 = datasets.CIFAR10(data_path, train=True, download=True, transform=transform)\n",
    "cifar10_val = datasets.CIFAR10(data_path, train=False, download=True, transform=transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cdc821af-8934-452a-b1f4-29db620e6e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.act1 = nn.Tanh()\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.act2 = nn.Tanh()\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.fc1 = nn.Linear(64 * 8 * 8, 256)  \n",
    "        self.act3 = nn.Tanh()\n",
    "        self.fc2 = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.pool1(self.act1(self.conv1(x)))\n",
    "        out = self.pool2(self.act2(self.conv2(out)))\n",
    "        out = out.view(-1, 64 * 8 * 8) \n",
    "        out = self.act3(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ff5c3db2-7469-46e2-b6b5-4d7ecb22c487",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def validate(model, loader, device):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()  #\n",
    "    with torch.no_grad(): \n",
    "        for imgs, labels in loader:\n",
    "            imgs = imgs.to(device=device)\n",
    "            labels = labels.to(device=device)\n",
    "            outputs = model(imgs)\n",
    "            _, predicted = torch.max(outputs, dim=1)\n",
    "            total += labels.shape[0]\n",
    "            correct += int((predicted == labels).sum())\n",
    "    model.train()  \n",
    "    return correct / total\n",
    "\n",
    "def training_loop(n_epochs, optimizer, model, loss_fn, train_loader, val_loader, device):\n",
    "    total_start_time = time.time()\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        model.train()  \n",
    "        loss_train = 0.0\n",
    "        start_time = time.time()\n",
    "        \n",
    "        for imgs, labels in train_loader:\n",
    "            imgs = imgs.to(device=device)    \n",
    "            labels = labels.to(device=device) \n",
    "            outputs = model(imgs)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            loss_train += loss.item()\n",
    "          \n",
    "        val_accuracy = validate(model, val_loader, device) *100\n",
    "        avg_loss = loss_train / len(train_loader)\n",
    "        print(f\"Epoch: {epoch}, Training Loss: {avg_loss}\")\n",
    "        print(f'Validation Accuracy after epoch {epoch}: {val_accuracy}%')\n",
    "    end_time = time.time()  \n",
    "    duration = end_time - total_start_time\n",
    "    print(f'Total Training Time: {duration} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b6d96395-ed82-4479-a1db-e80a9e717f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(cifar10, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(cifar10_val, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9a7075fb-a187-4a76-921a-c6e6e86d8eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-2)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "162ebef9-9ef2-4e6e-8e1a-0e5bc9dd9579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Training Loss: 2.065116420883657\n",
      "Validation Accuracy after epoch 1: 33.83%\n",
      "Epoch: 2, Training Loss: 1.7632340982442012\n",
      "Validation Accuracy after epoch 2: 42.21%\n",
      "Epoch: 3, Training Loss: 1.6107084688628117\n",
      "Validation Accuracy after epoch 3: 42.08%\n",
      "Epoch: 4, Training Loss: 1.5177295834512052\n",
      "Validation Accuracy after epoch 4: 45.89%\n",
      "Epoch: 5, Training Loss: 1.4411470807726732\n",
      "Validation Accuracy after epoch 5: 44.89%\n",
      "Epoch: 6, Training Loss: 1.3688853079705592\n",
      "Validation Accuracy after epoch 6: 47.17%\n",
      "Epoch: 7, Training Loss: 1.3083990704068138\n",
      "Validation Accuracy after epoch 7: 54.24%\n",
      "Epoch: 8, Training Loss: 1.2526253458788938\n",
      "Validation Accuracy after epoch 8: 54.510000000000005%\n",
      "Epoch: 9, Training Loss: 1.2037605140977503\n",
      "Validation Accuracy after epoch 9: 55.82%\n",
      "Epoch: 10, Training Loss: 1.1594743931384952\n",
      "Validation Accuracy after epoch 10: 56.42%\n",
      "Epoch: 11, Training Loss: 1.1188343331179655\n",
      "Validation Accuracy after epoch 11: 59.31999999999999%\n",
      "Epoch: 12, Training Loss: 1.0821121838086707\n",
      "Validation Accuracy after epoch 12: 61.53999999999999%\n",
      "Epoch: 13, Training Loss: 1.0446395943384341\n",
      "Validation Accuracy after epoch 13: 56.87%\n",
      "Epoch: 14, Training Loss: 1.01209067132162\n",
      "Validation Accuracy after epoch 14: 57.24%\n",
      "Epoch: 15, Training Loss: 0.9808183243817381\n",
      "Validation Accuracy after epoch 15: 59.03%\n",
      "Epoch: 16, Training Loss: 0.952137457211609\n",
      "Validation Accuracy after epoch 16: 64.77000000000001%\n",
      "Epoch: 17, Training Loss: 0.9223178763066411\n",
      "Validation Accuracy after epoch 17: 64.87%\n",
      "Epoch: 18, Training Loss: 0.8961093181844257\n",
      "Validation Accuracy after epoch 18: 66.03%\n",
      "Epoch: 19, Training Loss: 0.8695445535585399\n",
      "Validation Accuracy after epoch 19: 67.35%\n",
      "Epoch: 20, Training Loss: 0.8459777904440985\n",
      "Validation Accuracy after epoch 20: 67.10000000000001%\n",
      "Epoch: 21, Training Loss: 0.819510542561331\n",
      "Validation Accuracy after epoch 21: 66.74%\n",
      "Epoch: 22, Training Loss: 0.7953570082669368\n",
      "Validation Accuracy after epoch 22: 66.45%\n",
      "Epoch: 23, Training Loss: 0.7737398921604961\n",
      "Validation Accuracy after epoch 23: 68.0%\n",
      "Epoch: 24, Training Loss: 0.7503139534798424\n",
      "Validation Accuracy after epoch 24: 67.97%\n",
      "Epoch: 25, Training Loss: 0.7290414993262961\n",
      "Validation Accuracy after epoch 25: 67.25999999999999%\n",
      "Epoch: 26, Training Loss: 0.7072287666828126\n",
      "Validation Accuracy after epoch 26: 68.12%\n",
      "Epoch: 27, Training Loss: 0.6842225561361484\n",
      "Validation Accuracy after epoch 27: 64.63%\n",
      "Epoch: 28, Training Loss: 0.6617165822583391\n",
      "Validation Accuracy after epoch 28: 68.19%\n",
      "Epoch: 29, Training Loss: 0.6402384328186664\n",
      "Validation Accuracy after epoch 29: 70.13000000000001%\n",
      "Epoch: 30, Training Loss: 0.6192137683977557\n",
      "Validation Accuracy after epoch 30: 69.32000000000001%\n",
      "Epoch: 31, Training Loss: 0.5985918114785953\n",
      "Validation Accuracy after epoch 31: 70.42%\n",
      "Epoch: 32, Training Loss: 0.5762123254025379\n",
      "Validation Accuracy after epoch 32: 69.36%\n",
      "Epoch: 33, Training Loss: 0.5544752336447806\n",
      "Validation Accuracy after epoch 33: 70.12%\n",
      "Epoch: 34, Training Loss: 0.5345153493801956\n",
      "Validation Accuracy after epoch 34: 69.48%\n",
      "Epoch: 35, Training Loss: 0.5117942027347472\n",
      "Validation Accuracy after epoch 35: 70.67999999999999%\n",
      "Epoch: 36, Training Loss: 0.4912746309891076\n",
      "Validation Accuracy after epoch 36: 68.12%\n",
      "Epoch: 37, Training Loss: 0.4702753711996786\n",
      "Validation Accuracy after epoch 37: 70.93%\n",
      "Epoch: 38, Training Loss: 0.4496234234451028\n",
      "Validation Accuracy after epoch 38: 68.74%\n",
      "Epoch: 39, Training Loss: 0.42933545741812346\n",
      "Validation Accuracy after epoch 39: 69.8%\n",
      "Epoch: 40, Training Loss: 0.4090209953925189\n",
      "Validation Accuracy after epoch 40: 71.19%\n",
      "Epoch: 41, Training Loss: 0.38747965997975803\n",
      "Validation Accuracy after epoch 41: 70.45%\n",
      "Epoch: 42, Training Loss: 0.368224593246227\n",
      "Validation Accuracy after epoch 42: 70.49%\n",
      "Epoch: 43, Training Loss: 0.3493745735920299\n",
      "Validation Accuracy after epoch 43: 69.58%\n",
      "Epoch: 44, Training Loss: 0.3304438734298472\n",
      "Validation Accuracy after epoch 44: 71.09%\n",
      "Epoch: 45, Training Loss: 0.31157827527855364\n",
      "Validation Accuracy after epoch 45: 70.33%\n",
      "Epoch: 46, Training Loss: 0.2937133729534076\n",
      "Validation Accuracy after epoch 46: 71.04%\n",
      "Epoch: 47, Training Loss: 0.27497445187910136\n",
      "Validation Accuracy after epoch 47: 70.87%\n",
      "Epoch: 48, Training Loss: 0.2585117391898961\n",
      "Validation Accuracy after epoch 48: 70.96000000000001%\n",
      "Epoch: 49, Training Loss: 0.24254545966720642\n",
      "Validation Accuracy after epoch 49: 70.86%\n",
      "Epoch: 50, Training Loss: 0.22642563091938758\n",
      "Validation Accuracy after epoch 50: 71.2%\n",
      "Epoch: 51, Training Loss: 0.2109920882984348\n",
      "Validation Accuracy after epoch 51: 70.67%\n",
      "Epoch: 52, Training Loss: 0.19760141291124436\n",
      "Validation Accuracy after epoch 52: 71.13000000000001%\n",
      "Epoch: 53, Training Loss: 0.18440390391575406\n",
      "Validation Accuracy after epoch 53: 70.13000000000001%\n",
      "Epoch: 54, Training Loss: 0.17148783116999183\n",
      "Validation Accuracy after epoch 54: 70.61%\n",
      "Epoch: 55, Training Loss: 0.15980388580457025\n",
      "Validation Accuracy after epoch 55: 69.61%\n",
      "Epoch: 56, Training Loss: 0.14826153401199663\n",
      "Validation Accuracy after epoch 56: 70.23%\n",
      "Epoch: 57, Training Loss: 0.1377119443157826\n",
      "Validation Accuracy after epoch 57: 70.66%\n",
      "Epoch: 58, Training Loss: 0.12872010325569935\n",
      "Validation Accuracy after epoch 58: 68.76%\n",
      "Epoch: 59, Training Loss: 0.12001263937624672\n",
      "Validation Accuracy after epoch 59: 70.97%\n",
      "Epoch: 60, Training Loss: 0.11176448366354647\n",
      "Validation Accuracy after epoch 60: 70.36%\n",
      "Epoch: 61, Training Loss: 0.10412443248683687\n",
      "Validation Accuracy after epoch 61: 70.94%\n",
      "Epoch: 62, Training Loss: 0.09701611346010204\n",
      "Validation Accuracy after epoch 62: 70.85000000000001%\n",
      "Epoch: 63, Training Loss: 0.09035408829369813\n",
      "Validation Accuracy after epoch 63: 70.75%\n",
      "Epoch: 64, Training Loss: 0.08450114917572198\n",
      "Validation Accuracy after epoch 64: 70.17999999999999%\n",
      "Epoch: 65, Training Loss: 0.0792408344643119\n",
      "Validation Accuracy after epoch 65: 70.78%\n",
      "Epoch: 66, Training Loss: 0.07411647091150436\n",
      "Validation Accuracy after epoch 66: 70.44%\n",
      "Epoch: 67, Training Loss: 0.06961888598892695\n",
      "Validation Accuracy after epoch 67: 70.56%\n",
      "Epoch: 68, Training Loss: 0.06551168286396414\n",
      "Validation Accuracy after epoch 68: 70.64%\n",
      "Epoch: 69, Training Loss: 0.061711692677625\n",
      "Validation Accuracy after epoch 69: 70.39%\n",
      "Epoch: 70, Training Loss: 0.05797508809610706\n",
      "Validation Accuracy after epoch 70: 70.96000000000001%\n",
      "Epoch: 71, Training Loss: 0.05477400894855599\n",
      "Validation Accuracy after epoch 71: 70.84%\n",
      "Epoch: 72, Training Loss: 0.05199003146718378\n",
      "Validation Accuracy after epoch 72: 70.82000000000001%\n",
      "Epoch: 73, Training Loss: 0.04920959499571711\n",
      "Validation Accuracy after epoch 73: 69.88%\n",
      "Epoch: 74, Training Loss: 0.04661591018042754\n",
      "Validation Accuracy after epoch 74: 70.67999999999999%\n",
      "Epoch: 75, Training Loss: 0.044377601076670166\n",
      "Validation Accuracy after epoch 75: 70.45%\n",
      "Epoch: 76, Training Loss: 0.04221289837375626\n",
      "Validation Accuracy after epoch 76: 70.64%\n",
      "Epoch: 77, Training Loss: 0.04021698948176925\n",
      "Validation Accuracy after epoch 77: 70.65%\n",
      "Epoch: 78, Training Loss: 0.03854641101092024\n",
      "Validation Accuracy after epoch 78: 70.67%\n",
      "Epoch: 79, Training Loss: 0.036754265727708714\n",
      "Validation Accuracy after epoch 79: 70.65%\n",
      "Epoch: 80, Training Loss: 0.03521184176873521\n",
      "Validation Accuracy after epoch 80: 70.67%\n",
      "Epoch: 81, Training Loss: 0.033671945471630986\n",
      "Validation Accuracy after epoch 81: 70.67%\n",
      "Epoch: 82, Training Loss: 0.03236964743231873\n",
      "Validation Accuracy after epoch 82: 70.75%\n",
      "Epoch: 83, Training Loss: 0.03111405200694147\n",
      "Validation Accuracy after epoch 83: 70.81%\n",
      "Epoch: 84, Training Loss: 0.029965334776741313\n",
      "Validation Accuracy after epoch 84: 70.67%\n",
      "Epoch: 85, Training Loss: 0.028775636747460382\n",
      "Validation Accuracy after epoch 85: 70.69%\n",
      "Epoch: 86, Training Loss: 0.027743328003036548\n",
      "Validation Accuracy after epoch 86: 70.67%\n",
      "Epoch: 87, Training Loss: 0.026777729463508673\n",
      "Validation Accuracy after epoch 87: 70.76%\n",
      "Epoch: 88, Training Loss: 0.025838244970783096\n",
      "Validation Accuracy after epoch 88: 70.75%\n",
      "Epoch: 89, Training Loss: 0.024952236841649503\n",
      "Validation Accuracy after epoch 89: 70.77%\n",
      "Epoch: 90, Training Loss: 0.024084949053709618\n",
      "Validation Accuracy after epoch 90: 70.5%\n",
      "Epoch: 91, Training Loss: 0.023387022084220672\n",
      "Validation Accuracy after epoch 91: 70.6%\n",
      "Epoch: 92, Training Loss: 0.022695892083141808\n",
      "Validation Accuracy after epoch 92: 70.58%\n",
      "Epoch: 93, Training Loss: 0.0218546923721576\n",
      "Validation Accuracy after epoch 93: 70.63000000000001%\n",
      "Epoch: 94, Training Loss: 0.021208873770111585\n",
      "Validation Accuracy after epoch 94: 70.41%\n",
      "Epoch: 95, Training Loss: 0.020609838111549997\n",
      "Validation Accuracy after epoch 95: 70.63000000000001%\n",
      "Epoch: 96, Training Loss: 0.020041687043664783\n",
      "Validation Accuracy after epoch 96: 70.67%\n",
      "Epoch: 97, Training Loss: 0.01945382642471577\n",
      "Validation Accuracy after epoch 97: 70.76%\n",
      "Epoch: 98, Training Loss: 0.018937056242247754\n",
      "Validation Accuracy after epoch 98: 70.82000000000001%\n",
      "Epoch: 99, Training Loss: 0.018418985545811485\n",
      "Validation Accuracy after epoch 99: 70.46%\n",
      "Epoch: 100, Training Loss: 0.017946180090775043\n",
      "Validation Accuracy after epoch 100: 70.78%\n",
      "Epoch: 101, Training Loss: 0.017492100402303135\n",
      "Validation Accuracy after epoch 101: 70.58%\n",
      "Epoch: 102, Training Loss: 0.01702524579184897\n",
      "Validation Accuracy after epoch 102: 70.49%\n",
      "Epoch: 103, Training Loss: 0.016630457125870926\n",
      "Validation Accuracy after epoch 103: 70.8%\n",
      "Epoch: 104, Training Loss: 0.016194273237748753\n",
      "Validation Accuracy after epoch 104: 70.54%\n",
      "Epoch: 105, Training Loss: 0.015814858629270588\n",
      "Validation Accuracy after epoch 105: 70.66%\n",
      "Epoch: 106, Training Loss: 0.015426622772746531\n",
      "Validation Accuracy after epoch 106: 70.73%\n",
      "Epoch: 107, Training Loss: 0.01507888959906519\n",
      "Validation Accuracy after epoch 107: 70.58%\n",
      "Epoch: 108, Training Loss: 0.01469463953757873\n",
      "Validation Accuracy after epoch 108: 70.58%\n",
      "Epoch: 109, Training Loss: 0.014401209562102241\n",
      "Validation Accuracy after epoch 109: 70.69%\n",
      "Epoch: 110, Training Loss: 0.014095153647672642\n",
      "Validation Accuracy after epoch 110: 70.72%\n",
      "Epoch: 111, Training Loss: 0.013793743322091297\n",
      "Validation Accuracy after epoch 111: 70.81%\n",
      "Epoch: 112, Training Loss: 0.013479744021059073\n",
      "Validation Accuracy after epoch 112: 70.74000000000001%\n",
      "Epoch: 113, Training Loss: 0.013199419651390112\n",
      "Validation Accuracy after epoch 113: 70.67%\n",
      "Epoch: 114, Training Loss: 0.012898232000629844\n",
      "Validation Accuracy after epoch 114: 70.64%\n",
      "Epoch: 115, Training Loss: 0.012693452208167148\n",
      "Validation Accuracy after epoch 115: 70.77%\n",
      "Epoch: 116, Training Loss: 0.012418577897117075\n",
      "Validation Accuracy after epoch 116: 70.69%\n",
      "Epoch: 117, Training Loss: 0.012183073084548954\n",
      "Validation Accuracy after epoch 117: 70.67999999999999%\n",
      "Epoch: 118, Training Loss: 0.011953897750995996\n",
      "Validation Accuracy after epoch 118: 70.7%\n",
      "Epoch: 119, Training Loss: 0.011718636620408663\n",
      "Validation Accuracy after epoch 119: 70.74000000000001%\n",
      "Epoch: 120, Training Loss: 0.011501639951592134\n",
      "Validation Accuracy after epoch 120: 70.71%\n",
      "Epoch: 121, Training Loss: 0.011298663901103198\n",
      "Validation Accuracy after epoch 121: 70.84%\n",
      "Epoch: 122, Training Loss: 0.011086861386209193\n",
      "Validation Accuracy after epoch 122: 70.75%\n",
      "Epoch: 123, Training Loss: 0.010901880164123367\n",
      "Validation Accuracy after epoch 123: 70.7%\n",
      "Epoch: 124, Training Loss: 0.010699228282369997\n",
      "Validation Accuracy after epoch 124: 70.61%\n",
      "Epoch: 125, Training Loss: 0.01051305445885319\n",
      "Validation Accuracy after epoch 125: 70.59%\n",
      "Epoch: 126, Training Loss: 0.01032973428154388\n",
      "Validation Accuracy after epoch 126: 70.75%\n",
      "Epoch: 127, Training Loss: 0.010154997632193291\n",
      "Validation Accuracy after epoch 127: 70.61%\n",
      "Epoch: 128, Training Loss: 0.009987844226886625\n",
      "Validation Accuracy after epoch 128: 70.8%\n",
      "Epoch: 129, Training Loss: 0.00982440419225951\n",
      "Validation Accuracy after epoch 129: 70.7%\n",
      "Epoch: 130, Training Loss: 0.00966009587976043\n",
      "Validation Accuracy after epoch 130: 70.71%\n",
      "Epoch: 131, Training Loss: 0.009499089874546318\n",
      "Validation Accuracy after epoch 131: 70.61%\n",
      "Epoch: 132, Training Loss: 0.009350803673572248\n",
      "Validation Accuracy after epoch 132: 70.8%\n",
      "Epoch: 133, Training Loss: 0.009205527932923811\n",
      "Validation Accuracy after epoch 133: 70.78999999999999%\n",
      "Epoch: 134, Training Loss: 0.009069552891613805\n",
      "Validation Accuracy after epoch 134: 70.78%\n",
      "Epoch: 135, Training Loss: 0.00892908777386579\n",
      "Validation Accuracy after epoch 135: 70.81%\n",
      "Epoch: 136, Training Loss: 0.008794714384081076\n",
      "Validation Accuracy after epoch 136: 70.74000000000001%\n",
      "Epoch: 137, Training Loss: 0.008662530522950736\n",
      "Validation Accuracy after epoch 137: 70.74000000000001%\n",
      "Epoch: 138, Training Loss: 0.008532840615052663\n",
      "Validation Accuracy after epoch 138: 70.59%\n",
      "Epoch: 139, Training Loss: 0.008412778262606325\n",
      "Validation Accuracy after epoch 139: 70.67999999999999%\n",
      "Epoch: 140, Training Loss: 0.008296774446611742\n",
      "Validation Accuracy after epoch 140: 70.54%\n",
      "Epoch: 141, Training Loss: 0.008182518644487042\n",
      "Validation Accuracy after epoch 141: 70.78999999999999%\n",
      "Epoch: 142, Training Loss: 0.008055839744155935\n",
      "Validation Accuracy after epoch 142: 70.75%\n",
      "Epoch: 143, Training Loss: 0.007946159680495444\n",
      "Validation Accuracy after epoch 143: 70.63000000000001%\n",
      "Epoch: 144, Training Loss: 0.007853565992468305\n",
      "Validation Accuracy after epoch 144: 70.67%\n",
      "Epoch: 145, Training Loss: 0.007744645792752733\n",
      "Validation Accuracy after epoch 145: 70.71%\n",
      "Epoch: 146, Training Loss: 0.007634823220660505\n",
      "Validation Accuracy after epoch 146: 70.71%\n",
      "Epoch: 147, Training Loss: 0.007524536452744432\n",
      "Validation Accuracy after epoch 147: 70.61%\n",
      "Epoch: 148, Training Loss: 0.0074368683130616115\n",
      "Validation Accuracy after epoch 148: 70.69%\n",
      "Epoch: 149, Training Loss: 0.007332738119718211\n",
      "Validation Accuracy after epoch 149: 70.66%\n",
      "Epoch: 150, Training Loss: 0.0072448945960358665\n",
      "Validation Accuracy after epoch 150: 70.69%\n",
      "Epoch: 151, Training Loss: 0.007148712241957845\n",
      "Validation Accuracy after epoch 151: 70.67999999999999%\n",
      "Epoch: 152, Training Loss: 0.007061810746593663\n",
      "Validation Accuracy after epoch 152: 70.72%\n",
      "Epoch: 153, Training Loss: 0.006974626791632503\n",
      "Validation Accuracy after epoch 153: 70.78%\n",
      "Epoch: 154, Training Loss: 0.00688856771415876\n",
      "Validation Accuracy after epoch 154: 70.84%\n",
      "Epoch: 155, Training Loss: 0.006803617093955045\n",
      "Validation Accuracy after epoch 155: 70.75%\n",
      "Epoch: 156, Training Loss: 0.006721864591407425\n",
      "Validation Accuracy after epoch 156: 70.58%\n",
      "Epoch: 157, Training Loss: 0.00663995886009539\n",
      "Validation Accuracy after epoch 157: 70.77%\n",
      "Epoch: 158, Training Loss: 0.006569520673652649\n",
      "Validation Accuracy after epoch 158: 70.83%\n",
      "Epoch: 159, Training Loss: 0.006491725881765013\n",
      "Validation Accuracy after epoch 159: 70.6%\n",
      "Epoch: 160, Training Loss: 0.006416603565856795\n",
      "Validation Accuracy after epoch 160: 70.63000000000001%\n",
      "Epoch: 161, Training Loss: 0.006345131359470394\n",
      "Validation Accuracy after epoch 161: 70.67999999999999%\n",
      "Epoch: 162, Training Loss: 0.0062693023031143965\n",
      "Validation Accuracy after epoch 162: 70.72%\n",
      "Epoch: 163, Training Loss: 0.006197794107720256\n",
      "Validation Accuracy after epoch 163: 70.69%\n",
      "Epoch: 164, Training Loss: 0.006130842399685775\n",
      "Validation Accuracy after epoch 164: 70.72%\n",
      "Epoch: 165, Training Loss: 0.006061052163357815\n",
      "Validation Accuracy after epoch 165: 70.76%\n",
      "Epoch: 166, Training Loss: 0.005994572472113096\n",
      "Validation Accuracy after epoch 166: 70.7%\n",
      "Epoch: 167, Training Loss: 0.005930130096340595\n",
      "Validation Accuracy after epoch 167: 70.58%\n",
      "Epoch: 168, Training Loss: 0.005861161794463444\n",
      "Validation Accuracy after epoch 168: 70.67999999999999%\n",
      "Epoch: 169, Training Loss: 0.005800514768980577\n",
      "Validation Accuracy after epoch 169: 70.72%\n",
      "Epoch: 170, Training Loss: 0.005744296202288412\n",
      "Validation Accuracy after epoch 170: 70.78999999999999%\n",
      "Epoch: 171, Training Loss: 0.005683400577393925\n",
      "Validation Accuracy after epoch 171: 70.73%\n",
      "Epoch: 172, Training Loss: 0.005627426205386343\n",
      "Validation Accuracy after epoch 172: 70.76%\n",
      "Epoch: 173, Training Loss: 0.0055657339668201515\n",
      "Validation Accuracy after epoch 173: 70.67999999999999%\n",
      "Epoch: 174, Training Loss: 0.0055113688946160895\n",
      "Validation Accuracy after epoch 174: 70.85000000000001%\n",
      "Epoch: 175, Training Loss: 0.005446922220408802\n",
      "Validation Accuracy after epoch 175: 70.62%\n",
      "Epoch: 176, Training Loss: 0.005397449402362489\n",
      "Validation Accuracy after epoch 176: 70.66%\n",
      "Epoch: 177, Training Loss: 0.005343790834202715\n",
      "Validation Accuracy after epoch 177: 70.7%\n",
      "Epoch: 178, Training Loss: 0.0052940969229163725\n",
      "Validation Accuracy after epoch 178: 70.7%\n",
      "Epoch: 179, Training Loss: 0.005240789557452244\n",
      "Validation Accuracy after epoch 179: 70.78999999999999%\n",
      "Epoch: 180, Training Loss: 0.00519126568339727\n",
      "Validation Accuracy after epoch 180: 70.7%\n",
      "Epoch: 181, Training Loss: 0.005139305119050186\n",
      "Validation Accuracy after epoch 181: 70.72%\n",
      "Epoch: 182, Training Loss: 0.005095577627287039\n",
      "Validation Accuracy after epoch 182: 70.58%\n",
      "Epoch: 183, Training Loss: 0.005042848959410339\n",
      "Validation Accuracy after epoch 183: 70.7%\n",
      "Epoch: 184, Training Loss: 0.004995597195942574\n",
      "Validation Accuracy after epoch 184: 70.69%\n",
      "Epoch: 185, Training Loss: 0.004949720772018994\n",
      "Validation Accuracy after epoch 185: 70.69%\n",
      "Epoch: 186, Training Loss: 0.00490154288536476\n",
      "Validation Accuracy after epoch 186: 70.77%\n",
      "Epoch: 187, Training Loss: 0.00486436654168093\n",
      "Validation Accuracy after epoch 187: 70.7%\n",
      "Epoch: 188, Training Loss: 0.004815826143669274\n",
      "Validation Accuracy after epoch 188: 70.82000000000001%\n",
      "Epoch: 189, Training Loss: 0.004773524194441336\n",
      "Validation Accuracy after epoch 189: 70.83%\n",
      "Epoch: 190, Training Loss: 0.004727727067811638\n",
      "Validation Accuracy after epoch 190: 70.76%\n",
      "Epoch: 191, Training Loss: 0.00468486768688978\n",
      "Validation Accuracy after epoch 191: 70.81%\n",
      "Epoch: 192, Training Loss: 0.004645304820771851\n",
      "Validation Accuracy after epoch 192: 70.67999999999999%\n",
      "Epoch: 193, Training Loss: 0.004604299087077379\n",
      "Validation Accuracy after epoch 193: 70.74000000000001%\n",
      "Epoch: 194, Training Loss: 0.0045640446555912685\n",
      "Validation Accuracy after epoch 194: 70.78999999999999%\n",
      "Epoch: 195, Training Loss: 0.004524316341268456\n",
      "Validation Accuracy after epoch 195: 70.74000000000001%\n",
      "Epoch: 196, Training Loss: 0.004482118260708478\n",
      "Validation Accuracy after epoch 196: 70.78%\n",
      "Epoch: 197, Training Loss: 0.004444622523699175\n",
      "Validation Accuracy after epoch 197: 70.69%\n",
      "Epoch: 198, Training Loss: 0.004409424905531832\n",
      "Validation Accuracy after epoch 198: 70.85000000000001%\n",
      "Epoch: 199, Training Loss: 0.004372400605022107\n",
      "Validation Accuracy after epoch 199: 70.72%\n",
      "Epoch: 200, Training Loss: 0.004332221491271844\n",
      "Validation Accuracy after epoch 200: 70.65%\n",
      "Epoch: 201, Training Loss: 0.004298255652310731\n",
      "Validation Accuracy after epoch 201: 70.78999999999999%\n",
      "Epoch: 202, Training Loss: 0.004261601921718787\n",
      "Validation Accuracy after epoch 202: 70.74000000000001%\n",
      "Epoch: 203, Training Loss: 0.004223370771852734\n",
      "Validation Accuracy after epoch 203: 70.76%\n",
      "Epoch: 204, Training Loss: 0.004194969144028128\n",
      "Validation Accuracy after epoch 204: 70.71%\n",
      "Epoch: 205, Training Loss: 0.004159367124340437\n",
      "Validation Accuracy after epoch 205: 70.82000000000001%\n",
      "Epoch: 206, Training Loss: 0.004127128228075955\n",
      "Validation Accuracy after epoch 206: 70.76%\n",
      "Epoch: 207, Training Loss: 0.0040929062027588985\n",
      "Validation Accuracy after epoch 207: 70.72%\n",
      "Epoch: 208, Training Loss: 0.004060958252798128\n",
      "Validation Accuracy after epoch 208: 70.75%\n",
      "Epoch: 209, Training Loss: 0.004028403053126867\n",
      "Validation Accuracy after epoch 209: 70.73%\n",
      "Epoch: 210, Training Loss: 0.003998057399888325\n",
      "Validation Accuracy after epoch 210: 70.8%\n",
      "Epoch: 211, Training Loss: 0.0039690880705138\n",
      "Validation Accuracy after epoch 211: 70.78%\n",
      "Epoch: 212, Training Loss: 0.003934952388743839\n",
      "Validation Accuracy after epoch 212: 70.75%\n",
      "Epoch: 213, Training Loss: 0.00390474425683565\n",
      "Validation Accuracy after epoch 213: 70.76%\n",
      "Epoch: 214, Training Loss: 0.0038765287306636114\n",
      "Validation Accuracy after epoch 214: 70.8%\n",
      "Epoch: 215, Training Loss: 0.003848103846571006\n",
      "Validation Accuracy after epoch 215: 70.76%\n",
      "Epoch: 216, Training Loss: 0.00382107775092668\n",
      "Validation Accuracy after epoch 216: 70.86%\n",
      "Epoch: 217, Training Loss: 0.003788146529468181\n",
      "Validation Accuracy after epoch 217: 70.76%\n",
      "Epoch: 218, Training Loss: 0.0037606439777695196\n",
      "Validation Accuracy after epoch 218: 70.78999999999999%\n",
      "Epoch: 219, Training Loss: 0.0037366565110881233\n",
      "Validation Accuracy after epoch 219: 70.82000000000001%\n",
      "Epoch: 220, Training Loss: 0.0037058031526179818\n",
      "Validation Accuracy after epoch 220: 70.78999999999999%\n",
      "Epoch: 221, Training Loss: 0.0036778526338677175\n",
      "Validation Accuracy after epoch 221: 70.84%\n",
      "Epoch: 222, Training Loss: 0.0036527252326721844\n",
      "Validation Accuracy after epoch 222: 70.78%\n",
      "Epoch: 223, Training Loss: 0.003624861768019312\n",
      "Validation Accuracy after epoch 223: 70.78999999999999%\n",
      "Epoch: 224, Training Loss: 0.0036019558304935086\n",
      "Validation Accuracy after epoch 224: 70.75%\n",
      "Epoch: 225, Training Loss: 0.003576769428911245\n",
      "Validation Accuracy after epoch 225: 70.84%\n",
      "Epoch: 226, Training Loss: 0.003551172372281237\n",
      "Validation Accuracy after epoch 226: 70.84%\n",
      "Epoch: 227, Training Loss: 0.003524234203998085\n",
      "Validation Accuracy after epoch 227: 70.93%\n",
      "Epoch: 228, Training Loss: 0.00350004747328932\n",
      "Validation Accuracy after epoch 228: 70.82000000000001%\n",
      "Epoch: 229, Training Loss: 0.0034780718521346026\n",
      "Validation Accuracy after epoch 229: 70.74000000000001%\n",
      "Epoch: 230, Training Loss: 0.003453910496988622\n",
      "Validation Accuracy after epoch 230: 70.77%\n",
      "Epoch: 231, Training Loss: 0.0034296519633339683\n",
      "Validation Accuracy after epoch 231: 70.87%\n",
      "Epoch: 232, Training Loss: 0.003406916690223357\n",
      "Validation Accuracy after epoch 232: 70.78%\n",
      "Epoch: 233, Training Loss: 0.0033829122358370965\n",
      "Validation Accuracy after epoch 233: 70.8%\n",
      "Epoch: 234, Training Loss: 0.003357695780790952\n",
      "Validation Accuracy after epoch 234: 70.83%\n",
      "Epoch: 235, Training Loss: 0.003335672476247925\n",
      "Validation Accuracy after epoch 235: 70.82000000000001%\n",
      "Epoch: 236, Training Loss: 0.0033183627354893405\n",
      "Validation Accuracy after epoch 236: 70.83%\n",
      "Epoch: 237, Training Loss: 0.0032935079221096835\n",
      "Validation Accuracy after epoch 237: 70.93%\n",
      "Epoch: 238, Training Loss: 0.0032710156095621494\n",
      "Validation Accuracy after epoch 238: 70.82000000000001%\n",
      "Epoch: 239, Training Loss: 0.0032489070099542667\n",
      "Validation Accuracy after epoch 239: 70.95%\n",
      "Epoch: 240, Training Loss: 0.003229629168140433\n",
      "Validation Accuracy after epoch 240: 70.89999999999999%\n",
      "Epoch: 241, Training Loss: 0.0032090998375002306\n",
      "Validation Accuracy after epoch 241: 70.86%\n",
      "Epoch: 242, Training Loss: 0.0031882892221348157\n",
      "Validation Accuracy after epoch 242: 70.91%\n",
      "Epoch: 243, Training Loss: 0.0031663598291768844\n",
      "Validation Accuracy after epoch 243: 70.83%\n",
      "Epoch: 244, Training Loss: 0.0031490961477979827\n",
      "Validation Accuracy after epoch 244: 70.87%\n",
      "Epoch: 245, Training Loss: 0.003128135150335396\n",
      "Validation Accuracy after epoch 245: 70.89999999999999%\n",
      "Epoch: 246, Training Loss: 0.0031086995952364885\n",
      "Validation Accuracy after epoch 246: 70.96000000000001%\n",
      "Epoch: 247, Training Loss: 0.003089278119245825\n",
      "Validation Accuracy after epoch 247: 70.88%\n",
      "Epoch: 248, Training Loss: 0.0030671080763158783\n",
      "Validation Accuracy after epoch 248: 70.8%\n",
      "Epoch: 249, Training Loss: 0.0030512412550890117\n",
      "Validation Accuracy after epoch 249: 70.88%\n",
      "Epoch: 250, Training Loss: 0.0030307678323860765\n",
      "Validation Accuracy after epoch 250: 70.87%\n",
      "Epoch: 251, Training Loss: 0.003012124299550491\n",
      "Validation Accuracy after epoch 251: 70.93%\n",
      "Epoch: 252, Training Loss: 0.002993505404186685\n",
      "Validation Accuracy after epoch 252: 70.86%\n",
      "Epoch: 253, Training Loss: 0.0029762894590444804\n",
      "Validation Accuracy after epoch 253: 70.83%\n",
      "Epoch: 254, Training Loss: 0.0029578338281306274\n",
      "Validation Accuracy after epoch 254: 70.89%\n",
      "Epoch: 255, Training Loss: 0.002940339797004924\n",
      "Validation Accuracy after epoch 255: 70.84%\n",
      "Epoch: 256, Training Loss: 0.002924067609439678\n",
      "Validation Accuracy after epoch 256: 70.93%\n",
      "Epoch: 257, Training Loss: 0.002909371303483758\n",
      "Validation Accuracy after epoch 257: 70.91%\n",
      "Epoch: 258, Training Loss: 0.002889112088545833\n",
      "Validation Accuracy after epoch 258: 70.91%\n",
      "Epoch: 259, Training Loss: 0.0028716257845987675\n",
      "Validation Accuracy after epoch 259: 70.81%\n",
      "Epoch: 260, Training Loss: 0.0028544336449011893\n",
      "Validation Accuracy after epoch 260: 70.89%\n",
      "Epoch: 261, Training Loss: 0.0028382053591615862\n",
      "Validation Accuracy after epoch 261: 70.87%\n",
      "Epoch: 262, Training Loss: 0.0028215533539550403\n",
      "Validation Accuracy after epoch 262: 70.89999999999999%\n",
      "Epoch: 263, Training Loss: 0.002804958106130552\n",
      "Validation Accuracy after epoch 263: 70.82000000000001%\n",
      "Epoch: 264, Training Loss: 0.0027890290519820473\n",
      "Validation Accuracy after epoch 264: 70.94%\n",
      "Epoch: 265, Training Loss: 0.002773781015556734\n",
      "Validation Accuracy after epoch 265: 70.89999999999999%\n",
      "Epoch: 266, Training Loss: 0.0027577519067563117\n",
      "Validation Accuracy after epoch 266: 70.98%\n",
      "Epoch: 267, Training Loss: 0.0027431080634693814\n",
      "Validation Accuracy after epoch 267: 70.8%\n",
      "Epoch: 268, Training Loss: 0.002725690302243718\n",
      "Validation Accuracy after epoch 268: 70.87%\n",
      "Epoch: 269, Training Loss: 0.0027105723779536593\n",
      "Validation Accuracy after epoch 269: 70.88%\n",
      "Epoch: 270, Training Loss: 0.002695752803207663\n",
      "Validation Accuracy after epoch 270: 70.87%\n",
      "Epoch: 271, Training Loss: 0.002681663218180618\n",
      "Validation Accuracy after epoch 271: 70.89999999999999%\n",
      "Epoch: 272, Training Loss: 0.0026638779721920715\n",
      "Validation Accuracy after epoch 272: 70.89%\n",
      "Epoch: 273, Training Loss: 0.0026513312541631994\n",
      "Validation Accuracy after epoch 273: 70.78999999999999%\n",
      "Epoch: 274, Training Loss: 0.0026367594150926376\n",
      "Validation Accuracy after epoch 274: 70.84%\n",
      "Epoch: 275, Training Loss: 0.002623741026095989\n",
      "Validation Accuracy after epoch 275: 70.97%\n",
      "Epoch: 276, Training Loss: 0.0026088032877141765\n",
      "Validation Accuracy after epoch 276: 70.91%\n",
      "Epoch: 277, Training Loss: 0.0025949674886841887\n",
      "Validation Accuracy after epoch 277: 70.89999999999999%\n",
      "Epoch: 278, Training Loss: 0.0025831679541134106\n",
      "Validation Accuracy after epoch 278: 70.91%\n",
      "Epoch: 279, Training Loss: 0.0025674966303869855\n",
      "Validation Accuracy after epoch 279: 70.93%\n",
      "Epoch: 280, Training Loss: 0.002553848581879264\n",
      "Validation Accuracy after epoch 280: 70.91%\n",
      "Epoch: 281, Training Loss: 0.0025407092619265724\n",
      "Validation Accuracy after epoch 281: 70.85000000000001%\n",
      "Epoch: 282, Training Loss: 0.0025257710309382385\n",
      "Validation Accuracy after epoch 282: 70.95%\n",
      "Epoch: 283, Training Loss: 0.002513538450574326\n",
      "Validation Accuracy after epoch 283: 70.93%\n",
      "Epoch: 284, Training Loss: 0.002499715075828135\n",
      "Validation Accuracy after epoch 284: 70.91%\n",
      "Epoch: 285, Training Loss: 0.0024870000059104254\n",
      "Validation Accuracy after epoch 285: 70.96000000000001%\n",
      "Epoch: 286, Training Loss: 0.0024727384318345134\n",
      "Validation Accuracy after epoch 286: 70.91%\n",
      "Epoch: 287, Training Loss: 0.002461541507034646\n",
      "Validation Accuracy after epoch 287: 70.83%\n",
      "Epoch: 288, Training Loss: 0.002448820216042916\n",
      "Validation Accuracy after epoch 288: 70.93%\n",
      "Epoch: 289, Training Loss: 0.002434906630438593\n",
      "Validation Accuracy after epoch 289: 70.87%\n",
      "Epoch: 290, Training Loss: 0.0024231535299500105\n",
      "Validation Accuracy after epoch 290: 70.89999999999999%\n",
      "Epoch: 291, Training Loss: 0.0024107635672361402\n",
      "Validation Accuracy after epoch 291: 70.94%\n",
      "Epoch: 292, Training Loss: 0.0023984235318084642\n",
      "Validation Accuracy after epoch 292: 70.91%\n",
      "Epoch: 293, Training Loss: 0.0023857183594261405\n",
      "Validation Accuracy after epoch 293: 70.86%\n",
      "Epoch: 294, Training Loss: 0.0023748716072993985\n",
      "Validation Accuracy after epoch 294: 70.97%\n",
      "Epoch: 295, Training Loss: 0.0023640153332329964\n",
      "Validation Accuracy after epoch 295: 70.92%\n",
      "Epoch: 296, Training Loss: 0.002351801444971672\n",
      "Validation Accuracy after epoch 296: 70.91%\n",
      "Epoch: 297, Training Loss: 0.0023391252296352688\n",
      "Validation Accuracy after epoch 297: 70.99%\n",
      "Epoch: 298, Training Loss: 0.002326956480596205\n",
      "Validation Accuracy after epoch 298: 70.89%\n",
      "Epoch: 299, Training Loss: 0.0023171606092818576\n",
      "Validation Accuracy after epoch 299: 70.92%\n",
      "Epoch: 300, Training Loss: 0.002306229398583474\n",
      "Validation Accuracy after epoch 300: 70.92%\n",
      "Total Training Time: 1385.4300723075867 seconds\n"
     ]
    }
   ],
   "source": [
    "training_loop(\n",
    "    n_epochs=300,\n",
    "    optimizer=optimizer,\n",
    "    model=model,\n",
    "    loss_fn=loss_fn,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "82e05af5-1ce3-4d55-b3d7-f65c990262a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.act1 = nn.Tanh()\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.act2 = nn.Tanh()\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.act3 = nn.Tanh()\n",
    "        self.pool3 = nn.MaxPool2d(2)\n",
    "        self.fc1 = nn.Linear(128 * 4 * 4, 256)\n",
    "        self.act4 = nn.Tanh()\n",
    "        self.fc2 = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.pool1(self.act1(self.conv1(x)))\n",
    "        out = self.pool2(self.act2(self.conv2(out)))\n",
    "        out = self.pool3(self.act3(self.conv3(out)))\n",
    "        out = out.view(-1, 128 * 4 * 4) \n",
    "        out = self.act4(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6bc5d828-bd98-4451-a8e1-9255397f25fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-2)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e94e6198-b6a0-49ed-a154-aaf3f23ec2db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Training Loss: 2.1930723769585496\n",
      "Validation Accuracy after epoch 1: 26.61%\n",
      "Epoch: 2, Training Loss: 1.9090867981581432\n",
      "Validation Accuracy after epoch 2: 37.01%\n",
      "Epoch: 3, Training Loss: 1.7144578894995668\n",
      "Validation Accuracy after epoch 3: 41.010000000000005%\n",
      "Epoch: 4, Training Loss: 1.5864605941735874\n",
      "Validation Accuracy after epoch 4: 44.86%\n",
      "Epoch: 5, Training Loss: 1.4918663739548315\n",
      "Validation Accuracy after epoch 5: 48.59%\n",
      "Epoch: 6, Training Loss: 1.4155759745851502\n",
      "Validation Accuracy after epoch 6: 51.06%\n",
      "Epoch: 7, Training Loss: 1.3517482565796894\n",
      "Validation Accuracy after epoch 7: 50.760000000000005%\n",
      "Epoch: 8, Training Loss: 1.2963406500761465\n",
      "Validation Accuracy after epoch 8: 54.42%\n",
      "Epoch: 9, Training Loss: 1.2419960498047606\n",
      "Validation Accuracy after epoch 9: 55.83%\n",
      "Epoch: 10, Training Loss: 1.1934811812075203\n",
      "Validation Accuracy after epoch 10: 54.14%\n",
      "Epoch: 11, Training Loss: 1.1466546099051795\n",
      "Validation Accuracy after epoch 11: 59.63%\n",
      "Epoch: 12, Training Loss: 1.1037999805434586\n",
      "Validation Accuracy after epoch 12: 55.21%\n",
      "Epoch: 13, Training Loss: 1.0629081759611358\n",
      "Validation Accuracy after epoch 13: 60.419999999999995%\n",
      "Epoch: 14, Training Loss: 1.023284140602707\n",
      "Validation Accuracy after epoch 14: 61.980000000000004%\n",
      "Epoch: 15, Training Loss: 0.990454321246013\n",
      "Validation Accuracy after epoch 15: 64.49000000000001%\n",
      "Epoch: 16, Training Loss: 0.9567783645656712\n",
      "Validation Accuracy after epoch 16: 64.61%\n",
      "Epoch: 17, Training Loss: 0.9272043148574927\n",
      "Validation Accuracy after epoch 17: 66.52%\n",
      "Epoch: 18, Training Loss: 0.8983607344005419\n",
      "Validation Accuracy after epoch 18: 66.94%\n",
      "Epoch: 19, Training Loss: 0.8700400163298068\n",
      "Validation Accuracy after epoch 19: 66.25999999999999%\n",
      "Epoch: 20, Training Loss: 0.8447075004848983\n",
      "Validation Accuracy after epoch 20: 65.12%\n",
      "Epoch: 21, Training Loss: 0.8213104293169573\n",
      "Validation Accuracy after epoch 21: 66.3%\n",
      "Epoch: 22, Training Loss: 0.7999175227511569\n",
      "Validation Accuracy after epoch 22: 67.17999999999999%\n",
      "Epoch: 23, Training Loss: 0.779402722292544\n",
      "Validation Accuracy after epoch 23: 67.23%\n",
      "Epoch: 24, Training Loss: 0.7559465097496881\n",
      "Validation Accuracy after epoch 24: 62.78%\n",
      "Epoch: 25, Training Loss: 0.7357694739499665\n",
      "Validation Accuracy after epoch 25: 65.66%\n",
      "Epoch: 26, Training Loss: 0.715723269468988\n",
      "Validation Accuracy after epoch 26: 67.74%\n",
      "Epoch: 27, Training Loss: 0.6949113055187113\n",
      "Validation Accuracy after epoch 27: 69.03%\n",
      "Epoch: 28, Training Loss: 0.6780241146645583\n",
      "Validation Accuracy after epoch 28: 69.52000000000001%\n",
      "Epoch: 29, Training Loss: 0.6599235200820981\n",
      "Validation Accuracy after epoch 29: 71.26%\n",
      "Epoch: 30, Training Loss: 0.6406837890443899\n",
      "Validation Accuracy after epoch 30: 70.07%\n",
      "Epoch: 31, Training Loss: 0.6215189166005005\n",
      "Validation Accuracy after epoch 31: 71.41999999999999%\n",
      "Epoch: 32, Training Loss: 0.6060666938114654\n",
      "Validation Accuracy after epoch 32: 68.4%\n",
      "Epoch: 33, Training Loss: 0.587788043386491\n",
      "Validation Accuracy after epoch 33: 70.65%\n",
      "Epoch: 34, Training Loss: 0.5714416491710926\n",
      "Validation Accuracy after epoch 34: 70.87%\n",
      "Epoch: 35, Training Loss: 0.5539682617272867\n",
      "Validation Accuracy after epoch 35: 72.15%\n",
      "Epoch: 36, Training Loss: 0.5366784443559549\n",
      "Validation Accuracy after epoch 36: 71.87%\n",
      "Epoch: 37, Training Loss: 0.5193894210907505\n",
      "Validation Accuracy after epoch 37: 72.06%\n",
      "Epoch: 38, Training Loss: 0.502695668841262\n",
      "Validation Accuracy after epoch 38: 71.98%\n",
      "Epoch: 39, Training Loss: 0.487032945294057\n",
      "Validation Accuracy after epoch 39: 71.78999999999999%\n",
      "Epoch: 40, Training Loss: 0.47073702409368035\n",
      "Validation Accuracy after epoch 40: 70.86%\n",
      "Epoch: 41, Training Loss: 0.4537825977139156\n",
      "Validation Accuracy after epoch 41: 71.02000000000001%\n",
      "Epoch: 42, Training Loss: 0.4372287098785191\n",
      "Validation Accuracy after epoch 42: 72.41%\n",
      "Epoch: 43, Training Loss: 0.42174197500928895\n",
      "Validation Accuracy after epoch 43: 73.15%\n",
      "Epoch: 44, Training Loss: 0.40501892296097164\n",
      "Validation Accuracy after epoch 44: 73.11%\n",
      "Epoch: 45, Training Loss: 0.3909721232550528\n",
      "Validation Accuracy after epoch 45: 72.83%\n",
      "Epoch: 46, Training Loss: 0.37385654344659325\n",
      "Validation Accuracy after epoch 46: 71.25%\n",
      "Epoch: 47, Training Loss: 0.35806306007573063\n",
      "Validation Accuracy after epoch 47: 71.34%\n",
      "Epoch: 48, Training Loss: 0.3437918038262278\n",
      "Validation Accuracy after epoch 48: 73.27%\n",
      "Epoch: 49, Training Loss: 0.3280006141385154\n",
      "Validation Accuracy after epoch 49: 72.71%\n",
      "Epoch: 50, Training Loss: 0.3144403028366206\n",
      "Validation Accuracy after epoch 50: 71.57%\n",
      "Epoch: 51, Training Loss: 0.30056844562139656\n",
      "Validation Accuracy after epoch 51: 72.83%\n",
      "Epoch: 52, Training Loss: 0.28592071428780663\n",
      "Validation Accuracy after epoch 52: 70.73%\n",
      "Epoch: 53, Training Loss: 0.2711781455332513\n",
      "Validation Accuracy after epoch 53: 72.08%\n",
      "Epoch: 54, Training Loss: 0.2578520742161652\n",
      "Validation Accuracy after epoch 54: 72.28999999999999%\n",
      "Epoch: 55, Training Loss: 0.2451284989581236\n",
      "Validation Accuracy after epoch 55: 72.99%\n",
      "Epoch: 56, Training Loss: 0.23307478532690526\n",
      "Validation Accuracy after epoch 56: 72.61999999999999%\n",
      "Epoch: 57, Training Loss: 0.2196597834510724\n",
      "Validation Accuracy after epoch 57: 73.08%\n",
      "Epoch: 58, Training Loss: 0.20754925722775558\n",
      "Validation Accuracy after epoch 58: 73.07000000000001%\n",
      "Epoch: 59, Training Loss: 0.19659902450754818\n",
      "Validation Accuracy after epoch 59: 72.00999999999999%\n",
      "Epoch: 60, Training Loss: 0.185103016588694\n",
      "Validation Accuracy after epoch 60: 73.48%\n",
      "Epoch: 61, Training Loss: 0.17357679700378872\n",
      "Validation Accuracy after epoch 61: 73.05%\n",
      "Epoch: 62, Training Loss: 0.16319255342187783\n",
      "Validation Accuracy after epoch 62: 73.21%\n",
      "Epoch: 63, Training Loss: 0.15367600449439509\n",
      "Validation Accuracy after epoch 63: 71.97%\n",
      "Epoch: 64, Training Loss: 0.1449577083996952\n",
      "Validation Accuracy after epoch 64: 72.68%\n",
      "Epoch: 65, Training Loss: 0.13578466066847678\n",
      "Validation Accuracy after epoch 65: 73.34%\n",
      "Epoch: 66, Training Loss: 0.127046103110475\n",
      "Validation Accuracy after epoch 66: 73.05%\n",
      "Epoch: 67, Training Loss: 0.11896853131787552\n",
      "Validation Accuracy after epoch 67: 72.99%\n",
      "Epoch: 68, Training Loss: 0.11099472776283999\n",
      "Validation Accuracy after epoch 68: 71.34%\n",
      "Epoch: 69, Training Loss: 0.10482565071576697\n",
      "Validation Accuracy after epoch 69: 71.67%\n",
      "Epoch: 70, Training Loss: 0.09691732152915367\n",
      "Validation Accuracy after epoch 70: 72.31%\n",
      "Epoch: 71, Training Loss: 0.09173084002064394\n",
      "Validation Accuracy after epoch 71: 73.07000000000001%\n",
      "Epoch: 72, Training Loss: 0.08480412045927227\n",
      "Validation Accuracy after epoch 72: 72.98%\n",
      "Epoch: 73, Training Loss: 0.07952221522293508\n",
      "Validation Accuracy after epoch 73: 71.53%\n",
      "Epoch: 74, Training Loss: 0.07465206378418238\n",
      "Validation Accuracy after epoch 74: 73.32%\n",
      "Epoch: 75, Training Loss: 0.06916904863436966\n",
      "Validation Accuracy after epoch 75: 72.72999999999999%\n",
      "Epoch: 76, Training Loss: 0.06604244611928682\n",
      "Validation Accuracy after epoch 76: 73.03%\n",
      "Epoch: 77, Training Loss: 0.06117130699746139\n",
      "Validation Accuracy after epoch 77: 73.22999999999999%\n",
      "Epoch: 78, Training Loss: 0.05743547000915117\n",
      "Validation Accuracy after epoch 78: 73.22999999999999%\n",
      "Epoch: 79, Training Loss: 0.054008468644945976\n",
      "Validation Accuracy after epoch 79: 73.35000000000001%\n",
      "Epoch: 80, Training Loss: 0.05104451905936003\n",
      "Validation Accuracy after epoch 80: 72.96000000000001%\n",
      "Epoch: 81, Training Loss: 0.04802015225124329\n",
      "Validation Accuracy after epoch 81: 72.37%\n",
      "Epoch: 82, Training Loss: 0.04540272784250243\n",
      "Validation Accuracy after epoch 82: 72.96000000000001%\n",
      "Epoch: 83, Training Loss: 0.042832920180104886\n",
      "Validation Accuracy after epoch 83: 73.13%\n",
      "Epoch: 84, Training Loss: 0.040590382778964686\n",
      "Validation Accuracy after epoch 84: 73.19%\n",
      "Epoch: 85, Training Loss: 0.03840913499950829\n",
      "Validation Accuracy after epoch 85: 73.5%\n",
      "Epoch: 86, Training Loss: 0.036442653127157554\n",
      "Validation Accuracy after epoch 86: 73.02%\n",
      "Epoch: 87, Training Loss: 0.034613148256888625\n",
      "Validation Accuracy after epoch 87: 73.26%\n",
      "Epoch: 88, Training Loss: 0.033051349908647026\n",
      "Validation Accuracy after epoch 88: 72.94%\n",
      "Epoch: 89, Training Loss: 0.031500692394754996\n",
      "Validation Accuracy after epoch 89: 73.28%\n",
      "Epoch: 90, Training Loss: 0.03008994010998808\n",
      "Validation Accuracy after epoch 90: 73.02%\n",
      "Epoch: 91, Training Loss: 0.02875665081617282\n",
      "Validation Accuracy after epoch 91: 73.36%\n",
      "Epoch: 92, Training Loss: 0.02754849981507072\n",
      "Validation Accuracy after epoch 92: 73.09%\n",
      "Epoch: 93, Training Loss: 0.026266868421545877\n",
      "Validation Accuracy after epoch 93: 73.36%\n",
      "Epoch: 94, Training Loss: 0.025301097331287534\n",
      "Validation Accuracy after epoch 94: 73.22%\n",
      "Epoch: 95, Training Loss: 0.024230037524086208\n",
      "Validation Accuracy after epoch 95: 73.29%\n",
      "Epoch: 96, Training Loss: 0.02331989796479683\n",
      "Validation Accuracy after epoch 96: 73.11%\n",
      "Epoch: 97, Training Loss: 0.022521740034022523\n",
      "Validation Accuracy after epoch 97: 73.1%\n",
      "Epoch: 98, Training Loss: 0.02171790800021623\n",
      "Validation Accuracy after epoch 98: 73.33%\n",
      "Epoch: 99, Training Loss: 0.020877403450076996\n",
      "Validation Accuracy after epoch 99: 73.24000000000001%\n",
      "Epoch: 100, Training Loss: 0.02016575233486798\n",
      "Validation Accuracy after epoch 100: 73.19%\n",
      "Epoch: 101, Training Loss: 0.019479162064488128\n",
      "Validation Accuracy after epoch 101: 73.28%\n",
      "Epoch: 102, Training Loss: 0.01885566915697454\n",
      "Validation Accuracy after epoch 102: 73.19%\n",
      "Epoch: 103, Training Loss: 0.018157851750083515\n",
      "Validation Accuracy after epoch 103: 73.21%\n",
      "Epoch: 104, Training Loss: 0.017590578149437257\n",
      "Validation Accuracy after epoch 104: 73.36%\n",
      "Epoch: 105, Training Loss: 0.017102562981393295\n",
      "Validation Accuracy after epoch 105: 73.29%\n",
      "Epoch: 106, Training Loss: 0.01645352087719628\n",
      "Validation Accuracy after epoch 106: 73.47%\n",
      "Epoch: 107, Training Loss: 0.016046687606317195\n",
      "Validation Accuracy after epoch 107: 73.31%\n",
      "Epoch: 108, Training Loss: 0.015554475008517199\n",
      "Validation Accuracy after epoch 108: 73.21%\n",
      "Epoch: 109, Training Loss: 0.015165692805062475\n",
      "Validation Accuracy after epoch 109: 73.5%\n",
      "Epoch: 110, Training Loss: 0.014704909382264137\n",
      "Validation Accuracy after epoch 110: 73.33%\n",
      "Epoch: 111, Training Loss: 0.014281760106253845\n",
      "Validation Accuracy after epoch 111: 73.33%\n",
      "Epoch: 112, Training Loss: 0.013951691627369055\n",
      "Validation Accuracy after epoch 112: 73.31%\n",
      "Epoch: 113, Training Loss: 0.01356839172570678\n",
      "Validation Accuracy after epoch 113: 73.22999999999999%\n",
      "Epoch: 114, Training Loss: 0.013211089665132106\n",
      "Validation Accuracy after epoch 114: 73.19%\n",
      "Epoch: 115, Training Loss: 0.012866915106568533\n",
      "Validation Accuracy after epoch 115: 73.27%\n",
      "Epoch: 116, Training Loss: 0.01256040417853638\n",
      "Validation Accuracy after epoch 116: 73.18%\n",
      "Epoch: 117, Training Loss: 0.012265499603822637\n",
      "Validation Accuracy after epoch 117: 73.35000000000001%\n",
      "Epoch: 118, Training Loss: 0.011957458160279313\n",
      "Validation Accuracy after epoch 118: 73.47%\n",
      "Epoch: 119, Training Loss: 0.011711144934782324\n",
      "Validation Accuracy after epoch 119: 73.34%\n",
      "Epoch: 120, Training Loss: 0.011409687513695158\n",
      "Validation Accuracy after epoch 120: 73.31%\n",
      "Epoch: 121, Training Loss: 0.011098804181594106\n",
      "Validation Accuracy after epoch 121: 73.34%\n",
      "Epoch: 122, Training Loss: 0.010910597996657613\n",
      "Validation Accuracy after epoch 122: 73.25%\n",
      "Epoch: 123, Training Loss: 0.010675818472981567\n",
      "Validation Accuracy after epoch 123: 73.28%\n",
      "Epoch: 124, Training Loss: 0.010416704231796935\n",
      "Validation Accuracy after epoch 124: 73.11999999999999%\n",
      "Epoch: 125, Training Loss: 0.010229928601804711\n",
      "Validation Accuracy after epoch 125: 73.17%\n",
      "Epoch: 126, Training Loss: 0.009989045078025373\n",
      "Validation Accuracy after epoch 126: 73.32%\n",
      "Epoch: 127, Training Loss: 0.009798455548108272\n",
      "Validation Accuracy after epoch 127: 73.18%\n",
      "Epoch: 128, Training Loss: 0.009575420684512238\n",
      "Validation Accuracy after epoch 128: 73.27%\n",
      "Epoch: 129, Training Loss: 0.00940295214266957\n",
      "Validation Accuracy after epoch 129: 73.28%\n",
      "Epoch: 130, Training Loss: 0.009233422806638929\n",
      "Validation Accuracy after epoch 130: 73.28%\n",
      "Epoch: 131, Training Loss: 0.009072200503543286\n",
      "Validation Accuracy after epoch 131: 73.22%\n",
      "Epoch: 132, Training Loss: 0.00886759841088158\n",
      "Validation Accuracy after epoch 132: 73.47%\n",
      "Epoch: 133, Training Loss: 0.008708065773462852\n",
      "Validation Accuracy after epoch 133: 73.31%\n",
      "Epoch: 134, Training Loss: 0.008544631644754726\n",
      "Validation Accuracy after epoch 134: 73.27%\n",
      "Epoch: 135, Training Loss: 0.008399450271973944\n",
      "Validation Accuracy after epoch 135: 73.04%\n",
      "Epoch: 136, Training Loss: 0.008227608330390605\n",
      "Validation Accuracy after epoch 136: 73.41%\n",
      "Epoch: 137, Training Loss: 0.00809076078780367\n",
      "Validation Accuracy after epoch 137: 73.15%\n",
      "Epoch: 138, Training Loss: 0.007947678494331476\n",
      "Validation Accuracy after epoch 138: 73.42%\n",
      "Epoch: 139, Training Loss: 0.007823588806526054\n",
      "Validation Accuracy after epoch 139: 73.19%\n",
      "Epoch: 140, Training Loss: 0.00768496295171635\n",
      "Validation Accuracy after epoch 140: 73.34%\n",
      "Epoch: 141, Training Loss: 0.0075568283313785295\n",
      "Validation Accuracy after epoch 141: 73.14%\n",
      "Epoch: 142, Training Loss: 0.007426847675172112\n",
      "Validation Accuracy after epoch 142: 73.09%\n",
      "Epoch: 143, Training Loss: 0.007316814555996158\n",
      "Validation Accuracy after epoch 143: 73.16%\n",
      "Epoch: 144, Training Loss: 0.007183440068624723\n",
      "Validation Accuracy after epoch 144: 73.2%\n",
      "Epoch: 145, Training Loss: 0.007087655578349309\n",
      "Validation Accuracy after epoch 145: 73.48%\n",
      "Epoch: 146, Training Loss: 0.006959549671805957\n",
      "Validation Accuracy after epoch 146: 73.09%\n",
      "Epoch: 147, Training Loss: 0.0068535266210065435\n",
      "Validation Accuracy after epoch 147: 73.21%\n",
      "Epoch: 148, Training Loss: 0.0067508341914252435\n",
      "Validation Accuracy after epoch 148: 73.3%\n",
      "Epoch: 149, Training Loss: 0.00664609652119772\n",
      "Validation Accuracy after epoch 149: 73.11%\n",
      "Epoch: 150, Training Loss: 0.006540814824009319\n",
      "Validation Accuracy after epoch 150: 73.17%\n",
      "Epoch: 151, Training Loss: 0.006441664325533068\n",
      "Validation Accuracy after epoch 151: 73.2%\n",
      "Epoch: 152, Training Loss: 0.006357521031592565\n",
      "Validation Accuracy after epoch 152: 73.21%\n",
      "Epoch: 153, Training Loss: 0.00627910434786478\n",
      "Validation Accuracy after epoch 153: 73.02%\n",
      "Epoch: 154, Training Loss: 0.0061614615035831665\n",
      "Validation Accuracy after epoch 154: 73.22999999999999%\n",
      "Epoch: 155, Training Loss: 0.006078490792699825\n",
      "Validation Accuracy after epoch 155: 73.29%\n",
      "Epoch: 156, Training Loss: 0.006003508070969711\n",
      "Validation Accuracy after epoch 156: 73.21%\n",
      "Epoch: 157, Training Loss: 0.005922198659726097\n",
      "Validation Accuracy after epoch 157: 73.34%\n",
      "Epoch: 158, Training Loss: 0.0058402737821130766\n",
      "Validation Accuracy after epoch 158: 73.27%\n",
      "Epoch: 159, Training Loss: 0.005754594308505182\n",
      "Validation Accuracy after epoch 159: 73.22%\n",
      "Epoch: 160, Training Loss: 0.005688120931972895\n",
      "Validation Accuracy after epoch 160: 73.22%\n",
      "Epoch: 161, Training Loss: 0.0056092665358649\n",
      "Validation Accuracy after epoch 161: 73.2%\n",
      "Epoch: 162, Training Loss: 0.0055357547729369015\n",
      "Validation Accuracy after epoch 162: 73.29%\n",
      "Epoch: 163, Training Loss: 0.005466621796078885\n",
      "Validation Accuracy after epoch 163: 73.15%\n",
      "Epoch: 164, Training Loss: 0.00540252223633506\n",
      "Validation Accuracy after epoch 164: 73.33%\n",
      "Epoch: 165, Training Loss: 0.005330295625614369\n",
      "Validation Accuracy after epoch 165: 73.27%\n",
      "Epoch: 166, Training Loss: 0.005261868831244252\n",
      "Validation Accuracy after epoch 166: 73.34%\n",
      "Epoch: 167, Training Loss: 0.005195242488254195\n",
      "Validation Accuracy after epoch 167: 73.3%\n",
      "Epoch: 168, Training Loss: 0.005134993507896009\n",
      "Validation Accuracy after epoch 168: 73.28%\n",
      "Epoch: 169, Training Loss: 0.005066159897355263\n",
      "Validation Accuracy after epoch 169: 73.26%\n",
      "Epoch: 170, Training Loss: 0.005003502206576755\n",
      "Validation Accuracy after epoch 170: 73.3%\n",
      "Epoch: 171, Training Loss: 0.004948973979043495\n",
      "Validation Accuracy after epoch 171: 73.31%\n",
      "Epoch: 172, Training Loss: 0.004889746887914246\n",
      "Validation Accuracy after epoch 172: 73.29%\n",
      "Epoch: 173, Training Loss: 0.004828895303739897\n",
      "Validation Accuracy after epoch 173: 73.37%\n",
      "Epoch: 174, Training Loss: 0.004777261007474759\n",
      "Validation Accuracy after epoch 174: 73.39%\n",
      "Epoch: 175, Training Loss: 0.004713624912609473\n",
      "Validation Accuracy after epoch 175: 73.34%\n",
      "Epoch: 176, Training Loss: 0.004662679275497794\n",
      "Validation Accuracy after epoch 176: 73.22999999999999%\n",
      "Epoch: 177, Training Loss: 0.004613065229886023\n",
      "Validation Accuracy after epoch 177: 73.22999999999999%\n",
      "Epoch: 178, Training Loss: 0.004561247057257615\n",
      "Validation Accuracy after epoch 178: 73.22%\n",
      "Epoch: 179, Training Loss: 0.004506481465135636\n",
      "Validation Accuracy after epoch 179: 73.34%\n",
      "Epoch: 180, Training Loss: 0.004458985451753001\n",
      "Validation Accuracy after epoch 180: 73.22%\n",
      "Epoch: 181, Training Loss: 0.004409855020249172\n",
      "Validation Accuracy after epoch 181: 73.4%\n",
      "Epoch: 182, Training Loss: 0.0043616358436706\n",
      "Validation Accuracy after epoch 182: 73.38%\n",
      "Epoch: 183, Training Loss: 0.004320472452963423\n",
      "Validation Accuracy after epoch 183: 73.29%\n",
      "Epoch: 184, Training Loss: 0.00426920545269566\n",
      "Validation Accuracy after epoch 184: 73.22999999999999%\n",
      "Epoch: 185, Training Loss: 0.004224247600147239\n",
      "Validation Accuracy after epoch 185: 73.19%\n",
      "Epoch: 186, Training Loss: 0.004177330235671966\n",
      "Validation Accuracy after epoch 186: 73.26%\n",
      "Epoch: 187, Training Loss: 0.0041365097449554125\n",
      "Validation Accuracy after epoch 187: 73.27%\n",
      "Epoch: 188, Training Loss: 0.0040970769138587515\n",
      "Validation Accuracy after epoch 188: 73.3%\n",
      "Epoch: 189, Training Loss: 0.004052681620935421\n",
      "Validation Accuracy after epoch 189: 73.3%\n",
      "Epoch: 190, Training Loss: 0.004013986438405616\n",
      "Validation Accuracy after epoch 190: 73.3%\n",
      "Epoch: 191, Training Loss: 0.00397486760146449\n",
      "Validation Accuracy after epoch 191: 73.41%\n",
      "Epoch: 192, Training Loss: 0.0039316124419438775\n",
      "Validation Accuracy after epoch 192: 73.28%\n",
      "Epoch: 193, Training Loss: 0.003890848263045368\n",
      "Validation Accuracy after epoch 193: 73.31%\n",
      "Epoch: 194, Training Loss: 0.0038511682982982883\n",
      "Validation Accuracy after epoch 194: 73.21%\n",
      "Epoch: 195, Training Loss: 0.0038195036480005574\n",
      "Validation Accuracy after epoch 195: 73.24000000000001%\n",
      "Epoch: 196, Training Loss: 0.0037833602937912604\n",
      "Validation Accuracy after epoch 196: 73.07000000000001%\n",
      "Epoch: 197, Training Loss: 0.0037516535042732705\n",
      "Validation Accuracy after epoch 197: 73.41%\n",
      "Epoch: 198, Training Loss: 0.003706470166113885\n",
      "Validation Accuracy after epoch 198: 73.29%\n",
      "Epoch: 199, Training Loss: 0.0036734766353641057\n",
      "Validation Accuracy after epoch 199: 73.18%\n",
      "Epoch: 200, Training Loss: 0.0036455403439953084\n",
      "Validation Accuracy after epoch 200: 73.1%\n",
      "Epoch: 201, Training Loss: 0.003607154997569435\n",
      "Validation Accuracy after epoch 201: 73.24000000000001%\n",
      "Epoch: 202, Training Loss: 0.0035741732411427173\n",
      "Validation Accuracy after epoch 202: 73.32%\n",
      "Epoch: 203, Training Loss: 0.003540997759348539\n",
      "Validation Accuracy after epoch 203: 73.13%\n",
      "Epoch: 204, Training Loss: 0.0035132615838338005\n",
      "Validation Accuracy after epoch 204: 73.27%\n",
      "Epoch: 205, Training Loss: 0.0034765156596015348\n",
      "Validation Accuracy after epoch 205: 73.21%\n",
      "Epoch: 206, Training Loss: 0.003443433763965478\n",
      "Validation Accuracy after epoch 206: 73.22%\n",
      "Epoch: 207, Training Loss: 0.0034203118502634015\n",
      "Validation Accuracy after epoch 207: 73.36%\n",
      "Epoch: 208, Training Loss: 0.003385752542813778\n",
      "Validation Accuracy after epoch 208: 73.22999999999999%\n",
      "Epoch: 209, Training Loss: 0.003352087399716277\n",
      "Validation Accuracy after epoch 209: 73.27%\n",
      "Epoch: 210, Training Loss: 0.003328834537683469\n",
      "Validation Accuracy after epoch 210: 73.27%\n",
      "Epoch: 211, Training Loss: 0.003298089488634549\n",
      "Validation Accuracy after epoch 211: 73.3%\n",
      "Epoch: 212, Training Loss: 0.0032714216928521785\n",
      "Validation Accuracy after epoch 212: 73.29%\n",
      "Epoch: 213, Training Loss: 0.0032428251643417416\n",
      "Validation Accuracy after epoch 213: 73.2%\n",
      "Epoch: 214, Training Loss: 0.0032142283418156265\n",
      "Validation Accuracy after epoch 214: 73.22%\n",
      "Epoch: 215, Training Loss: 0.0031888244704574424\n",
      "Validation Accuracy after epoch 215: 73.21%\n",
      "Epoch: 216, Training Loss: 0.003161571739638067\n",
      "Validation Accuracy after epoch 216: 73.21%\n",
      "Epoch: 217, Training Loss: 0.003133223702609444\n",
      "Validation Accuracy after epoch 217: 73.25%\n",
      "Epoch: 218, Training Loss: 0.0031112483360201996\n",
      "Validation Accuracy after epoch 218: 73.24000000000001%\n",
      "Epoch: 219, Training Loss: 0.0030818125344705682\n",
      "Validation Accuracy after epoch 219: 73.22%\n",
      "Epoch: 220, Training Loss: 0.003062030292012493\n",
      "Validation Accuracy after epoch 220: 73.3%\n",
      "Epoch: 221, Training Loss: 0.0030354725497970096\n",
      "Validation Accuracy after epoch 221: 73.24000000000001%\n",
      "Epoch: 222, Training Loss: 0.0030094579361198124\n",
      "Validation Accuracy after epoch 222: 73.22999999999999%\n",
      "Epoch: 223, Training Loss: 0.00298588465073901\n",
      "Validation Accuracy after epoch 223: 73.27%\n",
      "Epoch: 224, Training Loss: 0.0029654029769884886\n",
      "Validation Accuracy after epoch 224: 73.15%\n",
      "Epoch: 225, Training Loss: 0.002938433838805751\n",
      "Validation Accuracy after epoch 225: 73.26%\n",
      "Epoch: 226, Training Loss: 0.0029177054166770002\n",
      "Validation Accuracy after epoch 226: 73.4%\n",
      "Epoch: 227, Training Loss: 0.0028921891625522805\n",
      "Validation Accuracy after epoch 227: 73.22999999999999%\n",
      "Epoch: 228, Training Loss: 0.002871467299876101\n",
      "Validation Accuracy after epoch 228: 73.18%\n",
      "Epoch: 229, Training Loss: 0.002852601777164318\n",
      "Validation Accuracy after epoch 229: 73.25%\n",
      "Epoch: 230, Training Loss: 0.002826947434966112\n",
      "Validation Accuracy after epoch 230: 73.19%\n",
      "Epoch: 231, Training Loss: 0.0028072675002876984\n",
      "Validation Accuracy after epoch 231: 73.24000000000001%\n",
      "Epoch: 232, Training Loss: 0.002783488736802336\n",
      "Validation Accuracy after epoch 232: 73.26%\n",
      "Epoch: 233, Training Loss: 0.00276367424774672\n",
      "Validation Accuracy after epoch 233: 73.17%\n",
      "Epoch: 234, Training Loss: 0.0027402566879561356\n",
      "Validation Accuracy after epoch 234: 73.27%\n",
      "Epoch: 235, Training Loss: 0.0027246094243886794\n",
      "Validation Accuracy after epoch 235: 73.25%\n",
      "Epoch: 236, Training Loss: 0.002702323239013229\n",
      "Validation Accuracy after epoch 236: 73.29%\n",
      "Epoch: 237, Training Loss: 0.0026823728902996675\n",
      "Validation Accuracy after epoch 237: 73.11999999999999%\n",
      "Epoch: 238, Training Loss: 0.002666068518215128\n",
      "Validation Accuracy after epoch 238: 73.24000000000001%\n",
      "Epoch: 239, Training Loss: 0.0026441209302271915\n",
      "Validation Accuracy after epoch 239: 73.2%\n",
      "Epoch: 240, Training Loss: 0.002625448069216021\n",
      "Validation Accuracy after epoch 240: 73.24000000000001%\n",
      "Epoch: 241, Training Loss: 0.0026040963345931372\n",
      "Validation Accuracy after epoch 241: 73.26%\n",
      "Epoch: 242, Training Loss: 0.0025882434622144035\n",
      "Validation Accuracy after epoch 242: 73.2%\n",
      "Epoch: 243, Training Loss: 0.0025694799230462583\n",
      "Validation Accuracy after epoch 243: 73.22%\n",
      "Epoch: 244, Training Loss: 0.002552550036848411\n",
      "Validation Accuracy after epoch 244: 73.22999999999999%\n",
      "Epoch: 245, Training Loss: 0.00253502995816662\n",
      "Validation Accuracy after epoch 245: 73.27%\n",
      "Epoch: 246, Training Loss: 0.0025162110373120553\n",
      "Validation Accuracy after epoch 246: 73.26%\n",
      "Epoch: 247, Training Loss: 0.002498834275716768\n",
      "Validation Accuracy after epoch 247: 73.2%\n",
      "Epoch: 248, Training Loss: 0.002482459293868955\n",
      "Validation Accuracy after epoch 248: 73.22999999999999%\n",
      "Epoch: 249, Training Loss: 0.00246398187155509\n",
      "Validation Accuracy after epoch 249: 73.26%\n",
      "Epoch: 250, Training Loss: 0.0024474024468356423\n",
      "Validation Accuracy after epoch 250: 73.19%\n",
      "Epoch: 251, Training Loss: 0.0024318640231085786\n",
      "Validation Accuracy after epoch 251: 73.18%\n",
      "Epoch: 252, Training Loss: 0.0024158112388259025\n",
      "Validation Accuracy after epoch 252: 73.18%\n",
      "Epoch: 253, Training Loss: 0.0023985628175306256\n",
      "Validation Accuracy after epoch 253: 73.2%\n",
      "Epoch: 254, Training Loss: 0.0023822800666891764\n",
      "Validation Accuracy after epoch 254: 73.18%\n",
      "Epoch: 255, Training Loss: 0.0023707319110574778\n",
      "Validation Accuracy after epoch 255: 73.22%\n",
      "Epoch: 256, Training Loss: 0.0023504494651592316\n",
      "Validation Accuracy after epoch 256: 73.31%\n",
      "Epoch: 257, Training Loss: 0.002337954148067795\n",
      "Validation Accuracy after epoch 257: 73.22%\n",
      "Epoch: 258, Training Loss: 0.0023202620763176827\n",
      "Validation Accuracy after epoch 258: 73.1%\n",
      "Epoch: 259, Training Loss: 0.002309428460662589\n",
      "Validation Accuracy after epoch 259: 73.2%\n",
      "Epoch: 260, Training Loss: 0.0022910293510250384\n",
      "Validation Accuracy after epoch 260: 73.29%\n",
      "Epoch: 261, Training Loss: 0.0022763683876889707\n",
      "Validation Accuracy after epoch 261: 73.19%\n",
      "Epoch: 262, Training Loss: 0.0022629473341719422\n",
      "Validation Accuracy after epoch 262: 73.22%\n",
      "Epoch: 263, Training Loss: 0.0022491072091664595\n",
      "Validation Accuracy after epoch 263: 73.22%\n",
      "Epoch: 264, Training Loss: 0.0022343638080024562\n",
      "Validation Accuracy after epoch 264: 73.28%\n",
      "Epoch: 265, Training Loss: 0.0022200122046882233\n",
      "Validation Accuracy after epoch 265: 73.14%\n",
      "Epoch: 266, Training Loss: 0.0022081086286129263\n",
      "Validation Accuracy after epoch 266: 73.21%\n",
      "Epoch: 267, Training Loss: 0.0021949087609322575\n",
      "Validation Accuracy after epoch 267: 73.19%\n",
      "Epoch: 268, Training Loss: 0.0021787305266353424\n",
      "Validation Accuracy after epoch 268: 73.3%\n",
      "Epoch: 269, Training Loss: 0.0021657559546091787\n",
      "Validation Accuracy after epoch 269: 73.25%\n",
      "Epoch: 270, Training Loss: 0.0021530916265871786\n",
      "Validation Accuracy after epoch 270: 73.19%\n",
      "Epoch: 271, Training Loss: 0.002138450616867046\n",
      "Validation Accuracy after epoch 271: 73.24000000000001%\n",
      "Epoch: 272, Training Loss: 0.0021269730878207844\n",
      "Validation Accuracy after epoch 272: 73.21%\n",
      "Epoch: 273, Training Loss: 0.0021129030014669327\n",
      "Validation Accuracy after epoch 273: 73.25%\n",
      "Epoch: 274, Training Loss: 0.0021032281208049762\n",
      "Validation Accuracy after epoch 274: 73.28%\n",
      "Epoch: 275, Training Loss: 0.0020904679840151935\n",
      "Validation Accuracy after epoch 275: 73.15%\n",
      "Epoch: 276, Training Loss: 0.002077615434748104\n",
      "Validation Accuracy after epoch 276: 73.13%\n",
      "Epoch: 277, Training Loss: 0.0020633886861966214\n",
      "Validation Accuracy after epoch 277: 73.22%\n",
      "Epoch: 278, Training Loss: 0.0020510897316071957\n",
      "Validation Accuracy after epoch 278: 73.22999999999999%\n",
      "Epoch: 279, Training Loss: 0.002038706726271926\n",
      "Validation Accuracy after epoch 279: 73.24000000000001%\n",
      "Epoch: 280, Training Loss: 0.002029141811344325\n",
      "Validation Accuracy after epoch 280: 73.18%\n",
      "Epoch: 281, Training Loss: 0.0020168295759550483\n",
      "Validation Accuracy after epoch 281: 73.22999999999999%\n",
      "Epoch: 282, Training Loss: 0.0020054756962816895\n",
      "Validation Accuracy after epoch 282: 73.2%\n",
      "Epoch: 283, Training Loss: 0.001996093375883434\n",
      "Validation Accuracy after epoch 283: 73.17%\n",
      "Epoch: 284, Training Loss: 0.0019799018202199484\n",
      "Validation Accuracy after epoch 284: 73.16%\n",
      "Epoch: 285, Training Loss: 0.0019719804961072364\n",
      "Validation Accuracy after epoch 285: 73.21%\n",
      "Epoch: 286, Training Loss: 0.0019601427306405617\n",
      "Validation Accuracy after epoch 286: 73.2%\n",
      "Epoch: 287, Training Loss: 0.0019490801983976216\n",
      "Validation Accuracy after epoch 287: 73.26%\n",
      "Epoch: 288, Training Loss: 0.0019380331363664735\n",
      "Validation Accuracy after epoch 288: 73.22999999999999%\n",
      "Epoch: 289, Training Loss: 0.001927830606533448\n",
      "Validation Accuracy after epoch 289: 73.17%\n",
      "Epoch: 290, Training Loss: 0.001915986120612706\n",
      "Validation Accuracy after epoch 290: 73.19%\n",
      "Epoch: 291, Training Loss: 0.0019079752317320109\n",
      "Validation Accuracy after epoch 291: 73.29%\n",
      "Epoch: 292, Training Loss: 0.0018965096327254686\n",
      "Validation Accuracy after epoch 292: 73.21%\n",
      "Epoch: 293, Training Loss: 0.0018850776594360847\n",
      "Validation Accuracy after epoch 293: 73.26%\n",
      "Epoch: 294, Training Loss: 0.0018745160952229481\n",
      "Validation Accuracy after epoch 294: 73.21%\n",
      "Epoch: 295, Training Loss: 0.001865346545857899\n",
      "Validation Accuracy after epoch 295: 73.19%\n",
      "Epoch: 296, Training Loss: 0.0018552124630981375\n",
      "Validation Accuracy after epoch 296: 73.29%\n",
      "Epoch: 297, Training Loss: 0.001844072650434435\n",
      "Validation Accuracy after epoch 297: 73.26%\n",
      "Epoch: 298, Training Loss: 0.001834503300559452\n",
      "Validation Accuracy after epoch 298: 73.18%\n",
      "Epoch: 299, Training Loss: 0.001824822492839154\n",
      "Validation Accuracy after epoch 299: 73.16%\n",
      "Epoch: 300, Training Loss: 0.0018171672618476308\n",
      "Validation Accuracy after epoch 300: 73.21%\n",
      "Total Training Time: 1478.0554537773132 seconds\n"
     ]
    }
   ],
   "source": [
    "training_loop(\n",
    "    n_epochs=300,\n",
    "    optimizer=optimizer,\n",
    "    model=model,\n",
    "    loss_fn=loss_fn,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3183861c-89f4-4362-9630-3ffd983a8339",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 2 a)\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, n_chans):\n",
    "        super(ResBlock, self).__init__()\n",
    "        self.conv = nn.Conv2d(n_chans, n_chans, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(n_chans, n_chans, kernel_size=3, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = F.relu(self.conv(x))\n",
    "        out = self.conv2(out)\n",
    "        out += residual  \n",
    "        return F.relu(out)\n",
    "\n",
    "class ResNet10(nn.Module):\n",
    "    def __init__(self, n_chans1=32, n_blocks=10):\n",
    "        super(ResNet10, self).__init__()\n",
    "        self.n_chans1 = n_chans1\n",
    "        self.conv1 = nn.Conv2d(3, n_chans1, kernel_size=3, padding=1)\n",
    "        self.resblocks = nn.Sequential(*[ResBlock(n_chans1) for _ in range(n_blocks)])\n",
    "        \n",
    "  \n",
    "        self.fc1 = nn.Linear(n_chans1 * 8 * 8, 32)\n",
    "        self.fc2 = nn.Linear(32, 10) \n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.relu(self.conv1(x)), 2)  \n",
    "        out = self.resblocks(out)  \n",
    "        out = F.adaptive_avg_pool2d(out, (8, 8))  \n",
    "        out = out.view(out.size(0), -1)  \n",
    "        out = torch.relu(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4206698e-b938-451e-a2dd-e6784231dd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet10(n_chans1=32, n_blocks=10).to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-2)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3bdb2756-cb65-4ab2-af49-72358f5eafe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Training Loss: 2.0462962231977517\n",
      "Validation Accuracy after epoch 1: 30.09%\n",
      "Epoch: 2, Training Loss: 1.736056514865602\n",
      "Validation Accuracy after epoch 2: 40.96%\n",
      "Epoch: 3, Training Loss: 1.5505998003513306\n",
      "Validation Accuracy after epoch 3: 38.690000000000005%\n",
      "Epoch: 4, Training Loss: 1.4388548196734066\n",
      "Validation Accuracy after epoch 4: 46.35%\n",
      "Epoch: 5, Training Loss: 1.3462261626939944\n",
      "Validation Accuracy after epoch 5: 47.949999999999996%\n",
      "Epoch: 6, Training Loss: 1.268026067701447\n",
      "Validation Accuracy after epoch 6: 53.63%\n",
      "Epoch: 7, Training Loss: 1.2021813150257101\n",
      "Validation Accuracy after epoch 7: 52.38%\n",
      "Epoch: 8, Training Loss: 1.1465146859436084\n",
      "Validation Accuracy after epoch 8: 58.379999999999995%\n",
      "Epoch: 9, Training Loss: 1.0946092156650464\n",
      "Validation Accuracy after epoch 9: 42.4%\n",
      "Epoch: 10, Training Loss: 1.0533907853276527\n",
      "Validation Accuracy after epoch 10: 49.99%\n",
      "Epoch: 11, Training Loss: 1.0041152521624894\n",
      "Validation Accuracy after epoch 11: 59.099999999999994%\n",
      "Epoch: 12, Training Loss: 0.9615121147669184\n",
      "Validation Accuracy after epoch 12: 48.94%\n",
      "Epoch: 13, Training Loss: 0.9203314371121204\n",
      "Validation Accuracy after epoch 13: 63.190000000000005%\n",
      "Epoch: 14, Training Loss: 0.8846263246005758\n",
      "Validation Accuracy after epoch 14: 61.71%\n",
      "Epoch: 15, Training Loss: 0.8498053841883569\n",
      "Validation Accuracy after epoch 15: 66.97%\n",
      "Epoch: 16, Training Loss: 0.8188123205662383\n",
      "Validation Accuracy after epoch 16: 64.68%\n",
      "Epoch: 17, Training Loss: 0.7903074410260486\n",
      "Validation Accuracy after epoch 17: 65.75999999999999%\n",
      "Epoch: 18, Training Loss: 0.762610299889084\n",
      "Validation Accuracy after epoch 18: 67.96%\n",
      "Epoch: 19, Training Loss: 0.7311438381519464\n",
      "Validation Accuracy after epoch 19: 66.64999999999999%\n",
      "Epoch: 20, Training Loss: 0.705596588837826\n",
      "Validation Accuracy after epoch 20: 68.03%\n",
      "Epoch: 21, Training Loss: 0.6836159217845449\n",
      "Validation Accuracy after epoch 21: 58.620000000000005%\n",
      "Epoch: 22, Training Loss: 0.6569025215056851\n",
      "Validation Accuracy after epoch 22: 65.56%\n",
      "Epoch: 23, Training Loss: 0.6357580462227697\n",
      "Validation Accuracy after epoch 23: 68.24%\n",
      "Epoch: 24, Training Loss: 0.6076372191881585\n",
      "Validation Accuracy after epoch 24: 71.97%\n",
      "Epoch: 25, Training Loss: 0.5873294916108746\n",
      "Validation Accuracy after epoch 25: 69.51%\n",
      "Epoch: 26, Training Loss: 0.5660355723346285\n",
      "Validation Accuracy after epoch 26: 68.75%\n",
      "Epoch: 27, Training Loss: 0.5461582196376208\n",
      "Validation Accuracy after epoch 27: 67.78%\n",
      "Epoch: 28, Training Loss: 0.5235270813793478\n",
      "Validation Accuracy after epoch 28: 70.33%\n",
      "Epoch: 29, Training Loss: 0.5019812116689999\n",
      "Validation Accuracy after epoch 29: 70.42%\n",
      "Epoch: 30, Training Loss: 0.4827022132704325\n",
      "Validation Accuracy after epoch 30: 62.38%\n",
      "Epoch: 31, Training Loss: 0.4666968658757027\n",
      "Validation Accuracy after epoch 31: 64.22%\n",
      "Epoch: 32, Training Loss: 0.44315885594281396\n",
      "Validation Accuracy after epoch 32: 68.73%\n",
      "Epoch: 33, Training Loss: 0.42613409076581527\n",
      "Validation Accuracy after epoch 33: 69.95%\n",
      "Epoch: 34, Training Loss: 0.4068213157222399\n",
      "Validation Accuracy after epoch 34: 68.54%\n",
      "Epoch: 35, Training Loss: 0.3909457083124563\n",
      "Validation Accuracy after epoch 35: 72.35000000000001%\n",
      "Epoch: 36, Training Loss: 0.37257609463980434\n",
      "Validation Accuracy after epoch 36: 67.24%\n",
      "Epoch: 37, Training Loss: 0.35786025258510007\n",
      "Validation Accuracy after epoch 37: 67.38%\n",
      "Epoch: 38, Training Loss: 0.3411495122496429\n",
      "Validation Accuracy after epoch 38: 69.96%\n",
      "Epoch: 39, Training Loss: 0.32269004480841823\n",
      "Validation Accuracy after epoch 39: 64.77000000000001%\n",
      "Epoch: 40, Training Loss: 0.3078948455431577\n",
      "Validation Accuracy after epoch 40: 70.04%\n",
      "Epoch: 41, Training Loss: 0.2939723075827217\n",
      "Validation Accuracy after epoch 41: 67.53%\n",
      "Epoch: 42, Training Loss: 0.2817513429752701\n",
      "Validation Accuracy after epoch 42: 66.45%\n",
      "Epoch: 43, Training Loss: 0.2681152268081827\n",
      "Validation Accuracy after epoch 43: 67.63%\n",
      "Epoch: 44, Training Loss: 0.24954077715763961\n",
      "Validation Accuracy after epoch 44: 67.67999999999999%\n",
      "Epoch: 45, Training Loss: 0.23697554735500184\n",
      "Validation Accuracy after epoch 45: 68.95%\n",
      "Epoch: 46, Training Loss: 0.22636421371127485\n",
      "Validation Accuracy after epoch 46: 67.47%\n",
      "Epoch: 47, Training Loss: 0.2100127365730722\n",
      "Validation Accuracy after epoch 47: 71.47%\n",
      "Epoch: 48, Training Loss: 0.2000166177416168\n",
      "Validation Accuracy after epoch 48: 69.66%\n",
      "Epoch: 49, Training Loss: 0.1917560995625489\n",
      "Validation Accuracy after epoch 49: 65.74%\n",
      "Epoch: 50, Training Loss: 0.17945762686288494\n",
      "Validation Accuracy after epoch 50: 71.07%\n",
      "Epoch: 51, Training Loss: 0.17120569059387078\n",
      "Validation Accuracy after epoch 51: 69.77%\n",
      "Epoch: 52, Training Loss: 0.1593978809183249\n",
      "Validation Accuracy after epoch 52: 67.9%\n",
      "Epoch: 53, Training Loss: 0.15728608167746946\n",
      "Validation Accuracy after epoch 53: 69.53%\n",
      "Epoch: 54, Training Loss: 0.1434874537405665\n",
      "Validation Accuracy after epoch 54: 70.86%\n",
      "Epoch: 55, Training Loss: 0.1349338975966053\n",
      "Validation Accuracy after epoch 55: 64.28%\n",
      "Epoch: 56, Training Loss: 0.1362468350733466\n",
      "Validation Accuracy after epoch 56: 70.19999999999999%\n",
      "Epoch: 57, Training Loss: 0.11732118360250426\n",
      "Validation Accuracy after epoch 57: 70.92%\n",
      "Epoch: 58, Training Loss: 0.12049499365246243\n",
      "Validation Accuracy after epoch 58: 68.82000000000001%\n",
      "Epoch: 59, Training Loss: 0.11182496636567632\n",
      "Validation Accuracy after epoch 59: 69.59%\n",
      "Epoch: 60, Training Loss: 0.10168471554820628\n",
      "Validation Accuracy after epoch 60: 69.69%\n",
      "Epoch: 61, Training Loss: 0.10231162083056539\n",
      "Validation Accuracy after epoch 61: 70.26%\n",
      "Epoch: 62, Training Loss: 0.0961372449951213\n",
      "Validation Accuracy after epoch 62: 66.86999999999999%\n",
      "Epoch: 63, Training Loss: 0.09341900578945342\n",
      "Validation Accuracy after epoch 63: 70.69%\n",
      "Epoch: 64, Training Loss: 0.08682678481373374\n",
      "Validation Accuracy after epoch 64: 70.52000000000001%\n",
      "Epoch: 65, Training Loss: 0.08278257918872815\n",
      "Validation Accuracy after epoch 65: 70.19999999999999%\n",
      "Epoch: 66, Training Loss: 0.0735214517304145\n",
      "Validation Accuracy after epoch 66: 71.3%\n",
      "Epoch: 67, Training Loss: 0.07436642754653855\n",
      "Validation Accuracy after epoch 67: 67.97%\n",
      "Epoch: 68, Training Loss: 0.07239192402254685\n",
      "Validation Accuracy after epoch 68: 71.46000000000001%\n",
      "Epoch: 69, Training Loss: 0.06016700916156611\n",
      "Validation Accuracy after epoch 69: 65.67%\n",
      "Epoch: 70, Training Loss: 0.08012412631046979\n",
      "Validation Accuracy after epoch 70: 70.14%\n",
      "Epoch: 71, Training Loss: 0.05205588496100786\n",
      "Validation Accuracy after epoch 71: 71.78%\n",
      "Epoch: 72, Training Loss: 0.05790483967497554\n",
      "Validation Accuracy after epoch 72: 69.57%\n",
      "Epoch: 73, Training Loss: 0.053284701750711407\n",
      "Validation Accuracy after epoch 73: 70.58%\n",
      "Epoch: 74, Training Loss: 0.05460660569706236\n",
      "Validation Accuracy after epoch 74: 71.16%\n",
      "Epoch: 75, Training Loss: 0.061329758272755205\n",
      "Validation Accuracy after epoch 75: 71.37%\n",
      "Epoch: 76, Training Loss: 0.04380471907589403\n",
      "Validation Accuracy after epoch 76: 71.26%\n",
      "Epoch: 77, Training Loss: 0.04467236918583036\n",
      "Validation Accuracy after epoch 77: 72.03%\n",
      "Epoch: 78, Training Loss: 0.033760698404638904\n",
      "Validation Accuracy after epoch 78: 70.64%\n",
      "Epoch: 79, Training Loss: 0.05796590594068953\n",
      "Validation Accuracy after epoch 79: 69.66%\n",
      "Epoch: 80, Training Loss: 0.03907412540720915\n",
      "Validation Accuracy after epoch 80: 70.82000000000001%\n",
      "Epoch: 81, Training Loss: 0.047952298927755044\n",
      "Validation Accuracy after epoch 81: 71.28999999999999%\n",
      "Epoch: 82, Training Loss: 0.042765829555244876\n",
      "Validation Accuracy after epoch 82: 71.22%\n",
      "Epoch: 83, Training Loss: 0.03911572112820928\n",
      "Validation Accuracy after epoch 83: 67.94%\n",
      "Epoch: 84, Training Loss: 0.044096488625069014\n",
      "Validation Accuracy after epoch 84: 71.34%\n",
      "Epoch: 85, Training Loss: 0.04463299279554647\n",
      "Validation Accuracy after epoch 85: 70.98%\n",
      "Epoch: 86, Training Loss: 0.033850427034854066\n",
      "Validation Accuracy after epoch 86: 71.00999999999999%\n",
      "Epoch: 87, Training Loss: 0.014144603730528615\n",
      "Validation Accuracy after epoch 87: 70.59%\n",
      "Epoch: 88, Training Loss: 0.03305110395623251\n",
      "Validation Accuracy after epoch 88: 70.74000000000001%\n",
      "Epoch: 89, Training Loss: 0.0303406915142108\n",
      "Validation Accuracy after epoch 89: 70.82000000000001%\n",
      "Epoch: 90, Training Loss: 0.021287168023738322\n",
      "Validation Accuracy after epoch 90: 69.67999999999999%\n",
      "Epoch: 91, Training Loss: 0.047823089971271465\n",
      "Validation Accuracy after epoch 91: 69.92%\n",
      "Epoch: 92, Training Loss: 0.028528560941015867\n",
      "Validation Accuracy after epoch 92: 71.02000000000001%\n",
      "Epoch: 93, Training Loss: 0.023164757261624532\n",
      "Validation Accuracy after epoch 93: 67.11%\n",
      "Epoch: 94, Training Loss: 0.02571933421883476\n",
      "Validation Accuracy after epoch 94: 71.28999999999999%\n",
      "Epoch: 95, Training Loss: 0.03004513310540281\n",
      "Validation Accuracy after epoch 95: 71.53%\n",
      "Epoch: 96, Training Loss: 0.01765899850962781\n",
      "Validation Accuracy after epoch 96: 70.63000000000001%\n",
      "Epoch: 97, Training Loss: 0.03850803121126762\n",
      "Validation Accuracy after epoch 97: 71.69%\n",
      "Epoch: 98, Training Loss: 0.025552035823566816\n",
      "Validation Accuracy after epoch 98: 71.39999999999999%\n",
      "Epoch: 99, Training Loss: 0.010255579570135788\n",
      "Validation Accuracy after epoch 99: 71.71%\n",
      "Epoch: 100, Training Loss: 0.002719964110203173\n",
      "Validation Accuracy after epoch 100: 72.11999999999999%\n",
      "Epoch: 101, Training Loss: 0.00042169017971965887\n",
      "Validation Accuracy after epoch 101: 72.26%\n",
      "Epoch: 102, Training Loss: 0.00023114463151370236\n",
      "Validation Accuracy after epoch 102: 72.23%\n",
      "Epoch: 103, Training Loss: 0.00017823962463780216\n",
      "Validation Accuracy after epoch 103: 72.28999999999999%\n",
      "Epoch: 104, Training Loss: 0.0001473445368561987\n",
      "Validation Accuracy after epoch 104: 72.32%\n",
      "Epoch: 105, Training Loss: 0.00012575366257494615\n",
      "Validation Accuracy after epoch 105: 72.33000000000001%\n",
      "Epoch: 106, Training Loss: 0.0001106275020892799\n",
      "Validation Accuracy after epoch 106: 72.24000000000001%\n",
      "Epoch: 107, Training Loss: 9.850724209207658e-05\n",
      "Validation Accuracy after epoch 107: 72.34%\n",
      "Epoch: 108, Training Loss: 8.89875030113433e-05\n",
      "Validation Accuracy after epoch 108: 72.39%\n",
      "Epoch: 109, Training Loss: 8.09891464384569e-05\n",
      "Validation Accuracy after epoch 109: 72.38%\n",
      "Epoch: 110, Training Loss: 7.430989334668835e-05\n",
      "Validation Accuracy after epoch 110: 72.36%\n",
      "Epoch: 111, Training Loss: 6.875427394523686e-05\n",
      "Validation Accuracy after epoch 111: 72.39999999999999%\n",
      "Epoch: 112, Training Loss: 6.394330564530499e-05\n",
      "Validation Accuracy after epoch 112: 72.39999999999999%\n",
      "Epoch: 113, Training Loss: 5.982368249691638e-05\n",
      "Validation Accuracy after epoch 113: 72.43%\n",
      "Epoch: 114, Training Loss: 5.606670537891169e-05\n",
      "Validation Accuracy after epoch 114: 72.39%\n",
      "Epoch: 115, Training Loss: 5.292071145412571e-05\n",
      "Validation Accuracy after epoch 115: 72.39999999999999%\n",
      "Epoch: 116, Training Loss: 5.001414646895494e-05\n",
      "Validation Accuracy after epoch 116: 72.36%\n",
      "Epoch: 117, Training Loss: 4.7404370225904176e-05\n",
      "Validation Accuracy after epoch 117: 72.37%\n",
      "Epoch: 118, Training Loss: 4.501042278958345e-05\n",
      "Validation Accuracy after epoch 118: 72.36%\n",
      "Epoch: 119, Training Loss: 4.293172916506517e-05\n",
      "Validation Accuracy after epoch 119: 72.31%\n",
      "Epoch: 120, Training Loss: 4.088793021405054e-05\n",
      "Validation Accuracy after epoch 120: 72.34%\n",
      "Epoch: 121, Training Loss: 3.917195936071232e-05\n",
      "Validation Accuracy after epoch 121: 72.31%\n",
      "Epoch: 122, Training Loss: 3.754617932333096e-05\n",
      "Validation Accuracy after epoch 122: 72.35000000000001%\n",
      "Epoch: 123, Training Loss: 3.6005633874060024e-05\n",
      "Validation Accuracy after epoch 123: 72.34%\n",
      "Epoch: 124, Training Loss: 3.467132346896294e-05\n",
      "Validation Accuracy after epoch 124: 72.3%\n",
      "Epoch: 125, Training Loss: 3.335472052504323e-05\n",
      "Validation Accuracy after epoch 125: 72.33000000000001%\n",
      "Epoch: 126, Training Loss: 3.219587263942221e-05\n",
      "Validation Accuracy after epoch 126: 72.26%\n",
      "Epoch: 127, Training Loss: 3.1052740635289684e-05\n",
      "Validation Accuracy after epoch 127: 72.25%\n",
      "Epoch: 128, Training Loss: 3.0066526233392843e-05\n",
      "Validation Accuracy after epoch 128: 72.24000000000001%\n",
      "Epoch: 129, Training Loss: 2.903748993326178e-05\n",
      "Validation Accuracy after epoch 129: 72.26%\n",
      "Epoch: 130, Training Loss: 2.8111273455765734e-05\n",
      "Validation Accuracy after epoch 130: 72.23%\n",
      "Epoch: 131, Training Loss: 2.7259890721191314e-05\n",
      "Validation Accuracy after epoch 131: 72.25%\n",
      "Epoch: 132, Training Loss: 2.6442644535445257e-05\n",
      "Validation Accuracy after epoch 132: 72.24000000000001%\n",
      "Epoch: 133, Training Loss: 2.564407820856381e-05\n",
      "Validation Accuracy after epoch 133: 72.22%\n",
      "Epoch: 134, Training Loss: 2.4921304814264904e-05\n",
      "Validation Accuracy after epoch 134: 72.18%\n",
      "Epoch: 135, Training Loss: 2.426495930028773e-05\n",
      "Validation Accuracy after epoch 135: 72.18%\n",
      "Epoch: 136, Training Loss: 2.365681693993832e-05\n",
      "Validation Accuracy after epoch 136: 72.19%\n",
      "Epoch: 137, Training Loss: 2.2989421899886127e-05\n",
      "Validation Accuracy after epoch 137: 72.18%\n",
      "Epoch: 138, Training Loss: 2.2388775294877952e-05\n",
      "Validation Accuracy after epoch 138: 72.17%\n",
      "Epoch: 139, Training Loss: 2.182728068183141e-05\n",
      "Validation Accuracy after epoch 139: 72.15%\n",
      "Epoch: 140, Training Loss: 2.1282441788166567e-05\n",
      "Validation Accuracy after epoch 140: 72.17%\n",
      "Epoch: 141, Training Loss: 2.0817131800456366e-05\n",
      "Validation Accuracy after epoch 141: 72.19%\n",
      "Epoch: 142, Training Loss: 2.029553307254812e-05\n",
      "Validation Accuracy after epoch 142: 72.19%\n",
      "Epoch: 143, Training Loss: 1.9855776918760353e-05\n",
      "Validation Accuracy after epoch 143: 72.18%\n",
      "Epoch: 144, Training Loss: 1.938445731047745e-05\n",
      "Validation Accuracy after epoch 144: 72.17%\n",
      "Epoch: 145, Training Loss: 1.8987377551327234e-05\n",
      "Validation Accuracy after epoch 145: 72.15%\n",
      "Epoch: 146, Training Loss: 1.8535228534269628e-05\n",
      "Validation Accuracy after epoch 146: 72.15%\n",
      "Epoch: 147, Training Loss: 1.8156620740083013e-05\n",
      "Validation Accuracy after epoch 147: 72.19%\n",
      "Epoch: 148, Training Loss: 1.7810546422939747e-05\n",
      "Validation Accuracy after epoch 148: 72.19%\n",
      "Epoch: 149, Training Loss: 1.7411290438867187e-05\n",
      "Validation Accuracy after epoch 149: 72.2%\n",
      "Epoch: 150, Training Loss: 1.7087341013314803e-05\n",
      "Validation Accuracy after epoch 150: 72.19%\n",
      "Epoch: 151, Training Loss: 1.6750501663685745e-05\n",
      "Validation Accuracy after epoch 151: 72.22%\n",
      "Epoch: 152, Training Loss: 1.64086203867241e-05\n",
      "Validation Accuracy after epoch 152: 72.22%\n",
      "Epoch: 153, Training Loss: 1.6110285820247817e-05\n",
      "Validation Accuracy after epoch 153: 72.21%\n",
      "Epoch: 154, Training Loss: 1.584637998845824e-05\n",
      "Validation Accuracy after epoch 154: 72.19%\n",
      "Epoch: 155, Training Loss: 1.5511388900231023e-05\n",
      "Validation Accuracy after epoch 155: 72.18%\n",
      "Epoch: 156, Training Loss: 1.5230032435134778e-05\n",
      "Validation Accuracy after epoch 156: 72.17%\n",
      "Epoch: 157, Training Loss: 1.4966501518257616e-05\n",
      "Validation Accuracy after epoch 157: 72.2%\n",
      "Epoch: 158, Training Loss: 1.470806288714828e-05\n",
      "Validation Accuracy after epoch 158: 72.2%\n",
      "Epoch: 159, Training Loss: 1.4452234957236652e-05\n",
      "Validation Accuracy after epoch 159: 72.19%\n",
      "Epoch: 160, Training Loss: 1.4226883884032566e-05\n",
      "Validation Accuracy after epoch 160: 72.2%\n",
      "Epoch: 161, Training Loss: 1.3976270451367552e-05\n",
      "Validation Accuracy after epoch 161: 72.21%\n",
      "Epoch: 162, Training Loss: 1.3740914269278863e-05\n",
      "Validation Accuracy after epoch 162: 72.19%\n",
      "Epoch: 163, Training Loss: 1.3554320941927502e-05\n",
      "Validation Accuracy after epoch 163: 72.21%\n",
      "Epoch: 164, Training Loss: 1.3336495191583301e-05\n",
      "Validation Accuracy after epoch 164: 72.24000000000001%\n",
      "Epoch: 165, Training Loss: 1.3160000542017963e-05\n",
      "Validation Accuracy after epoch 165: 72.22%\n",
      "Epoch: 166, Training Loss: 1.2900976533637674e-05\n",
      "Validation Accuracy after epoch 166: 72.24000000000001%\n",
      "Epoch: 167, Training Loss: 1.2689828098040067e-05\n",
      "Validation Accuracy after epoch 167: 72.22%\n",
      "Epoch: 168, Training Loss: 1.2504576568386382e-05\n",
      "Validation Accuracy after epoch 168: 72.23%\n",
      "Epoch: 169, Training Loss: 1.2321537871616376e-05\n",
      "Validation Accuracy after epoch 169: 72.24000000000001%\n",
      "Epoch: 170, Training Loss: 1.2149192830153468e-05\n",
      "Validation Accuracy after epoch 170: 72.24000000000001%\n",
      "Epoch: 171, Training Loss: 1.1960324421050244e-05\n",
      "Validation Accuracy after epoch 171: 72.23%\n",
      "Epoch: 172, Training Loss: 1.1805554489423116e-05\n",
      "Validation Accuracy after epoch 172: 72.23%\n",
      "Epoch: 173, Training Loss: 1.162616904300439e-05\n",
      "Validation Accuracy after epoch 173: 72.22%\n",
      "Epoch: 174, Training Loss: 1.147985851595279e-05\n",
      "Validation Accuracy after epoch 174: 72.24000000000001%\n",
      "Epoch: 175, Training Loss: 1.131682548886062e-05\n",
      "Validation Accuracy after epoch 175: 72.23%\n",
      "Epoch: 176, Training Loss: 1.11507046829515e-05\n",
      "Validation Accuracy after epoch 176: 72.23%\n",
      "Epoch: 177, Training Loss: 1.1004549073915229e-05\n",
      "Validation Accuracy after epoch 177: 72.21%\n",
      "Epoch: 178, Training Loss: 1.089393550507369e-05\n",
      "Validation Accuracy after epoch 178: 72.23%\n",
      "Epoch: 179, Training Loss: 1.0713945774732262e-05\n",
      "Validation Accuracy after epoch 179: 72.21%\n",
      "Epoch: 180, Training Loss: 1.0587545164546734e-05\n",
      "Validation Accuracy after epoch 180: 72.21%\n",
      "Epoch: 181, Training Loss: 1.0447362746793346e-05\n",
      "Validation Accuracy after epoch 181: 72.22%\n",
      "Epoch: 182, Training Loss: 1.030788863809104e-05\n",
      "Validation Accuracy after epoch 182: 72.2%\n",
      "Epoch: 183, Training Loss: 1.0202862901623065e-05\n",
      "Validation Accuracy after epoch 183: 72.21%\n",
      "Epoch: 184, Training Loss: 1.005619044579977e-05\n",
      "Validation Accuracy after epoch 184: 72.2%\n",
      "Epoch: 185, Training Loss: 9.93350441954199e-06\n",
      "Validation Accuracy after epoch 185: 72.2%\n",
      "Epoch: 186, Training Loss: 9.826179646891217e-06\n",
      "Validation Accuracy after epoch 186: 72.24000000000001%\n",
      "Epoch: 187, Training Loss: 9.711750663310199e-06\n",
      "Validation Accuracy after epoch 187: 72.22%\n",
      "Epoch: 188, Training Loss: 9.575145078254413e-06\n",
      "Validation Accuracy after epoch 188: 72.23%\n",
      "Epoch: 189, Training Loss: 9.486175795603433e-06\n",
      "Validation Accuracy after epoch 189: 72.21%\n",
      "Epoch: 190, Training Loss: 9.360272926855627e-06\n",
      "Validation Accuracy after epoch 190: 72.23%\n",
      "Epoch: 191, Training Loss: 9.250696447582616e-06\n",
      "Validation Accuracy after epoch 191: 72.22%\n",
      "Epoch: 192, Training Loss: 9.19961726523248e-06\n",
      "Validation Accuracy after epoch 192: 72.23%\n",
      "Epoch: 193, Training Loss: 9.041648139997397e-06\n",
      "Validation Accuracy after epoch 193: 72.22%\n",
      "Epoch: 194, Training Loss: 8.942188050941532e-06\n",
      "Validation Accuracy after epoch 194: 72.21%\n",
      "Epoch: 195, Training Loss: 8.842286615552502e-06\n",
      "Validation Accuracy after epoch 195: 72.21%\n",
      "Epoch: 196, Training Loss: 8.744622293873437e-06\n",
      "Validation Accuracy after epoch 196: 72.21%\n",
      "Epoch: 197, Training Loss: 8.652998599289233e-06\n",
      "Validation Accuracy after epoch 197: 72.21%\n",
      "Epoch: 198, Training Loss: 8.56394679529527e-06\n",
      "Validation Accuracy after epoch 198: 72.21%\n",
      "Epoch: 199, Training Loss: 8.48416294787911e-06\n",
      "Validation Accuracy after epoch 199: 72.19%\n",
      "Epoch: 200, Training Loss: 8.413651360712692e-06\n",
      "Validation Accuracy after epoch 200: 72.2%\n",
      "Epoch: 201, Training Loss: 8.292141408226955e-06\n",
      "Validation Accuracy after epoch 201: 72.21%\n",
      "Epoch: 202, Training Loss: 8.206079548638722e-06\n",
      "Validation Accuracy after epoch 202: 72.21%\n",
      "Epoch: 203, Training Loss: 8.133321961734874e-06\n",
      "Validation Accuracy after epoch 203: 72.2%\n",
      "Epoch: 204, Training Loss: 8.085717219875665e-06\n",
      "Validation Accuracy after epoch 204: 72.21%\n",
      "Epoch: 205, Training Loss: 7.964513273658844e-06\n",
      "Validation Accuracy after epoch 205: 72.21%\n",
      "Epoch: 206, Training Loss: 7.895349735530553e-06\n",
      "Validation Accuracy after epoch 206: 72.2%\n",
      "Epoch: 207, Training Loss: 7.801346731334273e-06\n",
      "Validation Accuracy after epoch 207: 72.21%\n",
      "Epoch: 208, Training Loss: 7.725511970009496e-06\n",
      "Validation Accuracy after epoch 208: 72.21%\n",
      "Epoch: 209, Training Loss: 7.653921514433862e-06\n",
      "Validation Accuracy after epoch 209: 72.19%\n",
      "Epoch: 210, Training Loss: 7.580625662940537e-06\n",
      "Validation Accuracy after epoch 210: 72.2%\n",
      "Epoch: 211, Training Loss: 7.5139214807525136e-06\n",
      "Validation Accuracy after epoch 211: 72.19%\n",
      "Epoch: 212, Training Loss: 7.437600478006073e-06\n",
      "Validation Accuracy after epoch 212: 72.2%\n",
      "Epoch: 213, Training Loss: 7.366370357605607e-06\n",
      "Validation Accuracy after epoch 213: 72.2%\n",
      "Epoch: 214, Training Loss: 7.324804048536276e-06\n",
      "Validation Accuracy after epoch 214: 72.19%\n",
      "Epoch: 215, Training Loss: 7.250660981829933e-06\n",
      "Validation Accuracy after epoch 215: 72.18%\n",
      "Epoch: 216, Training Loss: 7.166498393361161e-06\n",
      "Validation Accuracy after epoch 216: 72.17%\n",
      "Epoch: 217, Training Loss: 7.10627648626381e-06\n",
      "Validation Accuracy after epoch 217: 72.18%\n",
      "Epoch: 218, Training Loss: 7.040025129817453e-06\n",
      "Validation Accuracy after epoch 218: 72.2%\n",
      "Epoch: 219, Training Loss: 6.9723641325441825e-06\n",
      "Validation Accuracy after epoch 219: 72.18%\n",
      "Epoch: 220, Training Loss: 6.916225555503976e-06\n",
      "Validation Accuracy after epoch 220: 72.18%\n",
      "Epoch: 221, Training Loss: 6.8555309151474365e-06\n",
      "Validation Accuracy after epoch 221: 72.19%\n",
      "Epoch: 222, Training Loss: 6.816549348205741e-06\n",
      "Validation Accuracy after epoch 222: 72.19%\n",
      "Epoch: 223, Training Loss: 6.733524053531204e-06\n",
      "Validation Accuracy after epoch 223: 72.19%\n",
      "Epoch: 224, Training Loss: 6.679594414037656e-06\n",
      "Validation Accuracy after epoch 224: 72.18%\n",
      "Epoch: 225, Training Loss: 6.631583491332171e-06\n",
      "Validation Accuracy after epoch 225: 72.18%\n",
      "Epoch: 226, Training Loss: 6.5682002323339004e-06\n",
      "Validation Accuracy after epoch 226: 72.18%\n",
      "Epoch: 227, Training Loss: 6.511927677027304e-06\n",
      "Validation Accuracy after epoch 227: 72.16%\n",
      "Epoch: 228, Training Loss: 6.453782382285171e-06\n",
      "Validation Accuracy after epoch 228: 72.16%\n",
      "Epoch: 229, Training Loss: 6.402375404854953e-06\n",
      "Validation Accuracy after epoch 229: 72.18%\n",
      "Epoch: 230, Training Loss: 6.352405145526994e-06\n",
      "Validation Accuracy after epoch 230: 72.17%\n",
      "Epoch: 231, Training Loss: 6.303223689928956e-06\n",
      "Validation Accuracy after epoch 231: 72.18%\n",
      "Epoch: 232, Training Loss: 6.247380274058481e-06\n",
      "Validation Accuracy after epoch 232: 72.18%\n",
      "Epoch: 233, Training Loss: 6.197229604976889e-06\n",
      "Validation Accuracy after epoch 233: 72.17%\n",
      "Epoch: 234, Training Loss: 6.151036400802937e-06\n",
      "Validation Accuracy after epoch 234: 72.18%\n",
      "Epoch: 235, Training Loss: 6.098933267410061e-06\n",
      "Validation Accuracy after epoch 235: 72.18%\n",
      "Epoch: 236, Training Loss: 6.054452506583789e-06\n",
      "Validation Accuracy after epoch 236: 72.18%\n",
      "Epoch: 237, Training Loss: 6.0111029740155015e-06\n",
      "Validation Accuracy after epoch 237: 72.18%\n",
      "Epoch: 238, Training Loss: 5.957061660828076e-06\n",
      "Validation Accuracy after epoch 238: 72.2%\n",
      "Epoch: 239, Training Loss: 5.9169308354065786e-06\n",
      "Validation Accuracy after epoch 239: 72.16%\n",
      "Epoch: 240, Training Loss: 5.869405109697626e-06\n",
      "Validation Accuracy after epoch 240: 72.17%\n",
      "Epoch: 241, Training Loss: 5.819863754381718e-06\n",
      "Validation Accuracy after epoch 241: 72.18%\n",
      "Epoch: 242, Training Loss: 5.779785958263819e-06\n",
      "Validation Accuracy after epoch 242: 72.18%\n",
      "Epoch: 243, Training Loss: 5.735598974775326e-06\n",
      "Validation Accuracy after epoch 243: 72.18%\n",
      "Epoch: 244, Training Loss: 5.694418006915348e-06\n",
      "Validation Accuracy after epoch 244: 72.2%\n",
      "Epoch: 245, Training Loss: 5.652770374939666e-06\n",
      "Validation Accuracy after epoch 245: 72.21%\n",
      "Epoch: 246, Training Loss: 5.61108018374384e-06\n",
      "Validation Accuracy after epoch 246: 72.2%\n",
      "Epoch: 247, Training Loss: 5.575718063400788e-06\n",
      "Validation Accuracy after epoch 247: 72.2%\n",
      "Epoch: 248, Training Loss: 5.528981369776745e-06\n",
      "Validation Accuracy after epoch 248: 72.2%\n",
      "Epoch: 249, Training Loss: 5.488121957232248e-06\n",
      "Validation Accuracy after epoch 249: 72.19%\n",
      "Epoch: 250, Training Loss: 5.447672129215454e-06\n",
      "Validation Accuracy after epoch 250: 72.19%\n",
      "Epoch: 251, Training Loss: 5.412053668205039e-06\n",
      "Validation Accuracy after epoch 251: 72.23%\n",
      "Epoch: 252, Training Loss: 5.3769660149288505e-06\n",
      "Validation Accuracy after epoch 252: 72.19%\n",
      "Epoch: 253, Training Loss: 5.355016017689885e-06\n",
      "Validation Accuracy after epoch 253: 72.21%\n",
      "Epoch: 254, Training Loss: 5.3010974644257425e-06\n",
      "Validation Accuracy after epoch 254: 72.21%\n",
      "Epoch: 255, Training Loss: 5.287571096062765e-06\n",
      "Validation Accuracy after epoch 255: 72.21%\n",
      "Epoch: 256, Training Loss: 5.232024215253643e-06\n",
      "Validation Accuracy after epoch 256: 72.21%\n",
      "Epoch: 257, Training Loss: 5.1912706980914075e-06\n",
      "Validation Accuracy after epoch 257: 72.22%\n",
      "Epoch: 258, Training Loss: 5.15548472034337e-06\n",
      "Validation Accuracy after epoch 258: 72.21%\n",
      "Epoch: 259, Training Loss: 5.1194091060044065e-06\n",
      "Validation Accuracy after epoch 259: 72.22%\n",
      "Epoch: 260, Training Loss: 5.087988027373141e-06\n",
      "Validation Accuracy after epoch 260: 72.23%\n",
      "Epoch: 261, Training Loss: 5.050611657993131e-06\n",
      "Validation Accuracy after epoch 261: 72.23%\n",
      "Epoch: 262, Training Loss: 5.0184134848219695e-06\n",
      "Validation Accuracy after epoch 262: 72.22%\n",
      "Epoch: 263, Training Loss: 4.986315596489497e-06\n",
      "Validation Accuracy after epoch 263: 72.23%\n",
      "Epoch: 264, Training Loss: 4.9523346060871796e-06\n",
      "Validation Accuracy after epoch 264: 72.23%\n",
      "Epoch: 265, Training Loss: 4.9191813598189675e-06\n",
      "Validation Accuracy after epoch 265: 72.23%\n",
      "Epoch: 266, Training Loss: 4.897699971620179e-06\n",
      "Validation Accuracy after epoch 266: 72.23%\n",
      "Epoch: 267, Training Loss: 4.85966454950167e-06\n",
      "Validation Accuracy after epoch 267: 72.23%\n",
      "Epoch: 268, Training Loss: 4.833366060104701e-06\n",
      "Validation Accuracy after epoch 268: 72.24000000000001%\n",
      "Epoch: 269, Training Loss: 4.795305761121771e-06\n",
      "Validation Accuracy after epoch 269: 72.24000000000001%\n",
      "Epoch: 270, Training Loss: 4.763429143147969e-06\n",
      "Validation Accuracy after epoch 270: 72.24000000000001%\n",
      "Epoch: 271, Training Loss: 4.736293700701368e-06\n",
      "Validation Accuracy after epoch 271: 72.23%\n",
      "Epoch: 272, Training Loss: 4.7078604173839034e-06\n",
      "Validation Accuracy after epoch 272: 72.23%\n",
      "Epoch: 273, Training Loss: 4.675765456741916e-06\n",
      "Validation Accuracy after epoch 273: 72.23%\n",
      "Epoch: 274, Training Loss: 4.649762887105369e-06\n",
      "Validation Accuracy after epoch 274: 72.21%\n",
      "Epoch: 275, Training Loss: 4.6193209214898315e-06\n",
      "Validation Accuracy after epoch 275: 72.22%\n",
      "Epoch: 276, Training Loss: 4.589646016305949e-06\n",
      "Validation Accuracy after epoch 276: 72.21%\n",
      "Epoch: 277, Training Loss: 4.56418181553239e-06\n",
      "Validation Accuracy after epoch 277: 72.21%\n",
      "Epoch: 278, Training Loss: 4.537217659461607e-06\n",
      "Validation Accuracy after epoch 278: 72.2%\n",
      "Epoch: 279, Training Loss: 4.505514347894826e-06\n",
      "Validation Accuracy after epoch 279: 72.2%\n",
      "Epoch: 280, Training Loss: 4.479078434535338e-06\n",
      "Validation Accuracy after epoch 280: 72.2%\n",
      "Epoch: 281, Training Loss: 4.452070559297025e-06\n",
      "Validation Accuracy after epoch 281: 72.2%\n",
      "Epoch: 282, Training Loss: 4.432655118806682e-06\n",
      "Validation Accuracy after epoch 282: 72.22%\n",
      "Epoch: 283, Training Loss: 4.400544545914356e-06\n",
      "Validation Accuracy after epoch 283: 72.22%\n",
      "Epoch: 284, Training Loss: 4.373043502952845e-06\n",
      "Validation Accuracy after epoch 284: 72.21%\n",
      "Epoch: 285, Training Loss: 4.3525477268643115e-06\n",
      "Validation Accuracy after epoch 285: 72.21%\n",
      "Epoch: 286, Training Loss: 4.322576449244317e-06\n",
      "Validation Accuracy after epoch 286: 72.21%\n",
      "Epoch: 287, Training Loss: 4.298421972033098e-06\n",
      "Validation Accuracy after epoch 287: 72.2%\n",
      "Epoch: 288, Training Loss: 4.272822214152652e-06\n",
      "Validation Accuracy after epoch 288: 72.21%\n",
      "Epoch: 289, Training Loss: 4.275635554578861e-06\n",
      "Validation Accuracy after epoch 289: 72.2%\n",
      "Epoch: 290, Training Loss: 4.232751115099934e-06\n",
      "Validation Accuracy after epoch 290: 72.21%\n",
      "Epoch: 291, Training Loss: 4.200337865703685e-06\n",
      "Validation Accuracy after epoch 291: 72.22%\n",
      "Epoch: 292, Training Loss: 4.185297705432173e-06\n",
      "Validation Accuracy after epoch 292: 72.22%\n",
      "Epoch: 293, Training Loss: 4.155861356294477e-06\n",
      "Validation Accuracy after epoch 293: 72.22%\n",
      "Epoch: 294, Training Loss: 4.135000613128072e-06\n",
      "Validation Accuracy after epoch 294: 72.23%\n",
      "Epoch: 295, Training Loss: 4.10702863598886e-06\n",
      "Validation Accuracy after epoch 295: 72.21%\n",
      "Epoch: 296, Training Loss: 4.085587842613964e-06\n",
      "Validation Accuracy after epoch 296: 72.21%\n",
      "Epoch: 297, Training Loss: 4.06309536562249e-06\n",
      "Validation Accuracy after epoch 297: 72.22%\n",
      "Epoch: 298, Training Loss: 4.040284157023271e-06\n",
      "Validation Accuracy after epoch 298: 72.22%\n",
      "Epoch: 299, Training Loss: 4.018445972497415e-06\n",
      "Validation Accuracy after epoch 299: 72.22%\n",
      "Epoch: 300, Training Loss: 4.000640738767837e-06\n",
      "Validation Accuracy after epoch 300: 72.21%\n",
      "Total Training Time: 1987.6897485256195 seconds\n"
     ]
    }
   ],
   "source": [
    "training_loop(\n",
    "    n_epochs=300,\n",
    "    optimizer=optimizer,\n",
    "    model=model,\n",
    "    loss_fn=loss_fn,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "10e9a8de-492f-496c-9e15-a6628d936ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2b ) weight decay \n",
    "model = ResNet10(n_chans1=32, n_blocks=10).to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-2, weight_decay=0.001)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "58a05f2d-d28e-4584-9095-f448b40fb66c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Training Loss: 2.0863163876716437\n",
      "Validation Accuracy after epoch 1: 31.540000000000003%\n",
      "Epoch: 2, Training Loss: 1.7833486260355587\n",
      "Validation Accuracy after epoch 2: 20.830000000000002%\n",
      "Epoch: 3, Training Loss: 1.6215860675972746\n",
      "Validation Accuracy after epoch 3: 43.1%\n",
      "Epoch: 4, Training Loss: 1.5115983608128774\n",
      "Validation Accuracy after epoch 4: 30.659999999999997%\n",
      "Epoch: 5, Training Loss: 1.4346572540300278\n",
      "Validation Accuracy after epoch 5: 49.519999999999996%\n",
      "Epoch: 6, Training Loss: 1.3648563983952602\n",
      "Validation Accuracy after epoch 6: 38.84%\n",
      "Epoch: 7, Training Loss: 1.29775622372737\n",
      "Validation Accuracy after epoch 7: 53.47%\n",
      "Epoch: 8, Training Loss: 1.2440070105940484\n",
      "Validation Accuracy after epoch 8: 48.72%\n",
      "Epoch: 9, Training Loss: 1.1891172707385724\n",
      "Validation Accuracy after epoch 9: 52.54%\n",
      "Epoch: 10, Training Loss: 1.1430731984355567\n",
      "Validation Accuracy after epoch 10: 54.169999999999995%\n",
      "Epoch: 11, Training Loss: 1.0930197679478189\n",
      "Validation Accuracy after epoch 11: 53.839999999999996%\n",
      "Epoch: 12, Training Loss: 1.0536760437823927\n",
      "Validation Accuracy after epoch 12: 56.8%\n",
      "Epoch: 13, Training Loss: 1.009295738261679\n",
      "Validation Accuracy after epoch 13: 60.28%\n",
      "Epoch: 14, Training Loss: 0.9761831655984035\n",
      "Validation Accuracy after epoch 14: 49.51%\n",
      "Epoch: 15, Training Loss: 0.9387384906906606\n",
      "Validation Accuracy after epoch 15: 62.43%\n",
      "Epoch: 16, Training Loss: 0.9067171034605607\n",
      "Validation Accuracy after epoch 16: 62.91%\n",
      "Epoch: 17, Training Loss: 0.876117320926598\n",
      "Validation Accuracy after epoch 17: 62.79%\n",
      "Epoch: 18, Training Loss: 0.8416577097018967\n",
      "Validation Accuracy after epoch 18: 54.190000000000005%\n",
      "Epoch: 19, Training Loss: 0.8174007875687631\n",
      "Validation Accuracy after epoch 19: 58.64%\n",
      "Epoch: 20, Training Loss: 0.7907662524286744\n",
      "Validation Accuracy after epoch 20: 60.040000000000006%\n",
      "Epoch: 21, Training Loss: 0.7637709986294627\n",
      "Validation Accuracy after epoch 21: 67.62%\n",
      "Epoch: 22, Training Loss: 0.7387804772390429\n",
      "Validation Accuracy after epoch 22: 68.32000000000001%\n",
      "Epoch: 23, Training Loss: 0.7154259350141297\n",
      "Validation Accuracy after epoch 23: 68.47999999999999%\n",
      "Epoch: 24, Training Loss: 0.6946824811913473\n",
      "Validation Accuracy after epoch 24: 70.27%\n",
      "Epoch: 25, Training Loss: 0.6717690838038769\n",
      "Validation Accuracy after epoch 25: 65.36%\n",
      "Epoch: 26, Training Loss: 0.6516270366166254\n",
      "Validation Accuracy after epoch 26: 70.08%\n",
      "Epoch: 27, Training Loss: 0.6290538807964081\n",
      "Validation Accuracy after epoch 27: 68.46%\n",
      "Epoch: 28, Training Loss: 0.6100641655952425\n",
      "Validation Accuracy after epoch 28: 58.589999999999996%\n",
      "Epoch: 29, Training Loss: 0.5892302807792068\n",
      "Validation Accuracy after epoch 29: 61.12%\n",
      "Epoch: 30, Training Loss: 0.5716136851350365\n",
      "Validation Accuracy after epoch 30: 66.9%\n",
      "Epoch: 31, Training Loss: 0.5523856681059388\n",
      "Validation Accuracy after epoch 31: 70.19%\n",
      "Epoch: 32, Training Loss: 0.5355784391693752\n",
      "Validation Accuracy after epoch 32: 70.12%\n",
      "Epoch: 33, Training Loss: 0.5168581774739354\n",
      "Validation Accuracy after epoch 33: 67.49000000000001%\n",
      "Epoch: 34, Training Loss: 0.4977241563027167\n",
      "Validation Accuracy after epoch 34: 71.08%\n",
      "Epoch: 35, Training Loss: 0.48279587078429853\n",
      "Validation Accuracy after epoch 35: 65.49000000000001%\n",
      "Epoch: 36, Training Loss: 0.46473601298487704\n",
      "Validation Accuracy after epoch 36: 71.35000000000001%\n",
      "Epoch: 37, Training Loss: 0.4499219972497362\n",
      "Validation Accuracy after epoch 37: 60.760000000000005%\n",
      "Epoch: 38, Training Loss: 0.43448239835479374\n",
      "Validation Accuracy after epoch 38: 70.67%\n",
      "Epoch: 39, Training Loss: 0.4153403900849545\n",
      "Validation Accuracy after epoch 39: 66.35%\n",
      "Epoch: 40, Training Loss: 0.40393913857391117\n",
      "Validation Accuracy after epoch 40: 71.46000000000001%\n",
      "Epoch: 41, Training Loss: 0.3869880025306016\n",
      "Validation Accuracy after epoch 41: 64.11%\n",
      "Epoch: 42, Training Loss: 0.37672572708724406\n",
      "Validation Accuracy after epoch 42: 70.6%\n",
      "Epoch: 43, Training Loss: 0.35975664702560894\n",
      "Validation Accuracy after epoch 43: 70.30999999999999%\n",
      "Epoch: 44, Training Loss: 0.34720697439730625\n",
      "Validation Accuracy after epoch 44: 70.99%\n",
      "Epoch: 45, Training Loss: 0.333405487849127\n",
      "Validation Accuracy after epoch 45: 71.3%\n",
      "Epoch: 46, Training Loss: 0.3250253981603381\n",
      "Validation Accuracy after epoch 46: 65.7%\n",
      "Epoch: 47, Training Loss: 0.30941136433835836\n",
      "Validation Accuracy after epoch 47: 72.17%\n",
      "Epoch: 48, Training Loss: 0.30176656648440436\n",
      "Validation Accuracy after epoch 48: 68.87%\n",
      "Epoch: 49, Training Loss: 0.2903369177809304\n",
      "Validation Accuracy after epoch 49: 64.75999999999999%\n",
      "Epoch: 50, Training Loss: 0.2732384658759207\n",
      "Validation Accuracy after epoch 50: 66.92%\n",
      "Epoch: 51, Training Loss: 0.2665305092902211\n",
      "Validation Accuracy after epoch 51: 68.52000000000001%\n",
      "Epoch: 52, Training Loss: 0.2494475500624808\n",
      "Validation Accuracy after epoch 52: 68.17999999999999%\n",
      "Epoch: 53, Training Loss: 0.2457674395988512\n",
      "Validation Accuracy after epoch 53: 69.28999999999999%\n",
      "Epoch: 54, Training Loss: 0.23576088687952826\n",
      "Validation Accuracy after epoch 54: 71.59%\n",
      "Epoch: 55, Training Loss: 0.22564156092417514\n",
      "Validation Accuracy after epoch 55: 66.81%\n",
      "Epoch: 56, Training Loss: 0.2135381410779703\n",
      "Validation Accuracy after epoch 56: 71.97%\n",
      "Epoch: 57, Training Loss: 0.20472641684153042\n",
      "Validation Accuracy after epoch 57: 71.89%\n",
      "Epoch: 58, Training Loss: 0.20042195845909816\n",
      "Validation Accuracy after epoch 58: 71.99%\n",
      "Epoch: 59, Training Loss: 0.18581914632578792\n",
      "Validation Accuracy after epoch 59: 70.58%\n",
      "Epoch: 60, Training Loss: 0.1897177617410984\n",
      "Validation Accuracy after epoch 60: 72.28999999999999%\n",
      "Epoch: 61, Training Loss: 0.1711084755599651\n",
      "Validation Accuracy after epoch 61: 70.24000000000001%\n",
      "Epoch: 62, Training Loss: 0.16736489306192112\n",
      "Validation Accuracy after epoch 62: 61.25000000000001%\n",
      "Epoch: 63, Training Loss: 0.16348757370448935\n",
      "Validation Accuracy after epoch 63: 64.86%\n",
      "Epoch: 64, Training Loss: 0.15630383845037588\n",
      "Validation Accuracy after epoch 64: 71.89%\n",
      "Epoch: 65, Training Loss: 0.15437583828254428\n",
      "Validation Accuracy after epoch 65: 65.21000000000001%\n",
      "Epoch: 66, Training Loss: 0.13928184138558558\n",
      "Validation Accuracy after epoch 66: 70.81%\n",
      "Epoch: 67, Training Loss: 0.1343067845501139\n",
      "Validation Accuracy after epoch 67: 68.52000000000001%\n",
      "Epoch: 68, Training Loss: 0.13384432010495526\n",
      "Validation Accuracy after epoch 68: 67.25999999999999%\n",
      "Epoch: 69, Training Loss: 0.1303213826521202\n",
      "Validation Accuracy after epoch 69: 67.97999999999999%\n",
      "Epoch: 70, Training Loss: 0.12295604403347463\n",
      "Validation Accuracy after epoch 70: 71.87%\n",
      "Epoch: 71, Training Loss: 0.11659963579152895\n",
      "Validation Accuracy after epoch 71: 62.739999999999995%\n",
      "Epoch: 72, Training Loss: 0.11940271921975114\n",
      "Validation Accuracy after epoch 72: 66.25999999999999%\n",
      "Epoch: 73, Training Loss: 0.11122567098721138\n",
      "Validation Accuracy after epoch 73: 69.16%\n",
      "Epoch: 74, Training Loss: 0.10874807269400572\n",
      "Validation Accuracy after epoch 74: 70.62%\n",
      "Epoch: 75, Training Loss: 0.10295981798878373\n",
      "Validation Accuracy after epoch 75: 71.34%\n",
      "Epoch: 76, Training Loss: 0.09691803818247031\n",
      "Validation Accuracy after epoch 76: 71.95%\n",
      "Epoch: 77, Training Loss: 0.09974414906928987\n",
      "Validation Accuracy after epoch 77: 71.21%\n",
      "Epoch: 78, Training Loss: 0.08915226478927561\n",
      "Validation Accuracy after epoch 78: 67.43%\n",
      "Epoch: 79, Training Loss: 0.0896170345847221\n",
      "Validation Accuracy after epoch 79: 68.30000000000001%\n",
      "Epoch: 80, Training Loss: 0.08868943557829198\n",
      "Validation Accuracy after epoch 80: 71.43%\n",
      "Epoch: 81, Training Loss: 0.0883888295706352\n",
      "Validation Accuracy after epoch 81: 66.3%\n",
      "Epoch: 82, Training Loss: 0.08774774720120575\n",
      "Validation Accuracy after epoch 82: 71.59%\n",
      "Epoch: 83, Training Loss: 0.0786356263272369\n",
      "Validation Accuracy after epoch 83: 67.22%\n",
      "Epoch: 84, Training Loss: 0.07565279671495966\n",
      "Validation Accuracy after epoch 84: 60.699999999999996%\n",
      "Epoch: 85, Training Loss: 0.08403337378021511\n",
      "Validation Accuracy after epoch 85: 71.48%\n",
      "Epoch: 86, Training Loss: 0.06863451602540034\n",
      "Validation Accuracy after epoch 86: 60.870000000000005%\n",
      "Epoch: 87, Training Loss: 0.09264228391208593\n",
      "Validation Accuracy after epoch 87: 71.85000000000001%\n",
      "Epoch: 88, Training Loss: 0.06601893790947545\n",
      "Validation Accuracy after epoch 88: 71.37%\n",
      "Epoch: 89, Training Loss: 0.06867369139329423\n",
      "Validation Accuracy after epoch 89: 72.07000000000001%\n",
      "Epoch: 90, Training Loss: 0.06517250277012672\n",
      "Validation Accuracy after epoch 90: 71.16%\n",
      "Epoch: 91, Training Loss: 0.06256740849793833\n",
      "Validation Accuracy after epoch 91: 62.160000000000004%\n",
      "Epoch: 92, Training Loss: 0.07452820156655653\n",
      "Validation Accuracy after epoch 92: 65.32%\n",
      "Epoch: 93, Training Loss: 0.06646462429857924\n",
      "Validation Accuracy after epoch 93: 70.64%\n",
      "Epoch: 94, Training Loss: 0.057861583842717286\n",
      "Validation Accuracy after epoch 94: 69.86%\n",
      "Epoch: 95, Training Loss: 0.061960185213428935\n",
      "Validation Accuracy after epoch 95: 71.8%\n",
      "Epoch: 96, Training Loss: 0.05129818681834737\n",
      "Validation Accuracy after epoch 96: 61.78%\n",
      "Epoch: 97, Training Loss: 0.06142959762346762\n",
      "Validation Accuracy after epoch 97: 71.44%\n",
      "Epoch: 98, Training Loss: 0.08067992478942551\n",
      "Validation Accuracy after epoch 98: 72.42%\n",
      "Epoch: 99, Training Loss: 0.04221497886770112\n",
      "Validation Accuracy after epoch 99: 71.53%\n",
      "Epoch: 100, Training Loss: 0.051259099901237\n",
      "Validation Accuracy after epoch 100: 69.86%\n",
      "Epoch: 101, Training Loss: 0.06875968364167416\n",
      "Validation Accuracy after epoch 101: 72.32%\n",
      "Epoch: 102, Training Loss: 0.03865689329822045\n",
      "Validation Accuracy after epoch 102: 65.97%\n",
      "Epoch: 103, Training Loss: 0.04443061368449417\n",
      "Validation Accuracy after epoch 103: 71.41%\n",
      "Epoch: 104, Training Loss: 0.07019381709408748\n",
      "Validation Accuracy after epoch 104: 72.38%\n",
      "Epoch: 105, Training Loss: 0.03181769348629762\n",
      "Validation Accuracy after epoch 105: 72.19%\n",
      "Epoch: 106, Training Loss: 0.05497921257407245\n",
      "Validation Accuracy after epoch 106: 72.04%\n",
      "Epoch: 107, Training Loss: 0.036660462416305925\n",
      "Validation Accuracy after epoch 107: 71.6%\n",
      "Epoch: 108, Training Loss: 0.04041456976486251\n",
      "Validation Accuracy after epoch 108: 67.91%\n",
      "Epoch: 109, Training Loss: 0.059451297772012156\n",
      "Validation Accuracy after epoch 109: 70.54%\n",
      "Epoch: 110, Training Loss: 0.05564020636617718\n",
      "Validation Accuracy after epoch 110: 72.25%\n",
      "Epoch: 111, Training Loss: 0.04642433523694101\n",
      "Validation Accuracy after epoch 111: 72.2%\n",
      "Epoch: 112, Training Loss: 0.04998788657664295\n",
      "Validation Accuracy after epoch 112: 72.11999999999999%\n",
      "Epoch: 113, Training Loss: 0.045670876115568866\n",
      "Validation Accuracy after epoch 113: 71.08%\n",
      "Epoch: 114, Training Loss: 0.03549946661737254\n",
      "Validation Accuracy after epoch 114: 65.85%\n",
      "Epoch: 115, Training Loss: 0.060695332711410074\n",
      "Validation Accuracy after epoch 115: 71.22%\n",
      "Epoch: 116, Training Loss: 0.04519676912562264\n",
      "Validation Accuracy after epoch 116: 60.19%\n",
      "Epoch: 117, Training Loss: 0.060703282368362255\n",
      "Validation Accuracy after epoch 117: 72.3%\n",
      "Epoch: 118, Training Loss: 0.052791087095902\n",
      "Validation Accuracy after epoch 118: 71.17999999999999%\n",
      "Epoch: 119, Training Loss: 0.05332256941502328\n",
      "Validation Accuracy after epoch 119: 65.47%\n",
      "Epoch: 120, Training Loss: 0.046772388589527945\n",
      "Validation Accuracy after epoch 120: 59.41%\n",
      "Epoch: 121, Training Loss: 0.07487593201326107\n",
      "Validation Accuracy after epoch 121: 71.03%\n",
      "Epoch: 122, Training Loss: 0.0517776792876713\n",
      "Validation Accuracy after epoch 122: 72.39%\n",
      "Epoch: 123, Training Loss: 0.055875009605827766\n",
      "Validation Accuracy after epoch 123: 71.78%\n",
      "Epoch: 124, Training Loss: 0.03442223937369173\n",
      "Validation Accuracy after epoch 124: 71.55%\n",
      "Epoch: 125, Training Loss: 0.04627967035830202\n",
      "Validation Accuracy after epoch 125: 70.07%\n",
      "Epoch: 126, Training Loss: 0.04820252977200853\n",
      "Validation Accuracy after epoch 126: 71.53%\n",
      "Epoch: 127, Training Loss: 0.043732448106916275\n",
      "Validation Accuracy after epoch 127: 72.24000000000001%\n",
      "Epoch: 128, Training Loss: 0.05147623417921641\n",
      "Validation Accuracy after epoch 128: 61.160000000000004%\n",
      "Epoch: 129, Training Loss: 0.04755251971549829\n",
      "Validation Accuracy after epoch 129: 71.53%\n",
      "Epoch: 130, Training Loss: 0.031361160328989265\n",
      "Validation Accuracy after epoch 130: 70.86%\n",
      "Epoch: 131, Training Loss: 0.04716054906966188\n",
      "Validation Accuracy after epoch 131: 71.67999999999999%\n",
      "Epoch: 132, Training Loss: 0.04954687480548578\n",
      "Validation Accuracy after epoch 132: 72.38%\n",
      "Epoch: 133, Training Loss: 0.03380108676168084\n",
      "Validation Accuracy after epoch 133: 66.63%\n",
      "Epoch: 134, Training Loss: 0.043732460961281736\n",
      "Validation Accuracy after epoch 134: 71.67999999999999%\n",
      "Epoch: 135, Training Loss: 0.04631756439470374\n",
      "Validation Accuracy after epoch 135: 70.12%\n",
      "Epoch: 136, Training Loss: 0.06579384220677102\n",
      "Validation Accuracy after epoch 136: 69.08%\n",
      "Epoch: 137, Training Loss: 0.038689720699839926\n",
      "Validation Accuracy after epoch 137: 70.67%\n",
      "Epoch: 138, Training Loss: 0.04418429306841067\n",
      "Validation Accuracy after epoch 138: 72.45%\n",
      "Epoch: 139, Training Loss: 0.04929818732448427\n",
      "Validation Accuracy after epoch 139: 72.16%\n",
      "Epoch: 140, Training Loss: 0.03690978992448124\n",
      "Validation Accuracy after epoch 140: 72.49%\n",
      "Epoch: 141, Training Loss: 0.024690263839873255\n",
      "Validation Accuracy after epoch 141: 68.64%\n",
      "Epoch: 142, Training Loss: 0.04824650952892611\n",
      "Validation Accuracy after epoch 142: 71.07%\n",
      "Epoch: 143, Training Loss: 0.05312778765056997\n",
      "Validation Accuracy after epoch 143: 71.32%\n",
      "Epoch: 144, Training Loss: 0.03242026351291336\n",
      "Validation Accuracy after epoch 144: 69.96%\n",
      "Epoch: 145, Training Loss: 0.05356118441148497\n",
      "Validation Accuracy after epoch 145: 71.92%\n",
      "Epoch: 146, Training Loss: 0.26657824595699975\n",
      "Validation Accuracy after epoch 146: 72.44%\n",
      "Epoch: 147, Training Loss: 0.08476994378144478\n",
      "Validation Accuracy after epoch 147: 69.93%\n",
      "Epoch: 148, Training Loss: 0.06375828206889293\n",
      "Validation Accuracy after epoch 148: 67.75999999999999%\n",
      "Epoch: 149, Training Loss: 0.06238052038335339\n",
      "Validation Accuracy after epoch 149: 71.47%\n",
      "Epoch: 150, Training Loss: 0.05070886199134509\n",
      "Validation Accuracy after epoch 150: 72.15%\n",
      "Epoch: 151, Training Loss: 0.04867585571235655\n",
      "Validation Accuracy after epoch 151: 72.27%\n",
      "Epoch: 152, Training Loss: 0.04934325020806745\n",
      "Validation Accuracy after epoch 152: 71.91%\n",
      "Epoch: 153, Training Loss: 0.044387340318331796\n",
      "Validation Accuracy after epoch 153: 70.74000000000001%\n",
      "Epoch: 154, Training Loss: 0.05097489600109122\n",
      "Validation Accuracy after epoch 154: 69.35%\n",
      "Epoch: 155, Training Loss: 0.043183614053112\n",
      "Validation Accuracy after epoch 155: 57.52%\n",
      "Epoch: 156, Training Loss: 0.05020626792026198\n",
      "Validation Accuracy after epoch 156: 72.00999999999999%\n",
      "Epoch: 157, Training Loss: 0.02546758148977009\n",
      "Validation Accuracy after epoch 157: 72.00999999999999%\n",
      "Epoch: 158, Training Loss: 0.0500422994769357\n",
      "Validation Accuracy after epoch 158: 72.11999999999999%\n",
      "Epoch: 159, Training Loss: 0.035619340797551594\n",
      "Validation Accuracy after epoch 159: 72.15%\n",
      "Epoch: 160, Training Loss: 0.04467116607769328\n",
      "Validation Accuracy after epoch 160: 68.73%\n",
      "Epoch: 161, Training Loss: 0.03657997779704778\n",
      "Validation Accuracy after epoch 161: 70.65%\n",
      "Epoch: 162, Training Loss: 0.05564023501149205\n",
      "Validation Accuracy after epoch 162: 72.44%\n",
      "Epoch: 163, Training Loss: 0.025582084385201792\n",
      "Validation Accuracy after epoch 163: 72.16%\n",
      "Epoch: 164, Training Loss: 0.034806803857442885\n",
      "Validation Accuracy after epoch 164: 72.46000000000001%\n",
      "Epoch: 165, Training Loss: 0.025384355425339518\n",
      "Validation Accuracy after epoch 165: 72.28999999999999%\n",
      "Epoch: 166, Training Loss: 0.0416776169041741\n",
      "Validation Accuracy after epoch 166: 71.39%\n",
      "Epoch: 167, Training Loss: 0.049728311061182674\n",
      "Validation Accuracy after epoch 167: 71.28%\n",
      "Epoch: 168, Training Loss: 0.039445507707838875\n",
      "Validation Accuracy after epoch 168: 71.52%\n",
      "Epoch: 169, Training Loss: 0.04038676433473625\n",
      "Validation Accuracy after epoch 169: 72.15%\n",
      "Epoch: 170, Training Loss: 0.05727091186460765\n",
      "Validation Accuracy after epoch 170: 72.2%\n",
      "Epoch: 171, Training Loss: 0.030073062431000535\n",
      "Validation Accuracy after epoch 171: 72.23%\n",
      "Epoch: 172, Training Loss: 0.04600203704044861\n",
      "Validation Accuracy after epoch 172: 72.18%\n",
      "Epoch: 173, Training Loss: 0.036430862178216755\n",
      "Validation Accuracy after epoch 173: 72.24000000000001%\n",
      "Epoch: 174, Training Loss: 0.05024179386104817\n",
      "Validation Accuracy after epoch 174: 71.44%\n",
      "Epoch: 175, Training Loss: 0.03530141381342012\n",
      "Validation Accuracy after epoch 175: 70.58%\n",
      "Epoch: 176, Training Loss: 0.045783147734650614\n",
      "Validation Accuracy after epoch 176: 70.56%\n",
      "Epoch: 177, Training Loss: 0.040413419408199695\n",
      "Validation Accuracy after epoch 177: 70.63000000000001%\n",
      "Epoch: 178, Training Loss: 0.043554843398039715\n",
      "Validation Accuracy after epoch 178: 72.05%\n",
      "Epoch: 179, Training Loss: 0.03574962610938012\n",
      "Validation Accuracy after epoch 179: 72.08%\n",
      "Epoch: 180, Training Loss: 0.03794732350012576\n",
      "Validation Accuracy after epoch 180: 71.78%\n",
      "Epoch: 181, Training Loss: 0.03397905152163628\n",
      "Validation Accuracy after epoch 181: 71.34%\n",
      "Epoch: 182, Training Loss: 0.02520594283629654\n",
      "Validation Accuracy after epoch 182: 71.61%\n",
      "Epoch: 183, Training Loss: 0.04125020310626296\n",
      "Validation Accuracy after epoch 183: 71.47%\n",
      "Epoch: 184, Training Loss: 0.01874513994257622\n",
      "Validation Accuracy after epoch 184: 69.98%\n",
      "Epoch: 185, Training Loss: 0.05869923449878264\n",
      "Validation Accuracy after epoch 185: 71.21%\n",
      "Epoch: 186, Training Loss: 0.019022836322810432\n",
      "Validation Accuracy after epoch 186: 71.46000000000001%\n",
      "Epoch: 187, Training Loss: 0.05153181448387092\n",
      "Validation Accuracy after epoch 187: 70.15%\n",
      "Epoch: 188, Training Loss: 0.03411323569915698\n",
      "Validation Accuracy after epoch 188: 70.97%\n",
      "Epoch: 189, Training Loss: 0.02923890499679772\n",
      "Validation Accuracy after epoch 189: 71.73%\n",
      "Epoch: 190, Training Loss: 0.04068524239967694\n",
      "Validation Accuracy after epoch 190: 67.38%\n",
      "Epoch: 191, Training Loss: 0.04988253688516543\n",
      "Validation Accuracy after epoch 191: 66.11%\n",
      "Epoch: 192, Training Loss: 0.043309821589740324\n",
      "Validation Accuracy after epoch 192: 72.07000000000001%\n",
      "Epoch: 193, Training Loss: 0.029740416930224438\n",
      "Validation Accuracy after epoch 193: 67.61%\n",
      "Epoch: 194, Training Loss: 0.03264714634064418\n",
      "Validation Accuracy after epoch 194: 71.88%\n",
      "Epoch: 195, Training Loss: 0.0496075773132903\n",
      "Validation Accuracy after epoch 195: 71.5%\n",
      "Epoch: 196, Training Loss: 0.030658943186331864\n",
      "Validation Accuracy after epoch 196: 70.50999999999999%\n",
      "Epoch: 197, Training Loss: 0.028753381425096793\n",
      "Validation Accuracy after epoch 197: 71.63000000000001%\n",
      "Epoch: 198, Training Loss: 0.05628364320393042\n",
      "Validation Accuracy after epoch 198: 71.53%\n",
      "Epoch: 199, Training Loss: 0.04538135488381814\n",
      "Validation Accuracy after epoch 199: 71.44%\n",
      "Epoch: 200, Training Loss: 0.04696144890221779\n",
      "Validation Accuracy after epoch 200: 70.89999999999999%\n",
      "Epoch: 201, Training Loss: 0.045197925461894446\n",
      "Validation Accuracy after epoch 201: 70.52000000000001%\n",
      "Epoch: 202, Training Loss: 0.04356814631337748\n",
      "Validation Accuracy after epoch 202: 72.02%\n",
      "Epoch: 203, Training Loss: 0.04713328374261537\n",
      "Validation Accuracy after epoch 203: 72.2%\n",
      "Epoch: 204, Training Loss: 0.03977679319279578\n",
      "Validation Accuracy after epoch 204: 69.94%\n",
      "Epoch: 205, Training Loss: 0.04580819901377272\n",
      "Validation Accuracy after epoch 205: 70.57%\n",
      "Epoch: 206, Training Loss: 0.046452239377732574\n",
      "Validation Accuracy after epoch 206: 71.15%\n",
      "Epoch: 207, Training Loss: 0.045370299009132246\n",
      "Validation Accuracy after epoch 207: 70.22%\n",
      "Epoch: 208, Training Loss: 0.042727107704971984\n",
      "Validation Accuracy after epoch 208: 64.4%\n",
      "Epoch: 209, Training Loss: 0.05296896459460925\n",
      "Validation Accuracy after epoch 209: 72.39999999999999%\n",
      "Epoch: 210, Training Loss: 0.04266152285357111\n",
      "Validation Accuracy after epoch 210: 72.24000000000001%\n",
      "Epoch: 211, Training Loss: 0.014138667198443484\n",
      "Validation Accuracy after epoch 211: 72.33000000000001%\n",
      "Epoch: 212, Training Loss: 0.024128432751896276\n",
      "Validation Accuracy after epoch 212: 72.61%\n",
      "Epoch: 213, Training Loss: 0.018191900167404615\n",
      "Validation Accuracy after epoch 213: 71.58%\n",
      "Epoch: 214, Training Loss: 0.049634827525697915\n",
      "Validation Accuracy after epoch 214: 71.94%\n",
      "Epoch: 215, Training Loss: 0.008665014469377992\n",
      "Validation Accuracy after epoch 215: 72.76%\n",
      "Epoch: 216, Training Loss: 0.049628266758542115\n",
      "Validation Accuracy after epoch 216: 72.33000000000001%\n",
      "Epoch: 217, Training Loss: 0.044840057977237634\n",
      "Validation Accuracy after epoch 217: 72.46000000000001%\n",
      "Epoch: 218, Training Loss: 0.03270458073846227\n",
      "Validation Accuracy after epoch 218: 70.66%\n",
      "Epoch: 219, Training Loss: 0.054499984112814724\n",
      "Validation Accuracy after epoch 219: 71.49%\n",
      "Epoch: 220, Training Loss: 0.05100990816518483\n",
      "Validation Accuracy after epoch 220: 70.69%\n",
      "Epoch: 221, Training Loss: 0.03818476194134125\n",
      "Validation Accuracy after epoch 221: 70.08%\n",
      "Epoch: 222, Training Loss: 0.046085392841158195\n",
      "Validation Accuracy after epoch 222: 71.91%\n",
      "Epoch: 223, Training Loss: 0.04544058877378083\n",
      "Validation Accuracy after epoch 223: 72.00999999999999%\n",
      "Epoch: 224, Training Loss: 0.05544039686216408\n",
      "Validation Accuracy after epoch 224: 72.32%\n",
      "Epoch: 225, Training Loss: 0.03701198384727892\n",
      "Validation Accuracy after epoch 225: 70.53%\n",
      "Epoch: 226, Training Loss: 0.035142058694778044\n",
      "Validation Accuracy after epoch 226: 71.93%\n",
      "Epoch: 227, Training Loss: 0.048876892461184214\n",
      "Validation Accuracy after epoch 227: 65.60000000000001%\n",
      "Epoch: 228, Training Loss: 0.03741985199647858\n",
      "Validation Accuracy after epoch 228: 71.96000000000001%\n",
      "Epoch: 229, Training Loss: 0.03784558107934135\n",
      "Validation Accuracy after epoch 229: 71.5%\n",
      "Epoch: 230, Training Loss: 0.03825645585155264\n",
      "Validation Accuracy after epoch 230: 72.26%\n",
      "Epoch: 231, Training Loss: 0.04494854602221366\n",
      "Validation Accuracy after epoch 231: 71.75%\n",
      "Epoch: 232, Training Loss: 0.05393762125834928\n",
      "Validation Accuracy after epoch 232: 71.59%\n",
      "Epoch: 233, Training Loss: 0.03466338258975928\n",
      "Validation Accuracy after epoch 233: 72.14%\n",
      "Epoch: 234, Training Loss: 0.042142926381699634\n",
      "Validation Accuracy after epoch 234: 67.05%\n",
      "Epoch: 235, Training Loss: 0.050335821386276625\n",
      "Validation Accuracy after epoch 235: 72.33000000000001%\n",
      "Epoch: 236, Training Loss: 0.03449835733670141\n",
      "Validation Accuracy after epoch 236: 72.89%\n",
      "Epoch: 237, Training Loss: 0.05051168722584081\n",
      "Validation Accuracy after epoch 237: 72.61%\n",
      "Epoch: 238, Training Loss: 0.01360263579438412\n",
      "Validation Accuracy after epoch 238: 70.5%\n",
      "Epoch: 239, Training Loss: 0.004710932793144835\n",
      "Validation Accuracy after epoch 239: 72.96000000000001%\n",
      "Epoch: 240, Training Loss: 0.0010442814456134895\n",
      "Validation Accuracy after epoch 240: 73.02%\n",
      "Epoch: 241, Training Loss: 0.0006744167515225714\n",
      "Validation Accuracy after epoch 241: 73.03%\n",
      "Epoch: 242, Training Loss: 0.0006531492255486981\n",
      "Validation Accuracy after epoch 242: 72.94%\n",
      "Epoch: 243, Training Loss: 0.0006730302519340943\n",
      "Validation Accuracy after epoch 243: 73.22999999999999%\n",
      "Epoch: 244, Training Loss: 0.0007278079272537698\n",
      "Validation Accuracy after epoch 244: 73.11999999999999%\n",
      "Epoch: 245, Training Loss: 0.0007917552413341478\n",
      "Validation Accuracy after epoch 245: 73.07000000000001%\n",
      "Epoch: 246, Training Loss: 0.0008607025358561978\n",
      "Validation Accuracy after epoch 246: 72.98%\n",
      "Epoch: 247, Training Loss: 0.0009256506285792731\n",
      "Validation Accuracy after epoch 247: 73.22%\n",
      "Epoch: 248, Training Loss: 0.0010005183981249496\n",
      "Validation Accuracy after epoch 248: 73.06%\n",
      "Epoch: 249, Training Loss: 0.001084706124812698\n",
      "Validation Accuracy after epoch 249: 73.1%\n",
      "Epoch: 250, Training Loss: 0.001158285368823588\n",
      "Validation Accuracy after epoch 250: 72.87%\n",
      "Epoch: 251, Training Loss: 0.030228122344972682\n",
      "Validation Accuracy after epoch 251: 50.92%\n",
      "Epoch: 252, Training Loss: 0.13218292734964424\n",
      "Validation Accuracy after epoch 252: 70.38%\n",
      "Epoch: 253, Training Loss: 0.10231637764040885\n",
      "Validation Accuracy after epoch 253: 71.85000000000001%\n",
      "Epoch: 254, Training Loss: 0.07333616508097124\n",
      "Validation Accuracy after epoch 254: 68.53%\n",
      "Epoch: 255, Training Loss: 0.06632214581863026\n",
      "Validation Accuracy after epoch 255: 68.72%\n",
      "Epoch: 256, Training Loss: 0.08006595639342828\n",
      "Validation Accuracy after epoch 256: 69.78%\n",
      "Epoch: 257, Training Loss: 0.06746371795454294\n",
      "Validation Accuracy after epoch 257: 68.7%\n",
      "Epoch: 258, Training Loss: 0.05651721352493376\n",
      "Validation Accuracy after epoch 258: 70.35%\n",
      "Epoch: 259, Training Loss: 0.09422033484858434\n",
      "Validation Accuracy after epoch 259: 71.99%\n",
      "Epoch: 260, Training Loss: 0.05853396786949681\n",
      "Validation Accuracy after epoch 260: 71.24000000000001%\n",
      "Epoch: 261, Training Loss: 0.054777730646355036\n",
      "Validation Accuracy after epoch 261: 71.71%\n",
      "Epoch: 262, Training Loss: 0.051053558308047614\n",
      "Validation Accuracy after epoch 262: 70.12%\n",
      "Epoch: 263, Training Loss: 0.0559056176216868\n",
      "Validation Accuracy after epoch 263: 71.14%\n",
      "Epoch: 264, Training Loss: 0.06213146771664274\n",
      "Validation Accuracy after epoch 264: 71.73%\n",
      "Epoch: 265, Training Loss: 0.04536005691952689\n",
      "Validation Accuracy after epoch 265: 63.019999999999996%\n",
      "Epoch: 266, Training Loss: 0.049793444748502225\n",
      "Validation Accuracy after epoch 266: 59.57%\n",
      "Epoch: 267, Training Loss: 0.05820716992872136\n",
      "Validation Accuracy after epoch 267: 69.84%\n",
      "Epoch: 268, Training Loss: 0.044140681624859145\n",
      "Validation Accuracy after epoch 268: 62.27%\n",
      "Epoch: 269, Training Loss: 0.055990928411245575\n",
      "Validation Accuracy after epoch 269: 64.74%\n",
      "Epoch: 270, Training Loss: 0.04830421292168848\n",
      "Validation Accuracy after epoch 270: 71.85000000000001%\n",
      "Epoch: 271, Training Loss: 0.0472490942692789\n",
      "Validation Accuracy after epoch 271: 65.94%\n",
      "Epoch: 272, Training Loss: 0.048912582291817754\n",
      "Validation Accuracy after epoch 272: 72.02%\n",
      "Epoch: 273, Training Loss: 0.04420154321077697\n",
      "Validation Accuracy after epoch 273: 65.10000000000001%\n",
      "Epoch: 274, Training Loss: 0.03346420220254809\n",
      "Validation Accuracy after epoch 274: 70.16%\n",
      "Epoch: 275, Training Loss: 0.051385880057367106\n",
      "Validation Accuracy after epoch 275: 71.78%\n",
      "Epoch: 276, Training Loss: 0.037932331049817795\n",
      "Validation Accuracy after epoch 276: 71.45%\n",
      "Epoch: 277, Training Loss: 0.043509788836216756\n",
      "Validation Accuracy after epoch 277: 70.89%\n",
      "Epoch: 278, Training Loss: 0.057351104807212255\n",
      "Validation Accuracy after epoch 278: 71.48%\n",
      "Epoch: 279, Training Loss: 0.031088744601531937\n",
      "Validation Accuracy after epoch 279: 57.08%\n",
      "Epoch: 280, Training Loss: 0.04708041415012101\n",
      "Validation Accuracy after epoch 280: 72.33000000000001%\n",
      "Epoch: 281, Training Loss: 0.038956768625556394\n",
      "Validation Accuracy after epoch 281: 71.61999999999999%\n",
      "Epoch: 282, Training Loss: 0.03900149858558474\n",
      "Validation Accuracy after epoch 282: 72.31%\n",
      "Epoch: 283, Training Loss: 0.028507482890701256\n",
      "Validation Accuracy after epoch 283: 72.61%\n",
      "Epoch: 284, Training Loss: 0.03769475191354018\n",
      "Validation Accuracy after epoch 284: 72.57000000000001%\n",
      "Epoch: 285, Training Loss: 0.02937485958354862\n",
      "Validation Accuracy after epoch 285: 54.17999999999999%\n",
      "Epoch: 286, Training Loss: 0.0778467887695438\n",
      "Validation Accuracy after epoch 286: 71.88%\n",
      "Epoch: 287, Training Loss: 0.02579761624825723\n",
      "Validation Accuracy after epoch 287: 71.74000000000001%\n",
      "Epoch: 288, Training Loss: 0.029843971167918523\n",
      "Validation Accuracy after epoch 288: 71.99%\n",
      "Epoch: 289, Training Loss: 0.06834291580967995\n",
      "Validation Accuracy after epoch 289: 72.45%\n",
      "Epoch: 290, Training Loss: 0.01687643552009794\n",
      "Validation Accuracy after epoch 290: 70.89999999999999%\n",
      "Epoch: 291, Training Loss: 0.048581387716210914\n",
      "Validation Accuracy after epoch 291: 72.04%\n",
      "Epoch: 292, Training Loss: 0.03753678597714704\n",
      "Validation Accuracy after epoch 292: 71.94%\n",
      "Epoch: 293, Training Loss: 0.042035673346752754\n",
      "Validation Accuracy after epoch 293: 72.11%\n",
      "Epoch: 294, Training Loss: 0.041233541945780355\n",
      "Validation Accuracy after epoch 294: 72.15%\n",
      "Epoch: 295, Training Loss: 0.049165626517166515\n",
      "Validation Accuracy after epoch 295: 71.75%\n",
      "Epoch: 296, Training Loss: 0.03324202072950761\n",
      "Validation Accuracy after epoch 296: 71.1%\n",
      "Epoch: 297, Training Loss: 0.035843393580122826\n",
      "Validation Accuracy after epoch 297: 71.67999999999999%\n",
      "Epoch: 298, Training Loss: 0.030112693079269687\n",
      "Validation Accuracy after epoch 298: 63.53%\n",
      "Epoch: 299, Training Loss: 0.03442168705362786\n",
      "Validation Accuracy after epoch 299: 48.07%\n",
      "Epoch: 300, Training Loss: 0.0791984148733818\n",
      "Validation Accuracy after epoch 300: 69.12%\n",
      "Total Training Time: 2316.558634519577 seconds\n"
     ]
    }
   ],
   "source": [
    "training_loop(\n",
    "    n_epochs=300,\n",
    "    optimizer=optimizer,\n",
    "    model=model,\n",
    "    loss_fn=loss_fn,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "705284c4-ba47-4eb8-9124-d43896bf7ab3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84a60fc3-ea6e-4292-8187-695689f0200c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 2 b) drop out\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, n_chans):\n",
    "        super(ResBlock, self).__init__()\n",
    "        self.conv = nn.Conv2d(n_chans, n_chans, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(n_chans, n_chans, kernel_size=3, padding=1)\n",
    "        self.dropout = nn.Dropout2d(p=0.3)\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = F.relu(self.conv(x))\n",
    "        out = self.dropout(out)\n",
    "        out = self.conv2(out)\n",
    "        out += residual  \n",
    "        return F.relu(out)\n",
    "\n",
    "class ResNet10(nn.Module):\n",
    "    def __init__(self, n_chans1=32, n_blocks=10):\n",
    "        super(ResNet10, self).__init__()\n",
    "        self.n_chans1 = n_chans1\n",
    "        self.conv1 = nn.Conv2d(3, n_chans1, kernel_size=3, padding=1)\n",
    "        self.conv1_dropout = nn.Dropout2d(p=0.3)\n",
    "        self.resblocks = nn.Sequential(*[ResBlock(n_chans1) for _ in range(n_blocks)])\n",
    "        \n",
    "  \n",
    "        self.fc1 = nn.Linear(n_chans1 * 8 * 8, 32)\n",
    "        self.fc2 = nn.Linear(32, 10) \n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.relu(self.conv1(x)), 2) \n",
    "        out = self.conv1_dropout(out)\n",
    "        out = self.resblocks(out)  \n",
    "        out = F.adaptive_avg_pool2d(out, (8, 8))  \n",
    "        out = out.view(out.size(0), -1)  \n",
    "        out = torch.relu(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94ea4716-bb8c-4337-8c41-4d3bd5823c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def validate(model, loader, device):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()  #\n",
    "    with torch.no_grad(): \n",
    "        for imgs, labels in loader:\n",
    "            imgs = imgs.to(device=device)\n",
    "            labels = labels.to(device=device)\n",
    "            outputs = model(imgs)\n",
    "            _, predicted = torch.max(outputs, dim=1)\n",
    "            total += labels.shape[0]\n",
    "            correct += int((predicted == labels).sum())\n",
    "    model.train()  \n",
    "    return correct / total\n",
    "\n",
    "def training_loop(n_epochs, optimizer, model, loss_fn, train_loader, val_loader, device):\n",
    "    total_start_time = time.time()\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        model.train()  \n",
    "        loss_train = 0.0\n",
    "        start_time = time.time()\n",
    "        \n",
    "        for imgs, labels in train_loader:\n",
    "            imgs = imgs.to(device=device)    \n",
    "            labels = labels.to(device=device) \n",
    "            outputs = model(imgs)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            loss_train += loss.item()\n",
    "          \n",
    "        val_accuracy = validate(model, val_loader, device) *100\n",
    "        avg_loss = loss_train / len(train_loader)\n",
    "        print(f\"Epoch: {epoch}, Training Loss: {avg_loss}\")\n",
    "        print(f'Validation Accuracy after epoch {epoch}: {val_accuracy}%')\n",
    "    end_time = time.time()  \n",
    "    duration = end_time - total_start_time\n",
    "    print(f'Total Training Time: {duration} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c24bab15-4378-4a5f-9dd5-b82d668e848e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available. Using GPU.\n"
     ]
    }
   ],
   "source": [
    "# Check if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available. Using GPU.\")\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    print(\"CUDA is not available. Using CPU.\")\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d4781d2c-0c4e-4609-8e9c-f40e63bc0874",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4e8d1871-40cd-4312-a233-c1aa5d57fb0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets\n",
    "data_path = '../data-unversioned/p1ch7/'\n",
    "cifar10 = datasets.CIFAR10(data_path, train=True, download=True, transform=transform)\n",
    "cifar10_val = datasets.CIFAR10(data_path, train=False, download=True, transform=transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "08e9f9fd-8f24-43e5-9e61-49039614177b",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e2b04e1b-6f55-4bbe-a368-64f43e1fd145",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(cifar10, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(cifar10_val, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "36b8e410-5103-4bba-aa55-edbea0902509",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet10(n_chans1=32, n_blocks=10).to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-2)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c6e95fc1-d146-4429-b18b-eb9377e4eb6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Training Loss: 2.188420028332859\n",
      "Validation Accuracy after epoch 1: 26.96%\n",
      "Epoch: 2, Training Loss: 1.9077004058586666\n",
      "Validation Accuracy after epoch 2: 37.91%\n",
      "Epoch: 3, Training Loss: 1.7624874541826565\n",
      "Validation Accuracy after epoch 3: 32.6%\n",
      "Epoch: 4, Training Loss: 1.6527273520789183\n",
      "Validation Accuracy after epoch 4: 38.73%\n",
      "Epoch: 5, Training Loss: 1.5709573911583943\n",
      "Validation Accuracy after epoch 5: 45.59%\n",
      "Epoch: 6, Training Loss: 1.5084244925957506\n",
      "Validation Accuracy after epoch 6: 41.839999999999996%\n",
      "Epoch: 7, Training Loss: 1.4505255758914801\n",
      "Validation Accuracy after epoch 7: 48.11%\n",
      "Epoch: 8, Training Loss: 1.3951543010104344\n",
      "Validation Accuracy after epoch 8: 51.62%\n",
      "Epoch: 9, Training Loss: 1.3519776779062607\n",
      "Validation Accuracy after epoch 9: 51.83%\n",
      "Epoch: 10, Training Loss: 1.3127172520703367\n",
      "Validation Accuracy after epoch 10: 53.49%\n",
      "Epoch: 11, Training Loss: 1.2804870741903935\n",
      "Validation Accuracy after epoch 11: 52.26%\n",
      "Epoch: 12, Training Loss: 1.244779103857172\n",
      "Validation Accuracy after epoch 12: 53.63%\n",
      "Epoch: 13, Training Loss: 1.2170998065367988\n",
      "Validation Accuracy after epoch 13: 55.769999999999996%\n",
      "Epoch: 14, Training Loss: 1.1881768503762267\n",
      "Validation Accuracy after epoch 14: 59.27%\n",
      "Epoch: 15, Training Loss: 1.1620467426374441\n",
      "Validation Accuracy after epoch 15: 48.010000000000005%\n",
      "Epoch: 16, Training Loss: 1.1377823130249063\n",
      "Validation Accuracy after epoch 16: 58.709999999999994%\n",
      "Epoch: 17, Training Loss: 1.11496674633392\n",
      "Validation Accuracy after epoch 17: 56.24%\n",
      "Epoch: 18, Training Loss: 1.093102418858072\n",
      "Validation Accuracy after epoch 18: 63.74999999999999%\n",
      "Epoch: 19, Training Loss: 1.0689715258300763\n",
      "Validation Accuracy after epoch 19: 59.489999999999995%\n",
      "Epoch: 20, Training Loss: 1.0471561041177082\n",
      "Validation Accuracy after epoch 20: 62.21%\n",
      "Epoch: 21, Training Loss: 1.0272114402650263\n",
      "Validation Accuracy after epoch 21: 63.970000000000006%\n",
      "Epoch: 22, Training Loss: 1.0090737383231483\n",
      "Validation Accuracy after epoch 22: 64.73%\n",
      "Epoch: 23, Training Loss: 0.9876547227887547\n",
      "Validation Accuracy after epoch 23: 64.87%\n",
      "Epoch: 24, Training Loss: 0.971738140677552\n",
      "Validation Accuracy after epoch 24: 66.02%\n",
      "Epoch: 25, Training Loss: 0.9542755752878116\n",
      "Validation Accuracy after epoch 25: 66.18%\n",
      "Epoch: 26, Training Loss: 0.9421621917763634\n",
      "Validation Accuracy after epoch 26: 54.1%\n",
      "Epoch: 27, Training Loss: 0.9264537487798334\n",
      "Validation Accuracy after epoch 27: 64.82%\n",
      "Epoch: 28, Training Loss: 0.9084036969162924\n",
      "Validation Accuracy after epoch 28: 68.21000000000001%\n",
      "Epoch: 29, Training Loss: 0.8941874541437534\n",
      "Validation Accuracy after epoch 29: 65.7%\n",
      "Epoch: 30, Training Loss: 0.8814595215537054\n",
      "Validation Accuracy after epoch 30: 66.71000000000001%\n",
      "Epoch: 31, Training Loss: 0.8667830653736354\n",
      "Validation Accuracy after epoch 31: 68.41000000000001%\n",
      "Epoch: 32, Training Loss: 0.8566908577976324\n",
      "Validation Accuracy after epoch 32: 69.46%\n",
      "Epoch: 33, Training Loss: 0.8466833059668846\n",
      "Validation Accuracy after epoch 33: 67.13%\n",
      "Epoch: 34, Training Loss: 0.8300719319097222\n",
      "Validation Accuracy after epoch 34: 67.4%\n",
      "Epoch: 35, Training Loss: 0.8210079240067231\n",
      "Validation Accuracy after epoch 35: 69.72%\n",
      "Epoch: 36, Training Loss: 0.8112188665305867\n",
      "Validation Accuracy after epoch 36: 69.75%\n",
      "Epoch: 37, Training Loss: 0.7986646935991619\n",
      "Validation Accuracy after epoch 37: 70.57%\n",
      "Epoch: 38, Training Loss: 0.7882725430647736\n",
      "Validation Accuracy after epoch 38: 66.42%\n",
      "Epoch: 39, Training Loss: 0.7787666928280345\n",
      "Validation Accuracy after epoch 39: 69.23%\n",
      "Epoch: 40, Training Loss: 0.7671678682879719\n",
      "Validation Accuracy after epoch 40: 62.68%\n",
      "Epoch: 41, Training Loss: 0.761062730037038\n",
      "Validation Accuracy after epoch 41: 68.61%\n",
      "Epoch: 42, Training Loss: 0.7524389158505613\n",
      "Validation Accuracy after epoch 42: 70.07%\n",
      "Epoch: 43, Training Loss: 0.7428450909874323\n",
      "Validation Accuracy after epoch 43: 69.78%\n",
      "Epoch: 44, Training Loss: 0.7311120900656561\n",
      "Validation Accuracy after epoch 44: 70.6%\n",
      "Epoch: 45, Training Loss: 0.7249760741696638\n",
      "Validation Accuracy after epoch 45: 71.06%\n",
      "Epoch: 46, Training Loss: 0.7124986140929219\n",
      "Validation Accuracy after epoch 46: 71.83%\n",
      "Epoch: 47, Training Loss: 0.7060807228774366\n",
      "Validation Accuracy after epoch 47: 71.34%\n",
      "Epoch: 48, Training Loss: 0.6933913967188667\n",
      "Validation Accuracy after epoch 48: 68.66%\n",
      "Epoch: 49, Training Loss: 0.6898345230409252\n",
      "Validation Accuracy after epoch 49: 70.59%\n",
      "Epoch: 50, Training Loss: 0.6808542234208578\n",
      "Validation Accuracy after epoch 50: 70.48%\n",
      "Epoch: 51, Training Loss: 0.6723074903116202\n",
      "Validation Accuracy after epoch 51: 71.81%\n",
      "Epoch: 52, Training Loss: 0.665599687401291\n",
      "Validation Accuracy after epoch 52: 72.13000000000001%\n",
      "Epoch: 53, Training Loss: 0.660919163728614\n",
      "Validation Accuracy after epoch 53: 72.27%\n",
      "Epoch: 54, Training Loss: 0.646067816087657\n",
      "Validation Accuracy after epoch 54: 69.08%\n",
      "Epoch: 55, Training Loss: 0.6431698580379681\n",
      "Validation Accuracy after epoch 55: 69.75%\n",
      "Epoch: 56, Training Loss: 0.6392138505454563\n",
      "Validation Accuracy after epoch 56: 72.59%\n",
      "Epoch: 57, Training Loss: 0.6261030903176579\n",
      "Validation Accuracy after epoch 57: 71.66%\n",
      "Epoch: 58, Training Loss: 0.6233075712343006\n",
      "Validation Accuracy after epoch 58: 72.58%\n",
      "Epoch: 59, Training Loss: 0.6137255135628269\n",
      "Validation Accuracy after epoch 59: 71.98%\n",
      "Epoch: 60, Training Loss: 0.6073698271875796\n",
      "Validation Accuracy after epoch 60: 72.11999999999999%\n",
      "Epoch: 61, Training Loss: 0.5992699848187854\n",
      "Validation Accuracy after epoch 61: 70.65%\n",
      "Epoch: 62, Training Loss: 0.5931241353378272\n",
      "Validation Accuracy after epoch 62: 72.92999999999999%\n",
      "Epoch: 63, Training Loss: 0.590794330896319\n",
      "Validation Accuracy after epoch 63: 73.15%\n",
      "Epoch: 64, Training Loss: 0.5813091830219455\n",
      "Validation Accuracy after epoch 64: 70.35%\n",
      "Epoch: 65, Training Loss: 0.5759179394339662\n",
      "Validation Accuracy after epoch 65: 71.27%\n",
      "Epoch: 66, Training Loss: 0.569467815387127\n",
      "Validation Accuracy after epoch 66: 69.47%\n",
      "Epoch: 67, Training Loss: 0.5651142734395879\n",
      "Validation Accuracy after epoch 67: 72.78%\n",
      "Epoch: 68, Training Loss: 0.5594291877944756\n",
      "Validation Accuracy after epoch 68: 71.78999999999999%\n",
      "Epoch: 69, Training Loss: 0.5551247053858265\n",
      "Validation Accuracy after epoch 69: 72.0%\n",
      "Epoch: 70, Training Loss: 0.5445991414587211\n",
      "Validation Accuracy after epoch 70: 74.22%\n",
      "Epoch: 71, Training Loss: 0.5419805660043531\n",
      "Validation Accuracy after epoch 71: 72.49%\n",
      "Epoch: 72, Training Loss: 0.5348875378556264\n",
      "Validation Accuracy after epoch 72: 73.8%\n",
      "Epoch: 73, Training Loss: 0.5302394013613692\n",
      "Validation Accuracy after epoch 73: 71.95%\n",
      "Epoch: 74, Training Loss: 0.5240707016166519\n",
      "Validation Accuracy after epoch 74: 73.58%\n",
      "Epoch: 75, Training Loss: 0.5193414033373909\n",
      "Validation Accuracy after epoch 75: 72.7%\n",
      "Epoch: 76, Training Loss: 0.5167182636497271\n",
      "Validation Accuracy after epoch 76: 72.15%\n",
      "Epoch: 77, Training Loss: 0.5050208857830834\n",
      "Validation Accuracy after epoch 77: 73.68%\n",
      "Epoch: 78, Training Loss: 0.5058634350900455\n",
      "Validation Accuracy after epoch 78: 72.55%\n",
      "Epoch: 79, Training Loss: 0.5001531301252068\n",
      "Validation Accuracy after epoch 79: 73.08%\n",
      "Epoch: 80, Training Loss: 0.4944070729681903\n",
      "Validation Accuracy after epoch 80: 74.21%\n",
      "Epoch: 81, Training Loss: 0.49125097836832254\n",
      "Validation Accuracy after epoch 81: 72.31%\n",
      "Epoch: 82, Training Loss: 0.48370842401252684\n",
      "Validation Accuracy after epoch 82: 73.28%\n",
      "Epoch: 83, Training Loss: 0.47769665744755885\n",
      "Validation Accuracy after epoch 83: 70.06%\n",
      "Epoch: 84, Training Loss: 0.47518596906796134\n",
      "Validation Accuracy after epoch 84: 71.6%\n",
      "Epoch: 85, Training Loss: 0.4691687813195426\n",
      "Validation Accuracy after epoch 85: 74.37%\n",
      "Epoch: 86, Training Loss: 0.46747329770146734\n",
      "Validation Accuracy after epoch 86: 74.00999999999999%\n",
      "Epoch: 87, Training Loss: 0.46203382421866096\n",
      "Validation Accuracy after epoch 87: 71.67999999999999%\n",
      "Epoch: 88, Training Loss: 0.45859429301203364\n",
      "Validation Accuracy after epoch 88: 74.0%\n",
      "Epoch: 89, Training Loss: 0.4507298022508621\n",
      "Validation Accuracy after epoch 89: 73.45%\n",
      "Epoch: 90, Training Loss: 0.44909611430085833\n",
      "Validation Accuracy after epoch 90: 73.14%\n",
      "Epoch: 91, Training Loss: 0.44338266562927714\n",
      "Validation Accuracy after epoch 91: 73.61999999999999%\n",
      "Epoch: 92, Training Loss: 0.43968477094417335\n",
      "Validation Accuracy after epoch 92: 73.95%\n",
      "Epoch: 93, Training Loss: 0.4366218480841278\n",
      "Validation Accuracy after epoch 93: 73.68%\n",
      "Epoch: 94, Training Loss: 0.4276724808927997\n",
      "Validation Accuracy after epoch 94: 73.27%\n",
      "Epoch: 95, Training Loss: 0.4270123552597697\n",
      "Validation Accuracy after epoch 95: 74.09%\n",
      "Epoch: 96, Training Loss: 0.4258013679014752\n",
      "Validation Accuracy after epoch 96: 72.96000000000001%\n",
      "Epoch: 97, Training Loss: 0.4175365279092813\n",
      "Validation Accuracy after epoch 97: 73.59%\n",
      "Epoch: 98, Training Loss: 0.41350329787377504\n",
      "Validation Accuracy after epoch 98: 73.1%\n",
      "Epoch: 99, Training Loss: 0.4145909464534591\n",
      "Validation Accuracy after epoch 99: 73.25%\n",
      "Epoch: 100, Training Loss: 0.4097309151802526\n",
      "Validation Accuracy after epoch 100: 74.06%\n",
      "Epoch: 101, Training Loss: 0.40372166245261115\n",
      "Validation Accuracy after epoch 101: 71.73%\n",
      "Epoch: 102, Training Loss: 0.40092649973947986\n",
      "Validation Accuracy after epoch 102: 73.11999999999999%\n",
      "Epoch: 103, Training Loss: 0.4030419657830997\n",
      "Validation Accuracy after epoch 103: 74.1%\n",
      "Epoch: 104, Training Loss: 0.39573140674844726\n",
      "Validation Accuracy after epoch 104: 72.85000000000001%\n",
      "Epoch: 105, Training Loss: 0.38908745001649003\n",
      "Validation Accuracy after epoch 105: 72.77%\n",
      "Epoch: 106, Training Loss: 0.3840751876992643\n",
      "Validation Accuracy after epoch 106: 72.92%\n",
      "Epoch: 107, Training Loss: 0.38161681544826465\n",
      "Validation Accuracy after epoch 107: 72.66%\n",
      "Epoch: 108, Training Loss: 0.3755572900137938\n",
      "Validation Accuracy after epoch 108: 73.05%\n",
      "Epoch: 109, Training Loss: 0.3787764559888169\n",
      "Validation Accuracy after epoch 109: 70.27%\n",
      "Epoch: 110, Training Loss: 0.37254616972583027\n",
      "Validation Accuracy after epoch 110: 72.92999999999999%\n",
      "Epoch: 111, Training Loss: 0.3704855856307022\n",
      "Validation Accuracy after epoch 111: 73.6%\n",
      "Epoch: 112, Training Loss: 0.3686468073397951\n",
      "Validation Accuracy after epoch 112: 72.7%\n",
      "Epoch: 113, Training Loss: 0.3639884274976943\n",
      "Validation Accuracy after epoch 113: 73.49%\n",
      "Epoch: 114, Training Loss: 0.36307772279471695\n",
      "Validation Accuracy after epoch 114: 73.47%\n",
      "Epoch: 115, Training Loss: 0.35642651357995275\n",
      "Validation Accuracy after epoch 115: 72.35000000000001%\n",
      "Epoch: 116, Training Loss: 0.3534710982342815\n",
      "Validation Accuracy after epoch 116: 74.21%\n",
      "Epoch: 117, Training Loss: 0.3515472583606115\n",
      "Validation Accuracy after epoch 117: 73.56%\n",
      "Epoch: 118, Training Loss: 0.34741069325019636\n",
      "Validation Accuracy after epoch 118: 74.46000000000001%\n",
      "Epoch: 119, Training Loss: 0.337623472818557\n",
      "Validation Accuracy after epoch 119: 72.49%\n",
      "Epoch: 120, Training Loss: 0.34093636290534685\n",
      "Validation Accuracy after epoch 120: 73.50999999999999%\n",
      "Epoch: 121, Training Loss: 0.3379484092354622\n",
      "Validation Accuracy after epoch 121: 72.89999999999999%\n",
      "Epoch: 122, Training Loss: 0.3335661446232625\n",
      "Validation Accuracy after epoch 122: 72.65%\n",
      "Epoch: 123, Training Loss: 0.33358880528784773\n",
      "Validation Accuracy after epoch 123: 71.82%\n",
      "Epoch: 124, Training Loss: 0.3293077095657054\n",
      "Validation Accuracy after epoch 124: 72.89999999999999%\n",
      "Epoch: 125, Training Loss: 0.3298886161288032\n",
      "Validation Accuracy after epoch 125: 71.89999999999999%\n",
      "Epoch: 126, Training Loss: 0.32908055331091135\n",
      "Validation Accuracy after epoch 126: 73.83%\n",
      "Epoch: 127, Training Loss: 0.32401316254721274\n",
      "Validation Accuracy after epoch 127: 71.32%\n",
      "Epoch: 128, Training Loss: 0.32256984199061417\n",
      "Validation Accuracy after epoch 128: 73.09%\n",
      "Epoch: 129, Training Loss: 0.3161389695294678\n",
      "Validation Accuracy after epoch 129: 72.32%\n",
      "Epoch: 130, Training Loss: 0.3135475945537505\n",
      "Validation Accuracy after epoch 130: 73.07000000000001%\n",
      "Epoch: 131, Training Loss: 0.3102967395254261\n",
      "Validation Accuracy after epoch 131: 73.15%\n",
      "Epoch: 132, Training Loss: 0.3082999311044545\n",
      "Validation Accuracy after epoch 132: 73.53%\n",
      "Epoch: 133, Training Loss: 0.3053117030397858\n",
      "Validation Accuracy after epoch 133: 73.32%\n",
      "Epoch: 134, Training Loss: 0.30232646410613107\n",
      "Validation Accuracy after epoch 134: 73.07000000000001%\n",
      "Epoch: 135, Training Loss: 0.30379646569680985\n",
      "Validation Accuracy after epoch 135: 72.74000000000001%\n",
      "Epoch: 136, Training Loss: 0.29750046635146643\n",
      "Validation Accuracy after epoch 136: 72.72999999999999%\n",
      "Epoch: 137, Training Loss: 0.29421236628042463\n",
      "Validation Accuracy after epoch 137: 73.65%\n",
      "Epoch: 138, Training Loss: 0.29607388555832076\n",
      "Validation Accuracy after epoch 138: 73.68%\n",
      "Epoch: 139, Training Loss: 0.29051874465573474\n",
      "Validation Accuracy after epoch 139: 72.92999999999999%\n",
      "Epoch: 140, Training Loss: 0.285490695530039\n",
      "Validation Accuracy after epoch 140: 71.52%\n",
      "Epoch: 141, Training Loss: 0.28999345031235835\n",
      "Validation Accuracy after epoch 141: 72.86%\n",
      "Epoch: 142, Training Loss: 0.28665626392035226\n",
      "Validation Accuracy after epoch 142: 73.28%\n",
      "Epoch: 143, Training Loss: 0.2844706311955324\n",
      "Validation Accuracy after epoch 143: 71.61999999999999%\n",
      "Epoch: 144, Training Loss: 0.28063180956922834\n",
      "Validation Accuracy after epoch 144: 72.05%\n",
      "Epoch: 145, Training Loss: 0.2782376631618003\n",
      "Validation Accuracy after epoch 145: 72.47%\n",
      "Epoch: 146, Training Loss: 0.27551888701174876\n",
      "Validation Accuracy after epoch 146: 72.19%\n",
      "Epoch: 147, Training Loss: 0.27571648220195794\n",
      "Validation Accuracy after epoch 147: 73.5%\n",
      "Epoch: 148, Training Loss: 0.26776092612872954\n",
      "Validation Accuracy after epoch 148: 73.3%\n",
      "Epoch: 149, Training Loss: 0.2694551688202126\n",
      "Validation Accuracy after epoch 149: 73.98%\n",
      "Epoch: 150, Training Loss: 0.26852293161060803\n",
      "Validation Accuracy after epoch 150: 73.04%\n",
      "Epoch: 151, Training Loss: 0.26609249228178083\n",
      "Validation Accuracy after epoch 151: 73.36%\n",
      "Epoch: 152, Training Loss: 0.26369867983567136\n",
      "Validation Accuracy after epoch 152: 73.78%\n",
      "Epoch: 153, Training Loss: 0.25880218364889057\n",
      "Validation Accuracy after epoch 153: 72.55%\n",
      "Epoch: 154, Training Loss: 0.25679796776922464\n",
      "Validation Accuracy after epoch 154: 72.36%\n",
      "Epoch: 155, Training Loss: 0.2542249446906283\n",
      "Validation Accuracy after epoch 155: 73.7%\n",
      "Epoch: 156, Training Loss: 0.2555964697352456\n",
      "Validation Accuracy after epoch 156: 73.72%\n",
      "Epoch: 157, Training Loss: 0.2506370338446954\n",
      "Validation Accuracy after epoch 157: 72.65%\n",
      "Epoch: 158, Training Loss: 0.25307320887246704\n",
      "Validation Accuracy after epoch 158: 72.8%\n",
      "Epoch: 159, Training Loss: 0.24859521917693908\n",
      "Validation Accuracy after epoch 159: 73.07000000000001%\n",
      "Epoch: 160, Training Loss: 0.2487030559174164\n",
      "Validation Accuracy after epoch 160: 73.19%\n",
      "Epoch: 161, Training Loss: 0.2498490877087464\n",
      "Validation Accuracy after epoch 161: 73.03%\n",
      "Epoch: 162, Training Loss: 0.24373234446396302\n",
      "Validation Accuracy after epoch 162: 72.7%\n",
      "Epoch: 163, Training Loss: 0.24409771527704374\n",
      "Validation Accuracy after epoch 163: 72.58%\n",
      "Epoch: 164, Training Loss: 0.2453050407845422\n",
      "Validation Accuracy after epoch 164: 73.14%\n",
      "Epoch: 165, Training Loss: 0.23987525858728173\n",
      "Validation Accuracy after epoch 165: 72.89999999999999%\n",
      "Epoch: 166, Training Loss: 0.23686188591829957\n",
      "Validation Accuracy after epoch 166: 73.46000000000001%\n",
      "Epoch: 167, Training Loss: 0.23534103457237143\n",
      "Validation Accuracy after epoch 167: 72.54%\n",
      "Epoch: 168, Training Loss: 0.23865053762712746\n",
      "Validation Accuracy after epoch 168: 72.92999999999999%\n",
      "Epoch: 169, Training Loss: 0.23815142170852407\n",
      "Validation Accuracy after epoch 169: 73.11%\n",
      "Epoch: 170, Training Loss: 0.22969886468118414\n",
      "Validation Accuracy after epoch 170: 71.7%\n",
      "Epoch: 171, Training Loss: 0.23415804574328006\n",
      "Validation Accuracy after epoch 171: 73.17%\n",
      "Epoch: 172, Training Loss: 0.22857886542330313\n",
      "Validation Accuracy after epoch 172: 73.29%\n",
      "Epoch: 173, Training Loss: 0.22598026727643006\n",
      "Validation Accuracy after epoch 173: 73.27%\n",
      "Epoch: 174, Training Loss: 0.22560149417413622\n",
      "Validation Accuracy after epoch 174: 73.67%\n",
      "Epoch: 175, Training Loss: 0.22700365826182659\n",
      "Validation Accuracy after epoch 175: 72.6%\n",
      "Epoch: 176, Training Loss: 0.22096506916844022\n",
      "Validation Accuracy after epoch 176: 70.91%\n",
      "Epoch: 177, Training Loss: 0.22154412989783318\n",
      "Validation Accuracy after epoch 177: 72.02%\n",
      "Epoch: 178, Training Loss: 0.224184700275969\n",
      "Validation Accuracy after epoch 178: 72.98%\n",
      "Epoch: 179, Training Loss: 0.21856695682744084\n",
      "Validation Accuracy after epoch 179: 73.63%\n",
      "Epoch: 180, Training Loss: 0.21882287829237826\n",
      "Validation Accuracy after epoch 180: 72.42%\n",
      "Epoch: 181, Training Loss: 0.2218187072974108\n",
      "Validation Accuracy after epoch 181: 73.53%\n",
      "Epoch: 182, Training Loss: 0.21168721007073626\n",
      "Validation Accuracy after epoch 182: 72.76%\n",
      "Epoch: 183, Training Loss: 0.2110805492371778\n",
      "Validation Accuracy after epoch 183: 73.66%\n",
      "Epoch: 184, Training Loss: 0.21285165514787444\n",
      "Validation Accuracy after epoch 184: 72.53%\n",
      "Epoch: 185, Training Loss: 0.21004024461921675\n",
      "Validation Accuracy after epoch 185: 73.22%\n",
      "Epoch: 186, Training Loss: 0.21031752606982465\n",
      "Validation Accuracy after epoch 186: 72.7%\n",
      "Epoch: 187, Training Loss: 0.2077909033088123\n",
      "Validation Accuracy after epoch 187: 72.18%\n",
      "Epoch: 188, Training Loss: 0.21074462369979952\n",
      "Validation Accuracy after epoch 188: 73.11999999999999%\n",
      "Epoch: 189, Training Loss: 0.20522229176710177\n",
      "Validation Accuracy after epoch 189: 72.55%\n",
      "Epoch: 190, Training Loss: 0.20367354239382401\n",
      "Validation Accuracy after epoch 190: 72.25%\n",
      "Epoch: 191, Training Loss: 0.20405931863219232\n",
      "Validation Accuracy after epoch 191: 72.27%\n",
      "Epoch: 192, Training Loss: 0.20152104875106183\n",
      "Validation Accuracy after epoch 192: 73.77%\n",
      "Epoch: 193, Training Loss: 0.20088362655199854\n",
      "Validation Accuracy after epoch 193: 73.54%\n",
      "Epoch: 194, Training Loss: 0.20220427380879516\n",
      "Validation Accuracy after epoch 194: 72.97%\n",
      "Epoch: 195, Training Loss: 0.19362258643883726\n",
      "Validation Accuracy after epoch 195: 73.53%\n",
      "Epoch: 196, Training Loss: 0.20093849560965205\n",
      "Validation Accuracy after epoch 196: 72.76%\n",
      "Epoch: 197, Training Loss: 0.1948241191866148\n",
      "Validation Accuracy after epoch 197: 73.19%\n",
      "Epoch: 198, Training Loss: 0.1963976142246781\n",
      "Validation Accuracy after epoch 198: 72.5%\n",
      "Epoch: 199, Training Loss: 0.1957833970017979\n",
      "Validation Accuracy after epoch 199: 72.48%\n",
      "Epoch: 200, Training Loss: 0.193636047675291\n",
      "Validation Accuracy after epoch 200: 73.33%\n",
      "Epoch: 201, Training Loss: 0.1865713179368726\n",
      "Validation Accuracy after epoch 201: 73.06%\n",
      "Epoch: 202, Training Loss: 0.19147199603831372\n",
      "Validation Accuracy after epoch 202: 73.56%\n",
      "Epoch: 203, Training Loss: 0.18784630910286207\n",
      "Validation Accuracy after epoch 203: 73.47%\n",
      "Epoch: 204, Training Loss: 0.1848820513947998\n",
      "Validation Accuracy after epoch 204: 73.24000000000001%\n",
      "Epoch: 205, Training Loss: 0.1903297636095825\n",
      "Validation Accuracy after epoch 205: 73.50999999999999%\n",
      "Epoch: 206, Training Loss: 0.18293909113044324\n",
      "Validation Accuracy after epoch 206: 69.58%\n",
      "Epoch: 207, Training Loss: 0.1895691929551799\n",
      "Validation Accuracy after epoch 207: 73.11999999999999%\n",
      "Epoch: 208, Training Loss: 0.18641613057964598\n",
      "Validation Accuracy after epoch 208: 72.92999999999999%\n",
      "Epoch: 209, Training Loss: 0.18334432873312775\n",
      "Validation Accuracy after epoch 209: 70.54%\n",
      "Epoch: 210, Training Loss: 0.1772856393738476\n",
      "Validation Accuracy after epoch 210: 71.66%\n",
      "Epoch: 211, Training Loss: 0.18598894294246535\n",
      "Validation Accuracy after epoch 211: 72.69%\n",
      "Epoch: 212, Training Loss: 0.1801339993944101\n",
      "Validation Accuracy after epoch 212: 73.22%\n",
      "Epoch: 213, Training Loss: 0.1786633894238097\n",
      "Validation Accuracy after epoch 213: 73.27%\n",
      "Epoch: 214, Training Loss: 0.17682921794026404\n",
      "Validation Accuracy after epoch 214: 71.76%\n",
      "Epoch: 215, Training Loss: 0.17823831555064376\n",
      "Validation Accuracy after epoch 215: 73.09%\n",
      "Epoch: 216, Training Loss: 0.17729087676995856\n",
      "Validation Accuracy after epoch 216: 72.87%\n",
      "Epoch: 217, Training Loss: 0.17513017765129618\n",
      "Validation Accuracy after epoch 217: 72.59%\n",
      "Epoch: 218, Training Loss: 0.17542171281050234\n",
      "Validation Accuracy after epoch 218: 72.78%\n",
      "Epoch: 219, Training Loss: 0.17118189781142013\n",
      "Validation Accuracy after epoch 219: 72.76%\n",
      "Epoch: 220, Training Loss: 0.17085903250824308\n",
      "Validation Accuracy after epoch 220: 72.25%\n",
      "Epoch: 221, Training Loss: 0.17289670897871637\n",
      "Validation Accuracy after epoch 221: 72.97%\n",
      "Epoch: 222, Training Loss: 0.1714893737188576\n",
      "Validation Accuracy after epoch 222: 72.72%\n",
      "Epoch: 223, Training Loss: 0.16952226836891734\n",
      "Validation Accuracy after epoch 223: 72.76%\n",
      "Epoch: 224, Training Loss: 0.1731408973083929\n",
      "Validation Accuracy after epoch 224: 72.45%\n",
      "Epoch: 225, Training Loss: 0.1687977792685637\n",
      "Validation Accuracy after epoch 225: 73.18%\n",
      "Epoch: 226, Training Loss: 0.16901373099821532\n",
      "Validation Accuracy after epoch 226: 70.66%\n",
      "Epoch: 227, Training Loss: 0.16510829379272354\n",
      "Validation Accuracy after epoch 227: 73.00999999999999%\n",
      "Epoch: 228, Training Loss: 0.16723379297443972\n",
      "Validation Accuracy after epoch 228: 72.0%\n",
      "Epoch: 229, Training Loss: 0.1651769102505787\n",
      "Validation Accuracy after epoch 229: 72.47%\n",
      "Epoch: 230, Training Loss: 0.17146870669196634\n",
      "Validation Accuracy after epoch 230: 72.42%\n",
      "Epoch: 231, Training Loss: 0.1636189243296528\n",
      "Validation Accuracy after epoch 231: 73.16%\n",
      "Epoch: 232, Training Loss: 0.166633796737627\n",
      "Validation Accuracy after epoch 232: 73.21%\n",
      "Epoch: 233, Training Loss: 0.1559959447756886\n",
      "Validation Accuracy after epoch 233: 73.83%\n",
      "Epoch: 234, Training Loss: 0.1590734587201034\n",
      "Validation Accuracy after epoch 234: 72.56%\n",
      "Epoch: 235, Training Loss: 0.16164213665725324\n",
      "Validation Accuracy after epoch 235: 72.42%\n",
      "Epoch: 236, Training Loss: 0.16088719482359756\n",
      "Validation Accuracy after epoch 236: 73.19%\n",
      "Epoch: 237, Training Loss: 0.1588397632136255\n",
      "Validation Accuracy after epoch 237: 72.78%\n",
      "Epoch: 238, Training Loss: 0.15862219374093328\n",
      "Validation Accuracy after epoch 238: 72.3%\n",
      "Epoch: 239, Training Loss: 0.15570096133510247\n",
      "Validation Accuracy after epoch 239: 71.72%\n",
      "Epoch: 240, Training Loss: 0.15997461956994766\n",
      "Validation Accuracy after epoch 240: 72.95%\n",
      "Epoch: 241, Training Loss: 0.15932478355791638\n",
      "Validation Accuracy after epoch 241: 72.1%\n",
      "Epoch: 242, Training Loss: 0.15425549088107884\n",
      "Validation Accuracy after epoch 242: 71.03%\n",
      "Epoch: 243, Training Loss: 0.15554348553014\n",
      "Validation Accuracy after epoch 243: 72.26%\n",
      "Epoch: 244, Training Loss: 0.15521757044565038\n",
      "Validation Accuracy after epoch 244: 73.34%\n",
      "Epoch: 245, Training Loss: 0.15539160715011152\n",
      "Validation Accuracy after epoch 245: 71.12%\n",
      "Epoch: 246, Training Loss: 0.1519790090563352\n",
      "Validation Accuracy after epoch 246: 72.59%\n",
      "Epoch: 247, Training Loss: 0.15279779856657738\n",
      "Validation Accuracy after epoch 247: 72.77%\n",
      "Epoch: 248, Training Loss: 0.15146346635582958\n",
      "Validation Accuracy after epoch 248: 73.1%\n",
      "Epoch: 249, Training Loss: 0.15187387033591948\n",
      "Validation Accuracy after epoch 249: 72.59%\n",
      "Epoch: 250, Training Loss: 0.15356560933458455\n",
      "Validation Accuracy after epoch 250: 72.42%\n",
      "Epoch: 251, Training Loss: 0.14675852123057218\n",
      "Validation Accuracy after epoch 251: 72.47%\n",
      "Epoch: 252, Training Loss: 0.14861450226777387\n",
      "Validation Accuracy after epoch 252: 72.95%\n",
      "Epoch: 253, Training Loss: 0.1454382547846688\n",
      "Validation Accuracy after epoch 253: 73.34%\n",
      "Epoch: 254, Training Loss: 0.14811434672759546\n",
      "Validation Accuracy after epoch 254: 71.1%\n",
      "Epoch: 255, Training Loss: 0.14761659709493752\n",
      "Validation Accuracy after epoch 255: 72.87%\n",
      "Epoch: 256, Training Loss: 0.1453439145470443\n",
      "Validation Accuracy after epoch 256: 72.66%\n",
      "Epoch: 257, Training Loss: 0.14631192339941515\n",
      "Validation Accuracy after epoch 257: 72.45%\n",
      "Epoch: 258, Training Loss: 0.14473003038512472\n",
      "Validation Accuracy after epoch 258: 73.0%\n",
      "Epoch: 259, Training Loss: 0.1447086745082303\n",
      "Validation Accuracy after epoch 259: 72.72%\n",
      "Epoch: 260, Training Loss: 0.14485317872136907\n",
      "Validation Accuracy after epoch 260: 73.24000000000001%\n",
      "Epoch: 261, Training Loss: 0.145953000735139\n",
      "Validation Accuracy after epoch 261: 72.84%\n",
      "Epoch: 262, Training Loss: 0.14424184147897354\n",
      "Validation Accuracy after epoch 262: 73.16%\n",
      "Epoch: 263, Training Loss: 0.13892494054401622\n",
      "Validation Accuracy after epoch 263: 72.76%\n",
      "Epoch: 264, Training Loss: 0.13876331645204587\n",
      "Validation Accuracy after epoch 264: 72.75%\n",
      "Epoch: 265, Training Loss: 0.14298949285369852\n",
      "Validation Accuracy after epoch 265: 73.02%\n",
      "Epoch: 266, Training Loss: 0.14226698755855907\n",
      "Validation Accuracy after epoch 266: 72.66%\n",
      "Epoch: 267, Training Loss: 0.14025603140682896\n",
      "Validation Accuracy after epoch 267: 71.27%\n",
      "Epoch: 268, Training Loss: 0.14106873086417843\n",
      "Validation Accuracy after epoch 268: 73.03%\n",
      "Epoch: 269, Training Loss: 0.14095021519914766\n",
      "Validation Accuracy after epoch 269: 72.7%\n",
      "Epoch: 270, Training Loss: 0.13811190734448298\n",
      "Validation Accuracy after epoch 270: 72.42%\n",
      "Epoch: 271, Training Loss: 0.13853211618264388\n",
      "Validation Accuracy after epoch 271: 73.17%\n",
      "Epoch: 272, Training Loss: 0.13699069110107373\n",
      "Validation Accuracy after epoch 272: 72.52%\n",
      "Epoch: 273, Training Loss: 0.1405722069461137\n",
      "Validation Accuracy after epoch 273: 72.49%\n",
      "Epoch: 274, Training Loss: 0.13538670683246287\n",
      "Validation Accuracy after epoch 274: 73.1%\n",
      "Epoch: 275, Training Loss: 0.13809385343723932\n",
      "Validation Accuracy after epoch 275: 73.2%\n",
      "Epoch: 276, Training Loss: 0.13658661222385476\n",
      "Validation Accuracy after epoch 276: 72.49%\n",
      "Epoch: 277, Training Loss: 0.13774335875040125\n",
      "Validation Accuracy after epoch 277: 73.04%\n",
      "Epoch: 278, Training Loss: 0.1330711445128045\n",
      "Validation Accuracy after epoch 278: 72.58%\n",
      "Epoch: 279, Training Loss: 0.1300866808385\n",
      "Validation Accuracy after epoch 279: 73.31%\n",
      "Epoch: 280, Training Loss: 0.13100530448324427\n",
      "Validation Accuracy after epoch 280: 72.65%\n",
      "Epoch: 281, Training Loss: 0.1308571349548371\n",
      "Validation Accuracy after epoch 281: 72.87%\n",
      "Epoch: 282, Training Loss: 0.13366054417684559\n",
      "Validation Accuracy after epoch 282: 72.68%\n",
      "Epoch: 283, Training Loss: 0.1309978426755656\n",
      "Validation Accuracy after epoch 283: 73.04%\n",
      "Epoch: 284, Training Loss: 0.130952388946148\n",
      "Validation Accuracy after epoch 284: 73.21%\n",
      "Epoch: 285, Training Loss: 0.1307862606923789\n",
      "Validation Accuracy after epoch 285: 73.49%\n",
      "Epoch: 286, Training Loss: 0.13278848518762748\n",
      "Validation Accuracy after epoch 286: 72.46000000000001%\n",
      "Epoch: 287, Training Loss: 0.13342667352336715\n",
      "Validation Accuracy after epoch 287: 70.66%\n",
      "Epoch: 288, Training Loss: 0.13167183495977003\n",
      "Validation Accuracy after epoch 288: 70.06%\n",
      "Epoch: 289, Training Loss: 0.13196631301375453\n",
      "Validation Accuracy after epoch 289: 73.15%\n",
      "Epoch: 290, Training Loss: 0.12885087097535278\n",
      "Validation Accuracy after epoch 290: 72.82%\n",
      "Epoch: 291, Training Loss: 0.1302472294005744\n",
      "Validation Accuracy after epoch 291: 72.2%\n",
      "Epoch: 292, Training Loss: 0.13184113166702296\n",
      "Validation Accuracy after epoch 292: 72.27%\n",
      "Epoch: 293, Training Loss: 0.12702998456538028\n",
      "Validation Accuracy after epoch 293: 72.32%\n",
      "Epoch: 294, Training Loss: 0.12587271027548044\n",
      "Validation Accuracy after epoch 294: 73.11999999999999%\n",
      "Epoch: 295, Training Loss: 0.1268973809469234\n",
      "Validation Accuracy after epoch 295: 72.38%\n",
      "Epoch: 296, Training Loss: 0.12811631484485952\n",
      "Validation Accuracy after epoch 296: 72.39999999999999%\n",
      "Epoch: 297, Training Loss: 0.1229631715624467\n",
      "Validation Accuracy after epoch 297: 73.4%\n",
      "Epoch: 298, Training Loss: 0.11873349759494291\n",
      "Validation Accuracy after epoch 298: 72.5%\n",
      "Epoch: 299, Training Loss: 0.12333252462213073\n",
      "Validation Accuracy after epoch 299: 71.25%\n",
      "Epoch: 300, Training Loss: 0.12571638861261403\n",
      "Validation Accuracy after epoch 300: 72.78999999999999%\n",
      "Total Training Time: 2158.926344871521 seconds\n"
     ]
    }
   ],
   "source": [
    "training_loop(\n",
    "    n_epochs=300,\n",
    "    optimizer=optimizer,\n",
    "    model=model,\n",
    "    loss_fn=loss_fn,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a6d9fa7e-e20b-4529-a7a8-95ad2afa3d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 2 b) Batch Normalization \n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, n_chans):\n",
    "        super(ResBlock, self).__init__()\n",
    "        self.conv = nn.Conv2d(n_chans, n_chans, kernel_size=3, padding=1, bias=False)  \n",
    "        self.batch_norm = nn.BatchNorm2d(n_chans)\n",
    "        \n",
    "      \n",
    "        nn.init.kaiming_normal_(self.conv.weight, nonlinearity='relu')\n",
    "        nn.init.constant_(self.batch_norm.weight, 1)  \n",
    "        nn.init.zeros_(self.batch_norm.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        out = self.batch_norm(out)\n",
    "        out = F.relu(out)\n",
    "        return out + x  \n",
    "\n",
    "class NetResDeep(nn.Module):  \n",
    "    def __init__(self, n_chans1=32, n_blocks=10):\n",
    "        super(NetResDeep, self).__init__()\n",
    "        self.n_chans1 = n_chans1\n",
    "        self.conv1 = nn.Conv2d(3, n_chans1, kernel_size=3, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(n_chans1)\n",
    "        \n",
    "        \n",
    "        nn.init.kaiming_normal_(self.conv1.weight, nonlinearity='relu')\n",
    "        \n",
    "     \n",
    "        self.resblocks = nn.Sequential(*[ResBlock(n_chans1) for _ in range(n_blocks)])\n",
    "        \n",
    "       \n",
    "        self.fc1 = nn.Linear(8 * 8 * n_chans1, 32)  \n",
    "        self.fc2 = nn.Linear(32, 10)  \n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))  \n",
    "        out = F.max_pool2d(out, 2) \n",
    "        out = self.resblocks(out)  \n",
    "        out = F.adaptive_avg_pool2d(out, (8, 8)) \n",
    "        out = out.view(-1, 8 * 8 * self.n_chans1) \n",
    "        out = F.relu(self.fc1(out))  \n",
    "        out = self.fc2(out)  \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4a6db9e1-6641-4160-879c-11fbfe7cff6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NetResDeep(n_chans1=32, n_blocks=10).to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=3e-3)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5dc1888c-15c2-44fb-a8ea-3f2df195bbc5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Training Loss: 1.9562370304561332\n",
      "Validation Accuracy after epoch 1: 30.45%\n",
      "Epoch: 2, Training Loss: 1.6446315262018871\n",
      "Validation Accuracy after epoch 2: 34.43%\n",
      "Epoch: 3, Training Loss: 1.4922315705462794\n",
      "Validation Accuracy after epoch 3: 41.6%\n",
      "Epoch: 4, Training Loss: 1.400319983129916\n",
      "Validation Accuracy after epoch 4: 44.39%\n",
      "Epoch: 5, Training Loss: 1.335924232097538\n",
      "Validation Accuracy after epoch 5: 52.239999999999995%\n",
      "Epoch: 6, Training Loss: 1.2825282219120913\n",
      "Validation Accuracy after epoch 6: 46.86%\n",
      "Epoch: 7, Training Loss: 1.2375153729982693\n",
      "Validation Accuracy after epoch 7: 50.67%\n",
      "Epoch: 8, Training Loss: 1.1968341992639215\n",
      "Validation Accuracy after epoch 8: 54.32%\n",
      "Epoch: 9, Training Loss: 1.1643986580774301\n",
      "Validation Accuracy after epoch 9: 45.550000000000004%\n",
      "Epoch: 10, Training Loss: 1.1321535258341933\n",
      "Validation Accuracy after epoch 10: 52.25%\n",
      "Epoch: 11, Training Loss: 1.101977552065764\n",
      "Validation Accuracy after epoch 11: 56.75%\n",
      "Epoch: 12, Training Loss: 1.0737892547074486\n",
      "Validation Accuracy after epoch 12: 58.63%\n",
      "Epoch: 13, Training Loss: 1.0491378553535626\n",
      "Validation Accuracy after epoch 13: 56.620000000000005%\n",
      "Epoch: 14, Training Loss: 1.016764394157683\n",
      "Validation Accuracy after epoch 14: 45.35%\n",
      "Epoch: 15, Training Loss: 0.9970759878225643\n",
      "Validation Accuracy after epoch 15: 51.21%\n",
      "Epoch: 16, Training Loss: 0.9726785805524157\n",
      "Validation Accuracy after epoch 16: 54.2%\n",
      "Epoch: 17, Training Loss: 0.9561408636972423\n",
      "Validation Accuracy after epoch 17: 57.699999999999996%\n",
      "Epoch: 18, Training Loss: 0.9295359030556496\n",
      "Validation Accuracy after epoch 18: 59.57%\n",
      "Epoch: 19, Training Loss: 0.9143256115181672\n",
      "Validation Accuracy after epoch 19: 60.5%\n",
      "Epoch: 20, Training Loss: 0.8986154759631437\n",
      "Validation Accuracy after epoch 20: 58.5%\n",
      "Epoch: 21, Training Loss: 0.8776386300926013\n",
      "Validation Accuracy after epoch 21: 60.77%\n",
      "Epoch: 22, Training Loss: 0.8671580067528483\n",
      "Validation Accuracy after epoch 22: 49.02%\n",
      "Epoch: 23, Training Loss: 0.8546233920718703\n",
      "Validation Accuracy after epoch 23: 51.9%\n",
      "Epoch: 24, Training Loss: 0.8393764158953791\n",
      "Validation Accuracy after epoch 24: 63.660000000000004%\n",
      "Epoch: 25, Training Loss: 0.8265351899292158\n",
      "Validation Accuracy after epoch 25: 59.330000000000005%\n",
      "Epoch: 26, Training Loss: 0.8119349575713467\n",
      "Validation Accuracy after epoch 26: 51.0%\n",
      "Epoch: 27, Training Loss: 0.8049096341633126\n",
      "Validation Accuracy after epoch 27: 64.60000000000001%\n",
      "Epoch: 28, Training Loss: 0.7895516577888938\n",
      "Validation Accuracy after epoch 28: 50.349999999999994%\n",
      "Epoch: 29, Training Loss: 0.78195745648478\n",
      "Validation Accuracy after epoch 29: 54.89000000000001%\n",
      "Epoch: 30, Training Loss: 0.7697300794331924\n",
      "Validation Accuracy after epoch 30: 61.160000000000004%\n",
      "Epoch: 31, Training Loss: 0.7603897473315144\n",
      "Validation Accuracy after epoch 31: 65.03999999999999%\n",
      "Epoch: 32, Training Loss: 0.7504715421391875\n",
      "Validation Accuracy after epoch 32: 54.72%\n",
      "Epoch: 33, Training Loss: 0.7403304216730625\n",
      "Validation Accuracy after epoch 33: 62.03999999999999%\n",
      "Epoch: 34, Training Loss: 0.733265240440893\n",
      "Validation Accuracy after epoch 34: 64.96%\n",
      "Epoch: 35, Training Loss: 0.7256203136404457\n",
      "Validation Accuracy after epoch 35: 62.59%\n",
      "Epoch: 36, Training Loss: 0.7125935413877068\n",
      "Validation Accuracy after epoch 36: 66.03%\n",
      "Epoch: 37, Training Loss: 0.7002991412759132\n",
      "Validation Accuracy after epoch 37: 67.23%\n",
      "Epoch: 38, Training Loss: 0.6929625360785848\n",
      "Validation Accuracy after epoch 38: 67.33%\n",
      "Epoch: 39, Training Loss: 0.6877664169082252\n",
      "Validation Accuracy after epoch 39: 61.88%\n",
      "Epoch: 40, Training Loss: 0.6777222813547724\n",
      "Validation Accuracy after epoch 40: 68.19%\n",
      "Epoch: 41, Training Loss: 0.6730769939358582\n",
      "Validation Accuracy after epoch 41: 65.9%\n",
      "Epoch: 42, Training Loss: 0.6646138957851683\n",
      "Validation Accuracy after epoch 42: 57.47%\n",
      "Epoch: 43, Training Loss: 0.6543826494756562\n",
      "Validation Accuracy after epoch 43: 62.61%\n",
      "Epoch: 44, Training Loss: 0.647224669185136\n",
      "Validation Accuracy after epoch 44: 68.78999999999999%\n",
      "Epoch: 45, Training Loss: 0.639248836642641\n",
      "Validation Accuracy after epoch 45: 62.83%\n",
      "Epoch: 46, Training Loss: 0.629804848862426\n",
      "Validation Accuracy after epoch 46: 61.85000000000001%\n",
      "Epoch: 47, Training Loss: 0.6233085587887508\n",
      "Validation Accuracy after epoch 47: 59.79%\n",
      "Epoch: 48, Training Loss: 0.6164239389664682\n",
      "Validation Accuracy after epoch 48: 70.1%\n",
      "Epoch: 49, Training Loss: 0.6118737592950196\n",
      "Validation Accuracy after epoch 49: 63.73%\n",
      "Epoch: 50, Training Loss: 0.6055629111616813\n",
      "Validation Accuracy after epoch 50: 68.41000000000001%\n",
      "Epoch: 51, Training Loss: 0.5992273517200709\n",
      "Validation Accuracy after epoch 51: 68.17%\n",
      "Epoch: 52, Training Loss: 0.5871664956021492\n",
      "Validation Accuracy after epoch 52: 68.06%\n",
      "Epoch: 53, Training Loss: 0.5823184857740427\n",
      "Validation Accuracy after epoch 53: 65.3%\n",
      "Epoch: 54, Training Loss: 0.5748543099826559\n",
      "Validation Accuracy after epoch 54: 72.44%\n",
      "Epoch: 55, Training Loss: 0.5719693384854995\n",
      "Validation Accuracy after epoch 55: 71.49%\n",
      "Epoch: 56, Training Loss: 0.5595725563633472\n",
      "Validation Accuracy after epoch 56: 66.27%\n",
      "Epoch: 57, Training Loss: 0.5583125609723504\n",
      "Validation Accuracy after epoch 57: 69.39999999999999%\n",
      "Epoch: 58, Training Loss: 0.5481734665687127\n",
      "Validation Accuracy after epoch 58: 67.9%\n",
      "Epoch: 59, Training Loss: 0.539953926106548\n",
      "Validation Accuracy after epoch 59: 67.77%\n",
      "Epoch: 60, Training Loss: 0.5359224431654986\n",
      "Validation Accuracy after epoch 60: 68.97%\n",
      "Epoch: 61, Training Loss: 0.5305731153434805\n",
      "Validation Accuracy after epoch 61: 70.71%\n",
      "Epoch: 62, Training Loss: 0.523585159950854\n",
      "Validation Accuracy after epoch 62: 65.42%\n",
      "Epoch: 63, Training Loss: 0.5186888959897143\n",
      "Validation Accuracy after epoch 63: 68.82000000000001%\n",
      "Epoch: 64, Training Loss: 0.5146522797701304\n",
      "Validation Accuracy after epoch 64: 65.89%\n",
      "Epoch: 65, Training Loss: 0.504268515216725\n",
      "Validation Accuracy after epoch 65: 29.39%\n",
      "Epoch: 66, Training Loss: 0.5005521796396016\n",
      "Validation Accuracy after epoch 66: 64.95%\n",
      "Epoch: 67, Training Loss: 0.49288529148110954\n",
      "Validation Accuracy after epoch 67: 66.10000000000001%\n",
      "Epoch: 68, Training Loss: 0.49012695026138553\n",
      "Validation Accuracy after epoch 68: 65.10000000000001%\n",
      "Epoch: 69, Training Loss: 0.48278209889102774\n",
      "Validation Accuracy after epoch 69: 64.17%\n",
      "Epoch: 70, Training Loss: 0.4821399974129389\n",
      "Validation Accuracy after epoch 70: 70.98%\n",
      "Epoch: 71, Training Loss: 0.4718118767108759\n",
      "Validation Accuracy after epoch 71: 63.019999999999996%\n",
      "Epoch: 72, Training Loss: 0.4661552276071685\n",
      "Validation Accuracy after epoch 72: 63.55%\n",
      "Epoch: 73, Training Loss: 0.46038854253642697\n",
      "Validation Accuracy after epoch 73: 67.04%\n",
      "Epoch: 74, Training Loss: 0.45233165209784226\n",
      "Validation Accuracy after epoch 74: 60.85%\n",
      "Epoch: 75, Training Loss: 0.447786396440795\n",
      "Validation Accuracy after epoch 75: 68.27%\n",
      "Epoch: 76, Training Loss: 0.4447885093938969\n",
      "Validation Accuracy after epoch 76: 66.71000000000001%\n",
      "Epoch: 77, Training Loss: 0.43487001338120923\n",
      "Validation Accuracy after epoch 77: 70.61%\n",
      "Epoch: 78, Training Loss: 0.4323403385403516\n",
      "Validation Accuracy after epoch 78: 68.02%\n",
      "Epoch: 79, Training Loss: 0.4220199502642502\n",
      "Validation Accuracy after epoch 79: 62.41%\n",
      "Epoch: 80, Training Loss: 0.4274517611393233\n",
      "Validation Accuracy after epoch 80: 65.02%\n",
      "Epoch: 81, Training Loss: 0.4193911169419813\n",
      "Validation Accuracy after epoch 81: 57.879999999999995%\n",
      "Epoch: 82, Training Loss: 0.4080752872711862\n",
      "Validation Accuracy after epoch 82: 52.410000000000004%\n",
      "Epoch: 83, Training Loss: 0.4071909820522799\n",
      "Validation Accuracy after epoch 83: 64.66%\n",
      "Epoch: 84, Training Loss: 0.40129811021373096\n",
      "Validation Accuracy after epoch 84: 62.83%\n",
      "Epoch: 85, Training Loss: 0.39468443700495887\n",
      "Validation Accuracy after epoch 85: 68.76%\n",
      "Epoch: 86, Training Loss: 0.3884675350240277\n",
      "Validation Accuracy after epoch 86: 72.2%\n",
      "Epoch: 87, Training Loss: 0.3824424450774022\n",
      "Validation Accuracy after epoch 87: 71.08%\n",
      "Epoch: 88, Training Loss: 0.3796673854598609\n",
      "Validation Accuracy after epoch 88: 69.02000000000001%\n",
      "Epoch: 89, Training Loss: 0.37334007194356233\n",
      "Validation Accuracy after epoch 89: 64.52%\n",
      "Epoch: 90, Training Loss: 0.36511979610337625\n",
      "Validation Accuracy after epoch 90: 69.97%\n",
      "Epoch: 91, Training Loss: 0.3665305185691475\n",
      "Validation Accuracy after epoch 91: 69.33%\n",
      "Epoch: 92, Training Loss: 0.35974714116138573\n",
      "Validation Accuracy after epoch 92: 61.519999999999996%\n",
      "Epoch: 93, Training Loss: 0.3517614845805766\n",
      "Validation Accuracy after epoch 93: 65.02%\n",
      "Epoch: 94, Training Loss: 0.350200358406662\n",
      "Validation Accuracy after epoch 94: 47.38%\n",
      "Epoch: 95, Training Loss: 0.34597153142285164\n",
      "Validation Accuracy after epoch 95: 64.07000000000001%\n",
      "Epoch: 96, Training Loss: 0.3375772157555346\n",
      "Validation Accuracy after epoch 96: 64.39%\n",
      "Epoch: 97, Training Loss: 0.3382578025502927\n",
      "Validation Accuracy after epoch 97: 69.07%\n",
      "Epoch: 98, Training Loss: 0.3295551167367517\n",
      "Validation Accuracy after epoch 98: 61.28%\n",
      "Epoch: 99, Training Loss: 0.3255582577489374\n",
      "Validation Accuracy after epoch 99: 72.86%\n",
      "Epoch: 100, Training Loss: 0.31942902943667245\n",
      "Validation Accuracy after epoch 100: 65.95%\n",
      "Epoch: 101, Training Loss: 0.31855935521442874\n",
      "Validation Accuracy after epoch 101: 47.27%\n",
      "Epoch: 102, Training Loss: 0.31039599449280886\n",
      "Validation Accuracy after epoch 102: 68.74%\n",
      "Epoch: 103, Training Loss: 0.3028694947662256\n",
      "Validation Accuracy after epoch 103: 57.25%\n",
      "Epoch: 104, Training Loss: 0.30330944894944006\n",
      "Validation Accuracy after epoch 104: 54.879999999999995%\n",
      "Epoch: 105, Training Loss: 0.2922228004716699\n",
      "Validation Accuracy after epoch 105: 61.870000000000005%\n",
      "Epoch: 106, Training Loss: 0.2927020217870812\n",
      "Validation Accuracy after epoch 106: 71.23%\n",
      "Epoch: 107, Training Loss: 0.2863050859202357\n",
      "Validation Accuracy after epoch 107: 55.35%\n",
      "Epoch: 108, Training Loss: 0.28070513968882355\n",
      "Validation Accuracy after epoch 108: 71.11%\n",
      "Epoch: 109, Training Loss: 0.27540310824771064\n",
      "Validation Accuracy after epoch 109: 66.47%\n",
      "Epoch: 110, Training Loss: 0.27223534137963334\n",
      "Validation Accuracy after epoch 110: 72.59%\n",
      "Epoch: 111, Training Loss: 0.2692423564146089\n",
      "Validation Accuracy after epoch 111: 68.83%\n",
      "Epoch: 112, Training Loss: 0.2638747401325904\n",
      "Validation Accuracy after epoch 112: 67.84%\n",
      "Epoch: 113, Training Loss: 0.25953462207808975\n",
      "Validation Accuracy after epoch 113: 70.62%\n",
      "Epoch: 114, Training Loss: 0.25318910086246404\n",
      "Validation Accuracy after epoch 114: 59.51%\n",
      "Epoch: 115, Training Loss: 0.24910825639582046\n",
      "Validation Accuracy after epoch 115: 67.44%\n",
      "Epoch: 116, Training Loss: 0.2478825648403381\n",
      "Validation Accuracy after epoch 116: 40.27%\n",
      "Epoch: 117, Training Loss: 0.24036920603240847\n",
      "Validation Accuracy after epoch 117: 72.63%\n",
      "Epoch: 118, Training Loss: 0.2344437325444749\n",
      "Validation Accuracy after epoch 118: 66.25%\n",
      "Epoch: 119, Training Loss: 0.23330953707704155\n",
      "Validation Accuracy after epoch 119: 60.69%\n",
      "Epoch: 120, Training Loss: 0.22968682247068722\n",
      "Validation Accuracy after epoch 120: 63.129999999999995%\n",
      "Epoch: 121, Training Loss: 0.2255712557879403\n",
      "Validation Accuracy after epoch 121: 62.8%\n",
      "Epoch: 122, Training Loss: 0.22106217688706983\n",
      "Validation Accuracy after epoch 122: 71.91%\n",
      "Epoch: 123, Training Loss: 0.21346387150876053\n",
      "Validation Accuracy after epoch 123: 67.96%\n",
      "Epoch: 124, Training Loss: 0.20868874126878542\n",
      "Validation Accuracy after epoch 124: 72.17%\n",
      "Epoch: 125, Training Loss: 0.20635332670205694\n",
      "Validation Accuracy after epoch 125: 59.809999999999995%\n",
      "Epoch: 126, Training Loss: 0.2096436433446453\n",
      "Validation Accuracy after epoch 126: 66.71000000000001%\n",
      "Epoch: 127, Training Loss: 0.19790961524314435\n",
      "Validation Accuracy after epoch 127: 66.94%\n",
      "Epoch: 128, Training Loss: 0.19114714410737196\n",
      "Validation Accuracy after epoch 128: 71.37%\n",
      "Epoch: 129, Training Loss: 0.19043343570416846\n",
      "Validation Accuracy after epoch 129: 67.04%\n",
      "Epoch: 130, Training Loss: 0.18861232719877186\n",
      "Validation Accuracy after epoch 130: 71.78999999999999%\n",
      "Epoch: 131, Training Loss: 0.17737080518375425\n",
      "Validation Accuracy after epoch 131: 72.23%\n",
      "Epoch: 132, Training Loss: 0.18178629649379063\n",
      "Validation Accuracy after epoch 132: 72.87%\n",
      "Epoch: 133, Training Loss: 0.17068392877250224\n",
      "Validation Accuracy after epoch 133: 63.970000000000006%\n",
      "Epoch: 134, Training Loss: 0.1732380623164613\n",
      "Validation Accuracy after epoch 134: 60.33%\n",
      "Epoch: 135, Training Loss: 0.17287466602633372\n",
      "Validation Accuracy after epoch 135: 65.60000000000001%\n",
      "Epoch: 136, Training Loss: 0.16241329919327707\n",
      "Validation Accuracy after epoch 136: 64.71000000000001%\n",
      "Epoch: 137, Training Loss: 0.16443273795725744\n",
      "Validation Accuracy after epoch 137: 62.79%\n",
      "Epoch: 138, Training Loss: 0.1514373477119619\n",
      "Validation Accuracy after epoch 138: 71.41999999999999%\n",
      "Epoch: 139, Training Loss: 0.15409524358161117\n",
      "Validation Accuracy after epoch 139: 69.76%\n",
      "Epoch: 140, Training Loss: 0.14797924393716524\n",
      "Validation Accuracy after epoch 140: 71.47%\n",
      "Epoch: 141, Training Loss: 0.14515892438152256\n",
      "Validation Accuracy after epoch 141: 67.99%\n",
      "Epoch: 142, Training Loss: 0.1480731085666915\n",
      "Validation Accuracy after epoch 142: 65.64999999999999%\n",
      "Epoch: 143, Training Loss: 0.14247811004957733\n",
      "Validation Accuracy after epoch 143: 42.34%\n",
      "Epoch: 144, Training Loss: 0.14039446444005307\n",
      "Validation Accuracy after epoch 144: 73.25%\n",
      "Epoch: 145, Training Loss: 0.1322289545998892\n",
      "Validation Accuracy after epoch 145: 64.01%\n",
      "Epoch: 146, Training Loss: 0.1329504336132799\n",
      "Validation Accuracy after epoch 146: 64.03999999999999%\n",
      "Epoch: 147, Training Loss: 0.12643213791158192\n",
      "Validation Accuracy after epoch 147: 67.73%\n",
      "Epoch: 148, Training Loss: 0.12403314999397606\n",
      "Validation Accuracy after epoch 148: 47.980000000000004%\n",
      "Epoch: 149, Training Loss: 0.12852991528599464\n",
      "Validation Accuracy after epoch 149: 68.64%\n",
      "Epoch: 150, Training Loss: 0.12231000836300271\n",
      "Validation Accuracy after epoch 150: 70.78%\n",
      "Epoch: 151, Training Loss: 0.11273151845730783\n",
      "Validation Accuracy after epoch 151: 68.5%\n",
      "Epoch: 152, Training Loss: 0.110929718655546\n",
      "Validation Accuracy after epoch 152: 51.28%\n",
      "Epoch: 153, Training Loss: 0.12138788715062086\n",
      "Validation Accuracy after epoch 153: 72.45%\n",
      "Epoch: 154, Training Loss: 0.10146466109072766\n",
      "Validation Accuracy after epoch 154: 72.67%\n",
      "Epoch: 155, Training Loss: 0.09590078263407778\n",
      "Validation Accuracy after epoch 155: 66.78%\n",
      "Epoch: 156, Training Loss: 0.09603776252063949\n",
      "Validation Accuracy after epoch 156: 60.480000000000004%\n",
      "Epoch: 157, Training Loss: 0.09749262436838521\n",
      "Validation Accuracy after epoch 157: 65.64999999999999%\n",
      "Epoch: 158, Training Loss: 0.10063301079222918\n",
      "Validation Accuracy after epoch 158: 61.63999999999999%\n",
      "Epoch: 159, Training Loss: 0.09211587525494493\n",
      "Validation Accuracy after epoch 159: 70.00999999999999%\n",
      "Epoch: 160, Training Loss: 0.08445188237587585\n",
      "Validation Accuracy after epoch 160: 70.03%\n",
      "Epoch: 161, Training Loss: 0.09214086178690195\n",
      "Validation Accuracy after epoch 161: 73.81%\n",
      "Epoch: 162, Training Loss: 0.08923996727475349\n",
      "Validation Accuracy after epoch 162: 68.57%\n",
      "Epoch: 163, Training Loss: 0.08141205552012643\n",
      "Validation Accuracy after epoch 163: 73.42%\n",
      "Epoch: 164, Training Loss: 0.07468734268346787\n",
      "Validation Accuracy after epoch 164: 72.91%\n",
      "Epoch: 165, Training Loss: 0.08004228662654204\n",
      "Validation Accuracy after epoch 165: 70.32000000000001%\n",
      "Epoch: 166, Training Loss: 0.0845968202780694\n",
      "Validation Accuracy after epoch 166: 43.05%\n",
      "Epoch: 167, Training Loss: 0.08059837360201819\n",
      "Validation Accuracy after epoch 167: 53.33%\n",
      "Epoch: 168, Training Loss: 0.06742165068550335\n",
      "Validation Accuracy after epoch 168: 68.41000000000001%\n",
      "Epoch: 169, Training Loss: 0.0664317943310589\n",
      "Validation Accuracy after epoch 169: 68.77%\n",
      "Epoch: 170, Training Loss: 0.06296188653925495\n",
      "Validation Accuracy after epoch 170: 70.39%\n",
      "Epoch: 171, Training Loss: 0.06744327557230335\n",
      "Validation Accuracy after epoch 171: 55.63%\n",
      "Epoch: 172, Training Loss: 0.06420566650140849\n",
      "Validation Accuracy after epoch 172: 71.82%\n",
      "Epoch: 173, Training Loss: 0.05800720451511633\n",
      "Validation Accuracy after epoch 173: 71.5%\n",
      "Epoch: 174, Training Loss: 0.06668167609883391\n",
      "Validation Accuracy after epoch 174: 57.04%\n",
      "Epoch: 175, Training Loss: 0.06524389272536654\n",
      "Validation Accuracy after epoch 175: 64.9%\n",
      "Epoch: 176, Training Loss: 0.05845696165028702\n",
      "Validation Accuracy after epoch 176: 70.34%\n",
      "Epoch: 177, Training Loss: 0.04742135312241476\n",
      "Validation Accuracy after epoch 177: 70.58%\n",
      "Epoch: 178, Training Loss: 0.0471889249548135\n",
      "Validation Accuracy after epoch 178: 64.95%\n",
      "Epoch: 179, Training Loss: 0.05221227850036129\n",
      "Validation Accuracy after epoch 179: 65.72%\n",
      "Epoch: 180, Training Loss: 0.04833175344726123\n",
      "Validation Accuracy after epoch 180: 67.53%\n",
      "Epoch: 181, Training Loss: 0.047571932854692994\n",
      "Validation Accuracy after epoch 181: 50.91%\n",
      "Epoch: 182, Training Loss: 0.0551197332380068\n",
      "Validation Accuracy after epoch 182: 69.84%\n",
      "Epoch: 183, Training Loss: 0.04740126559670414\n",
      "Validation Accuracy after epoch 183: 62.519999999999996%\n",
      "Epoch: 184, Training Loss: 0.0484683737331463\n",
      "Validation Accuracy after epoch 184: 23.49%\n",
      "Epoch: 185, Training Loss: 0.04554119387336666\n",
      "Validation Accuracy after epoch 185: 73.95%\n",
      "Epoch: 186, Training Loss: 0.03673824969240848\n",
      "Validation Accuracy after epoch 186: 51.849999999999994%\n",
      "Epoch: 187, Training Loss: 0.04458469924424082\n",
      "Validation Accuracy after epoch 187: 61.72%\n",
      "Epoch: 188, Training Loss: 0.044549368432951646\n",
      "Validation Accuracy after epoch 188: 71.16%\n",
      "Epoch: 189, Training Loss: 0.03332418978602514\n",
      "Validation Accuracy after epoch 189: 43.75%\n",
      "Epoch: 190, Training Loss: 0.06749036145941986\n",
      "Validation Accuracy after epoch 190: 41.980000000000004%\n",
      "Epoch: 191, Training Loss: 0.050098239230420775\n",
      "Validation Accuracy after epoch 191: 73.37%\n",
      "Epoch: 192, Training Loss: 0.034228981017013604\n",
      "Validation Accuracy after epoch 192: 62.71%\n",
      "Epoch: 193, Training Loss: 0.050737410818900715\n",
      "Validation Accuracy after epoch 193: 72.6%\n",
      "Epoch: 194, Training Loss: 0.03439993617158202\n",
      "Validation Accuracy after epoch 194: 73.59%\n",
      "Epoch: 195, Training Loss: 0.030177661021242436\n",
      "Validation Accuracy after epoch 195: 74.14%\n",
      "Epoch: 196, Training Loss: 0.030896296414136982\n",
      "Validation Accuracy after epoch 196: 74.08%\n",
      "Epoch: 197, Training Loss: 0.02747853863758066\n",
      "Validation Accuracy after epoch 197: 70.69%\n",
      "Epoch: 198, Training Loss: 0.0281043711581084\n",
      "Validation Accuracy after epoch 198: 72.16%\n",
      "Epoch: 199, Training Loss: 0.021946365157525766\n",
      "Validation Accuracy after epoch 199: 73.67%\n",
      "Epoch: 200, Training Loss: 0.021562080935734654\n",
      "Validation Accuracy after epoch 200: 70.54%\n",
      "Epoch: 201, Training Loss: 0.025048267037924524\n",
      "Validation Accuracy after epoch 201: 73.72%\n",
      "Epoch: 202, Training Loss: 0.02190171036294059\n",
      "Validation Accuracy after epoch 202: 70.82000000000001%\n",
      "Epoch: 203, Training Loss: 0.024062768475193043\n",
      "Validation Accuracy after epoch 203: 72.74000000000001%\n",
      "Epoch: 204, Training Loss: 0.02330215484894755\n",
      "Validation Accuracy after epoch 204: 71.74000000000001%\n",
      "Epoch: 205, Training Loss: 0.02114027938769792\n",
      "Validation Accuracy after epoch 205: 72.48%\n",
      "Epoch: 206, Training Loss: 0.020953165399252443\n",
      "Validation Accuracy after epoch 206: 73.72999999999999%\n",
      "Epoch: 207, Training Loss: 0.021512455153314736\n",
      "Validation Accuracy after epoch 207: 72.11999999999999%\n",
      "Epoch: 208, Training Loss: 0.02349082786245081\n",
      "Validation Accuracy after epoch 208: 73.31%\n",
      "Epoch: 209, Training Loss: 0.018876740026979675\n",
      "Validation Accuracy after epoch 209: 50.6%\n",
      "Epoch: 210, Training Loss: 0.02106350031204979\n",
      "Validation Accuracy after epoch 210: 74.05000000000001%\n",
      "Epoch: 211, Training Loss: 0.019295488984253772\n",
      "Validation Accuracy after epoch 211: 60.440000000000005%\n",
      "Epoch: 212, Training Loss: 0.021175662538690534\n",
      "Validation Accuracy after epoch 212: 72.37%\n",
      "Epoch: 213, Training Loss: 0.015322437657795422\n",
      "Validation Accuracy after epoch 213: 61.88%\n",
      "Epoch: 214, Training Loss: 0.023053270613844924\n",
      "Validation Accuracy after epoch 214: 65.59%\n",
      "Epoch: 215, Training Loss: 0.018214260250457404\n",
      "Validation Accuracy after epoch 215: 73.9%\n",
      "Epoch: 216, Training Loss: 0.017962863890911496\n",
      "Validation Accuracy after epoch 216: 73.17%\n",
      "Epoch: 217, Training Loss: 0.01794057044908023\n",
      "Validation Accuracy after epoch 217: 73.5%\n",
      "Epoch: 218, Training Loss: 0.018962610204515937\n",
      "Validation Accuracy after epoch 218: 74.06%\n",
      "Epoch: 219, Training Loss: 0.016242075151295814\n",
      "Validation Accuracy after epoch 219: 69.62%\n",
      "Epoch: 220, Training Loss: 0.016042323815344553\n",
      "Validation Accuracy after epoch 220: 72.72999999999999%\n",
      "Epoch: 221, Training Loss: 0.01447423114789688\n",
      "Validation Accuracy after epoch 221: 73.1%\n",
      "Epoch: 222, Training Loss: 0.012515941867009377\n",
      "Validation Accuracy after epoch 222: 73.79%\n",
      "Epoch: 223, Training Loss: 0.014461213113207732\n",
      "Validation Accuracy after epoch 223: 73.8%\n",
      "Epoch: 224, Training Loss: 0.0135896856666726\n",
      "Validation Accuracy after epoch 224: 73.36%\n",
      "Epoch: 225, Training Loss: 0.01444619669801677\n",
      "Validation Accuracy after epoch 225: 72.86%\n",
      "Epoch: 226, Training Loss: 0.011489779632666584\n",
      "Validation Accuracy after epoch 226: 73.94%\n",
      "Epoch: 227, Training Loss: 0.01039787258162661\n",
      "Validation Accuracy after epoch 227: 73.75%\n",
      "Epoch: 228, Training Loss: 0.01284474802858201\n",
      "Validation Accuracy after epoch 228: 74.11999999999999%\n",
      "Epoch: 229, Training Loss: 0.010519540068679167\n",
      "Validation Accuracy after epoch 229: 73.72999999999999%\n",
      "Epoch: 230, Training Loss: 0.011350714468711016\n",
      "Validation Accuracy after epoch 230: 71.95%\n",
      "Epoch: 231, Training Loss: 0.009628621902426375\n",
      "Validation Accuracy after epoch 231: 73.83%\n",
      "Epoch: 232, Training Loss: 0.009758058565613978\n",
      "Validation Accuracy after epoch 232: 73.00999999999999%\n",
      "Epoch: 233, Training Loss: 0.009591300579090424\n",
      "Validation Accuracy after epoch 233: 74.03999999999999%\n",
      "Epoch: 234, Training Loss: 0.010686629594129788\n",
      "Validation Accuracy after epoch 234: 59.730000000000004%\n",
      "Epoch: 235, Training Loss: 0.011606307027092122\n",
      "Validation Accuracy after epoch 235: 74.16%\n",
      "Epoch: 236, Training Loss: 0.009849342638510577\n",
      "Validation Accuracy after epoch 236: 73.58%\n",
      "Epoch: 237, Training Loss: 0.010656963769897885\n",
      "Validation Accuracy after epoch 237: 73.96000000000001%\n",
      "Epoch: 238, Training Loss: 0.028640097509140667\n",
      "Validation Accuracy after epoch 238: 73.75%\n",
      "Epoch: 239, Training Loss: 0.07356005935001371\n",
      "Validation Accuracy after epoch 239: 69.34%\n",
      "Epoch: 240, Training Loss: 0.056091179653509134\n",
      "Validation Accuracy after epoch 240: 73.3%\n",
      "Epoch: 241, Training Loss: 0.017248772047346938\n",
      "Validation Accuracy after epoch 241: 74.11%\n",
      "Epoch: 242, Training Loss: 0.012293571811419485\n",
      "Validation Accuracy after epoch 242: 73.96000000000001%\n",
      "Epoch: 243, Training Loss: 0.015063629192842022\n",
      "Validation Accuracy after epoch 243: 74.06%\n",
      "Epoch: 244, Training Loss: 0.010299203386071765\n",
      "Validation Accuracy after epoch 244: 73.96000000000001%\n",
      "Epoch: 245, Training Loss: 0.009025910933998644\n",
      "Validation Accuracy after epoch 245: 73.52%\n",
      "Epoch: 246, Training Loss: 0.00850830635252704\n",
      "Validation Accuracy after epoch 246: 73.85000000000001%\n",
      "Epoch: 247, Training Loss: 0.006568599618552134\n",
      "Validation Accuracy after epoch 247: 73.66%\n",
      "Epoch: 248, Training Loss: 0.0063683482988164675\n",
      "Validation Accuracy after epoch 248: 67.60000000000001%\n",
      "Epoch: 249, Training Loss: 0.014963937900014237\n",
      "Validation Accuracy after epoch 249: 72.3%\n",
      "Epoch: 250, Training Loss: 0.00994857211934898\n",
      "Validation Accuracy after epoch 250: 73.29%\n",
      "Epoch: 251, Training Loss: 0.009600581692220868\n",
      "Validation Accuracy after epoch 251: 63.0%\n",
      "Epoch: 252, Training Loss: 0.015106875891261317\n",
      "Validation Accuracy after epoch 252: 73.25%\n",
      "Epoch: 253, Training Loss: 0.008599294423762246\n",
      "Validation Accuracy after epoch 253: 73.42999999999999%\n",
      "Epoch: 254, Training Loss: 0.006223715889147635\n",
      "Validation Accuracy after epoch 254: 73.92999999999999%\n",
      "Epoch: 255, Training Loss: 0.007148084347434056\n",
      "Validation Accuracy after epoch 255: 68.03%\n",
      "Epoch: 256, Training Loss: 0.010082616470233107\n",
      "Validation Accuracy after epoch 256: 74.0%\n",
      "Epoch: 257, Training Loss: 0.010949140276296584\n",
      "Validation Accuracy after epoch 257: 56.279999999999994%\n",
      "Epoch: 258, Training Loss: 0.061172826375881964\n",
      "Validation Accuracy after epoch 258: 70.98%\n",
      "Epoch: 259, Training Loss: 0.015692425759561607\n",
      "Validation Accuracy after epoch 259: 73.71%\n",
      "Epoch: 260, Training Loss: 0.007307467962522298\n",
      "Validation Accuracy after epoch 260: 73.03%\n",
      "Epoch: 261, Training Loss: 0.007026780312812394\n",
      "Validation Accuracy after epoch 261: 73.72%\n",
      "Epoch: 262, Training Loss: 0.006503316630927019\n",
      "Validation Accuracy after epoch 262: 72.2%\n",
      "Epoch: 263, Training Loss: 0.006166136940009892\n",
      "Validation Accuracy after epoch 263: 74.11999999999999%\n",
      "Epoch: 264, Training Loss: 0.009251516130889821\n",
      "Validation Accuracy after epoch 264: 73.83999999999999%\n",
      "Epoch: 265, Training Loss: 0.006897711352033712\n",
      "Validation Accuracy after epoch 265: 72.94%\n",
      "Epoch: 266, Training Loss: 0.008532326096398493\n",
      "Validation Accuracy after epoch 266: 74.29%\n",
      "Epoch: 267, Training Loss: 0.0048931068239841955\n",
      "Validation Accuracy after epoch 267: 74.26%\n",
      "Epoch: 268, Training Loss: 0.004868087259812288\n",
      "Validation Accuracy after epoch 268: 73.74000000000001%\n",
      "Epoch: 269, Training Loss: 0.004743111720278143\n",
      "Validation Accuracy after epoch 269: 74.08%\n",
      "Epoch: 270, Training Loss: 0.004715190791433244\n",
      "Validation Accuracy after epoch 270: 73.58%\n",
      "Epoch: 271, Training Loss: 0.0053293981506829236\n",
      "Validation Accuracy after epoch 271: 74.1%\n",
      "Epoch: 272, Training Loss: 0.004901158921134747\n",
      "Validation Accuracy after epoch 272: 74.00999999999999%\n",
      "Epoch: 273, Training Loss: 0.004868481471046956\n",
      "Validation Accuracy after epoch 273: 66.81%\n",
      "Epoch: 274, Training Loss: 0.006503459163214964\n",
      "Validation Accuracy after epoch 274: 73.14%\n",
      "Epoch: 275, Training Loss: 0.004421520514095582\n",
      "Validation Accuracy after epoch 275: 74.24%\n",
      "Epoch: 276, Training Loss: 0.004305724447699981\n",
      "Validation Accuracy after epoch 276: 74.08%\n",
      "Epoch: 277, Training Loss: 0.004533793289310244\n",
      "Validation Accuracy after epoch 277: 73.67%\n",
      "Epoch: 278, Training Loss: 0.004550029161770869\n",
      "Validation Accuracy after epoch 278: 74.02%\n",
      "Epoch: 279, Training Loss: 0.004199167198586084\n",
      "Validation Accuracy after epoch 279: 73.37%\n",
      "Epoch: 280, Training Loss: 0.004248597103480995\n",
      "Validation Accuracy after epoch 280: 72.05%\n",
      "Epoch: 281, Training Loss: 0.004320268427073012\n",
      "Validation Accuracy after epoch 281: 74.08%\n",
      "Epoch: 282, Training Loss: 0.01030179976841168\n",
      "Validation Accuracy after epoch 282: 73.98%\n",
      "Epoch: 283, Training Loss: 0.0041577593463657915\n",
      "Validation Accuracy after epoch 283: 74.05000000000001%\n",
      "Epoch: 284, Training Loss: 0.005647726448314131\n",
      "Validation Accuracy after epoch 284: 46.46%\n",
      "Epoch: 285, Training Loss: 0.01995331095427375\n",
      "Validation Accuracy after epoch 285: 57.75%\n",
      "Epoch: 286, Training Loss: 0.1272210948907769\n",
      "Validation Accuracy after epoch 286: 61.35%\n",
      "Epoch: 287, Training Loss: 0.1902918265647162\n",
      "Validation Accuracy after epoch 287: 71.32%\n",
      "Epoch: 288, Training Loss: 0.04271956766686698\n",
      "Validation Accuracy after epoch 288: 72.39999999999999%\n",
      "Epoch: 289, Training Loss: 0.017959518748296238\n",
      "Validation Accuracy after epoch 289: 71.44%\n",
      "Epoch: 290, Training Loss: 0.009496809195932846\n",
      "Validation Accuracy after epoch 290: 73.54%\n",
      "Epoch: 291, Training Loss: 0.010376413652832355\n",
      "Validation Accuracy after epoch 291: 66.39%\n",
      "Epoch: 292, Training Loss: 0.022281608558134856\n",
      "Validation Accuracy after epoch 292: 54.86%\n",
      "Epoch: 293, Training Loss: 0.021347813390563374\n",
      "Validation Accuracy after epoch 293: 73.53%\n",
      "Epoch: 294, Training Loss: 0.007645512226341671\n",
      "Validation Accuracy after epoch 294: 73.46000000000001%\n",
      "Epoch: 295, Training Loss: 0.004978612022701581\n",
      "Validation Accuracy after epoch 295: 74.0%\n",
      "Epoch: 296, Training Loss: 0.004982774237976493\n",
      "Validation Accuracy after epoch 296: 73.64%\n",
      "Epoch: 297, Training Loss: 0.0049642019984348085\n",
      "Validation Accuracy after epoch 297: 74.09%\n",
      "Epoch: 298, Training Loss: 0.004348891644223975\n",
      "Validation Accuracy after epoch 298: 71.11%\n",
      "Epoch: 299, Training Loss: 0.005620259220142911\n",
      "Validation Accuracy after epoch 299: 73.72999999999999%\n",
      "Epoch: 300, Training Loss: 0.0048349842980272995\n",
      "Validation Accuracy after epoch 300: 70.77%\n",
      "Total Training Time: 11440.637595415115 seconds\n"
     ]
    }
   ],
   "source": [
    "training_loop(\n",
    "    n_epochs=300,\n",
    "    optimizer=optimizer,\n",
    "    model=model,\n",
    "    loss_fn=loss_fn,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bedc3a-e0e8-4f04-9326-88fdabbcada3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
